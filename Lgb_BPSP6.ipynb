{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lgb-BPSP6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPmSHPD3soRl",
        "colab_type": "code",
        "outputId": "095d3390-44b0-4e5c-e5c2-dff25f3d8f0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive                                                  \n",
        "drive.mount('/content/drive')                                                                                                                                                                                     "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFhRMxs3At4x",
        "colab_type": "code",
        "outputId": "cc8a7c27-9d4e-4f27-b2a6-4582074b63e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7410 sha256=33a9ea82773bf13c046394b7a52cfa9f65c8dca3f43c51906adca6f8180b5316\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 26.4 GB  | Proc size: 156.6 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV6-OdeTAUM2",
        "colab_type": "code",
        "outputId": "9aab2c8e-f4ea-4d19-84f6-b838c41b5b60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone --recursive https://github.com/Microsoft/LightGBM\n",
        "%cd /content/LightGBM/\n",
        "!mkdir build\n",
        "!cmake -DUSE_GPU=1 #avoid ..\n",
        "!make -j$(nproc)\n",
        "!sudo apt-get -y install python-pip\n",
        "!sudo -H pip install setuptools pandas numpy scipy scikit-learn -U\n",
        "%cd ./python-package\n",
        "!sudo python setup.py install --precompile"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'LightGBM'...\n",
            "remote: Enumerating objects: 195, done.\u001b[K\n",
            "remote: Counting objects: 100% (195/195), done.\u001b[K\n",
            "remote: Compressing objects: 100% (145/145), done.\u001b[K\n",
            "remote: Total 16559 (delta 102), reused 75 (delta 44), pack-reused 16364\n",
            "Receiving objects: 100% (16559/16559), 11.23 MiB | 28.26 MiB/s, done.\n",
            "Resolving deltas: 100% (11996/11996), done.\n",
            "Submodule 'include/boost/compute' (https://github.com/boostorg/compute) registered for path 'compute'\n",
            "Cloning into '/content/LightGBM/compute'...\n",
            "remote: Enumerating objects: 21728, done.        \n",
            "remote: Total 21728 (delta 0), reused 0 (delta 0), pack-reused 21728        \n",
            "Receiving objects: 100% (21728/21728), 8.50 MiB | 28.93 MiB/s, done.\n",
            "Resolving deltas: 100% (17565/17565), done.\n",
            "Submodule path 'compute': checked out '36c89134d4013b2e5e45bc55656a18bd6141995a'\n",
            "/content/LightGBM\n",
            "-- The C compiler identification is GNU 7.4.0\n",
            "-- The CXX compiler identification is GNU 7.4.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
            "-- Looking for CL_VERSION_2_2\n",
            "-- Looking for CL_VERSION_2_2 - found\n",
            "-- Found OpenCL: /usr/lib/x86_64-linux-gnu/libOpenCL.so (found version \"2.2\") \n",
            "-- OpenCL include directory: /usr/include\n",
            "-- Boost version: 1.65.1\n",
            "-- Found the following Boost libraries:\n",
            "--   filesystem\n",
            "--   system\n",
            "-- Performing Test MM_PREFETCH\n",
            "-- Performing Test MM_PREFETCH - Success\n",
            "-- Use _mm_prefetch\n",
            "-- Performing Test MM_MALLOC\n",
            "-- Performing Test MM_MALLOC - Success\n",
            "-- Use _mm_malloc\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/LightGBM\n",
            "\u001b[35m\u001b[1mScanning dependencies of target _lightgbm\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target lightgbm\u001b[0m\n",
            "[  1%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/main.cpp.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/application/application.cpp.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/c_api.cpp.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/lightgbm_R.cpp.o\u001b[0m\n",
            "[  9%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/application/application.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
            "[ 19%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
            "[ 58%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
            "[ 74%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
            "[ 77%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
            "[ 79%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
            "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
            "[ 84%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
            "[ 87%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX shared library lib_lightgbm.so\u001b[0m\n",
            "[ 93%] Built target _lightgbm\n",
            "[ 95%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
            "[ 96%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
            "[ 98%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable lightgbm\u001b[0m\n",
            "[100%] Built target lightgbm\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libpython-all-dev python-all python-all-dev python-asn1crypto\n",
            "  python-cffi-backend python-crypto python-cryptography python-dbus\n",
            "  python-enum34 python-gi python-idna python-ipaddress python-keyring\n",
            "  python-keyrings.alt python-pip-whl python-pkg-resources python-secretstorage\n",
            "  python-setuptools python-six python-wheel python-xdg\n",
            "Suggested packages:\n",
            "  python-crypto-doc python-cryptography-doc python-cryptography-vectors\n",
            "  python-dbus-dbg python-dbus-doc python-enum34-doc python-gi-cairo\n",
            "  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0 python-fs\n",
            "  python-gdata python-keyczar python-secretstorage-doc python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  libpython-all-dev python-all python-all-dev python-asn1crypto\n",
            "  python-cffi-backend python-crypto python-cryptography python-dbus\n",
            "  python-enum34 python-gi python-idna python-ipaddress python-keyring\n",
            "  python-keyrings.alt python-pip python-pip-whl python-pkg-resources\n",
            "  python-secretstorage python-setuptools python-six python-wheel python-xdg\n",
            "0 upgraded, 22 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 3,376 kB of archives.\n",
            "After this operation, 10.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpython-all-dev amd64 2.7.15~rc1-1 [1,092 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all amd64 2.7.15~rc1-1 [1,076 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all-dev amd64 2.7.15~rc1-1 [1,100 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-asn1crypto all 0.24.0-1 [72.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-cffi-backend amd64 1.11.5-1 [63.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-enum34 all 1.1.6-2 [34.8 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-idna all 2.6-1 [32.4 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-ipaddress all 1.0.17-1 [18.2 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-cryptography amd64 2.1.4-1ubuntu1.3 [221 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-dbus amd64 1.2.6-1 [90.2 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-gi amd64 3.26.1-2ubuntu1 [197 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-secretstorage all 2.3.1-2 [11.8 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-keyring all 10.6.0-1 [30.6 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-keyrings.alt all 3.0-1 [16.7 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.1 [1,653 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip all 9.0.1-2.3~ubuntu1.18.04.1 [151 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-setuptools all 39.0.1-2 [329 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-wheel all 0.30.0-0.2 [36.4 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-xdg all 0.25-4ubuntu1 [31.3 kB]\n",
            "Fetched 3,376 kB in 2s (1,556 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 22.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython-all-dev:amd64.\n",
            "(Reading database ... 145674 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libpython-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-all.\n",
            "Preparing to unpack .../01-python-all_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking python-all (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-all-dev.\n",
            "Preparing to unpack .../02-python-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking python-all-dev (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-asn1crypto.\n",
            "Preparing to unpack .../03-python-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python-cffi-backend.\n",
            "Preparing to unpack .../04-python-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python-crypto.\n",
            "Preparing to unpack .../05-python-crypto_2.6.1-8ubuntu2_amd64.deb ...\n",
            "Unpacking python-crypto (2.6.1-8ubuntu2) ...\n",
            "Selecting previously unselected package python-enum34.\n",
            "Preparing to unpack .../06-python-enum34_1.1.6-2_all.deb ...\n",
            "Unpacking python-enum34 (1.1.6-2) ...\n",
            "Selecting previously unselected package python-idna.\n",
            "Preparing to unpack .../07-python-idna_2.6-1_all.deb ...\n",
            "Unpacking python-idna (2.6-1) ...\n",
            "Selecting previously unselected package python-ipaddress.\n",
            "Preparing to unpack .../08-python-ipaddress_1.0.17-1_all.deb ...\n",
            "Unpacking python-ipaddress (1.0.17-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../09-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-cryptography.\n",
            "Preparing to unpack .../10-python-cryptography_2.1.4-1ubuntu1.3_amd64.deb ...\n",
            "Unpacking python-cryptography (2.1.4-1ubuntu1.3) ...\n",
            "Selecting previously unselected package python-dbus.\n",
            "Preparing to unpack .../11-python-dbus_1.2.6-1_amd64.deb ...\n",
            "Unpacking python-dbus (1.2.6-1) ...\n",
            "Selecting previously unselected package python-gi.\n",
            "Preparing to unpack .../12-python-gi_3.26.1-2ubuntu1_amd64.deb ...\n",
            "Unpacking python-gi (3.26.1-2ubuntu1) ...\n",
            "Selecting previously unselected package python-secretstorage.\n",
            "Preparing to unpack .../13-python-secretstorage_2.3.1-2_all.deb ...\n",
            "Unpacking python-secretstorage (2.3.1-2) ...\n",
            "Selecting previously unselected package python-keyring.\n",
            "Preparing to unpack .../14-python-keyring_10.6.0-1_all.deb ...\n",
            "Unpacking python-keyring (10.6.0-1) ...\n",
            "Selecting previously unselected package python-keyrings.alt.\n",
            "Preparing to unpack .../15-python-keyrings.alt_3.0-1_all.deb ...\n",
            "Unpacking python-keyrings.alt (3.0-1) ...\n",
            "Selecting previously unselected package python-pip-whl.\n",
            "Preparing to unpack .../16-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.1_all.deb ...\n",
            "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
            "Selecting previously unselected package python-pip.\n",
            "Preparing to unpack .../17-python-pip_9.0.1-2.3~ubuntu1.18.04.1_all.deb ...\n",
            "Unpacking python-pip (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../18-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-setuptools.\n",
            "Preparing to unpack .../19-python-setuptools_39.0.1-2_all.deb ...\n",
            "Unpacking python-setuptools (39.0.1-2) ...\n",
            "Selecting previously unselected package python-wheel.\n",
            "Preparing to unpack .../20-python-wheel_0.30.0-0.2_all.deb ...\n",
            "Unpacking python-wheel (0.30.0-0.2) ...\n",
            "Selecting previously unselected package python-xdg.\n",
            "Preparing to unpack .../21-python-xdg_0.25-4ubuntu1_all.deb ...\n",
            "Unpacking python-xdg (0.25-4ubuntu1) ...\n",
            "Setting up python-idna (2.6-1) ...\n",
            "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
            "Setting up python-asn1crypto (0.24.0-1) ...\n",
            "Setting up python-crypto (2.6.1-8ubuntu2) ...\n",
            "Setting up python-wheel (0.30.0-0.2) ...\n",
            "Setting up libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-cffi-backend (1.11.5-1) ...\n",
            "Setting up python-gi (3.26.1-2ubuntu1) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-enum34 (1.1.6-2) ...\n",
            "Setting up python-dbus (1.2.6-1) ...\n",
            "Setting up python-ipaddress (1.0.17-1) ...\n",
            "Setting up python-pip (9.0.1-2.3~ubuntu1.18.04.1) ...\n",
            "Setting up python-all (2.7.15~rc1-1) ...\n",
            "Setting up python-xdg (0.25-4ubuntu1) ...\n",
            "Setting up python-setuptools (39.0.1-2) ...\n",
            "Setting up python-keyrings.alt (3.0-1) ...\n",
            "Setting up python-all-dev (2.7.15~rc1-1) ...\n",
            "Setting up python-cryptography (2.1.4-1ubuntu1.3) ...\n",
            "Setting up python-secretstorage (2.3.1-2) ...\n",
            "Setting up python-keyring (10.6.0-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NfWYfg8sz7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%cp -rp '/content/drive/My Drive/ta-lib/' ~/\n",
        "%cd ~\n",
        "!rm -rf ta-lib*\n",
        "#!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
        "!wget https://sourceforge.net/projects/ta-lib/files/ta-lib/0.4.0/ta-lib-0.4.0-src.tar.gz\n",
        "!tar -xzvf ta-lib-0.4.0-src.tar.gz\n",
        "#%cd '/content/drive/My Drive/ta-lib'\n",
        "#%cd ta-lib\n",
        "import os\n",
        "#os.chdir('/content/drive/My Drive/ta-lib') # Can't use !cd in co-lab\n",
        "os.chdir('ta-lib') # Can't use !cd in co-lab\n",
        "#%cd ~/ta-lib\n",
        "!./configure --prefix=/usr\n",
        "#! '/content/drive/My Drive/ta-lib/configure' --prefix=/usr\n",
        "!make\n",
        "!make install\n",
        "!pip install Ta-Lib\n",
        "%cd /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqQfcWcDuX30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install optuna\n",
        "!pip install joblib\n",
        "!pip install catboost\n",
        "!pip install six\n",
        "!pip install bayesian-optimization\n",
        "#!pip --no-cache-dir install lightgbm --install-option=--gpu --install-option=\"--opencl-include-dir=/usr/local/cuda/include/\" --install-option=\"--opencl-library=/usr/local/cuda/lib64/libOpenCL.so\"\n",
        "#!pip install lightgbm --install-option=--GPU\n",
        "#!sudo pip --no-cache-dir install -I lightgbm --install-option=--gpu --install-option=\"--opencl-include-dir=/usr/local/cuda/include/\" --install-option=\"--opencl-library=/usr/local/cuda/lib64/libOpenCL.so\"\n",
        "\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "import catboost as cat\n",
        "from catboost import Pool\n",
        "from catboost import CatBoost\n",
        "from sklearn import datasets\n",
        "import dateutil\n",
        "import copy\n",
        "import sqlite3\n",
        "import math\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import pickle\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial.distance import correlation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#from multiprocessing import Pool, Value, Array\n",
        "import multiprocessing as multi\n",
        "from joblib import Parallel, delayed\n",
        "import talib as ta\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import sklearn.metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from functools import partial\n",
        "import optuna\n",
        "import joblib\n",
        "from joblib import Parallel, delayed\n",
        "import time\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLmcIF8ou7u9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OneMinData:\n",
        "    def initialize(self):\n",
        "        self.func_dict = {}  # key = [func_name + term], val = (function object, term)\n",
        "        self.index_data_dict = {}  # key= [func_name + term]], val = [index data]\n",
        "        self.unix_time = []\n",
        "        self.dt = []\n",
        "        self.open = []\n",
        "        self.high = []\n",
        "        self.low = []\n",
        "        self.close = []\n",
        "        self.open_change = []\n",
        "        self.high_change = []\n",
        "        self.low_change = []\n",
        "        self.close_change = []\n",
        "        self.size = []\n",
        "        self.future_side = []\n",
        "\n",
        "    def cut_data(self, num_data):\n",
        "        for k in self.index_data_dict:\n",
        "            self.index_data_dict[k] = self.index_data_dict[k][-num_data:]\n",
        "        self.unix_time = self.unix_time[-num_data:]\n",
        "        self.dt = self.dt[-num_data:]\n",
        "        self.open = self.open[-num_data:]\n",
        "        self.high = self.high[-num_data:]\n",
        "        self.low = self.low[-num_data:]\n",
        "        self.close = self.close[-num_data:]\n",
        "        self.open_change = self.open_change[-num_data:]\n",
        "        self.high_change = self.high_change[-num_data:]\n",
        "        self.low_change = self.low_change[-num_data:]\n",
        "        self.close_change = self.close_change[-num_data:]\n",
        "        self.size = self.size[-num_data:]\n",
        "        \n",
        "\n",
        "    def cut_data2(self, from_ind, to_ind):\n",
        "        for k in self.index_data_dict:\n",
        "            self.index_data_dict[k] = self.index_data_dict[k][from_ind:to_ind]\n",
        "        self.unix_time = self.unix_time[from_ind:to_ind]\n",
        "        self.dt = self.dt[from_ind:to_ind]\n",
        "        self.open = self.open[from_ind:to_ind]\n",
        "        self.high = self.high[from_ind:to_ind]\n",
        "        self.low = self.low[from_ind:to_ind]\n",
        "        self.close = self.close[from_ind:to_ind]\n",
        "        self.open_change = self.open_change[from_ind:to_ind]\n",
        "        self.high_change = self.high_change[from_ind:to_ind]\n",
        "        self.low_change = self.low_change[from_ind:to_ind]\n",
        "        self.close_change = self.close_change[from_ind:to_ind]\n",
        "        self.size = self.size[from_ind:to_ind]\n",
        "\n",
        "\n",
        "    def del_data(self, num_remain_data):\n",
        "        if len(self.dt) > num_remain_data:\n",
        "            for k in self.index_data_dict:\n",
        "                del self.index_data_dict[k][:-num_remain_data]\n",
        "            del self.unix_time[:-num_remain_data]\n",
        "            del self.dt[:-num_remain_data]\n",
        "            del self.open[:-num_remain_data]\n",
        "            del self.high[:-num_remain_data]\n",
        "            del self.low[:-num_remain_data]\n",
        "            del self.close[:-num_remain_data]\n",
        "            del self.open_change[:-num_remain_data]\n",
        "            del self.high_change[:-num_remain_data]\n",
        "            del self.low_change[:-num_remain_data]\n",
        "            del self.close_change[:-num_remain_data]\n",
        "            del self.size[:-num_remain_data]\n",
        "\n",
        "    def extract_data(self, ex_from, to):\n",
        "        if len(self.dt) > ex_from:\n",
        "            for k in self.index_data_dict:\n",
        "                del self.index_data_dict[k][-ex_from:-to]\n",
        "            del self.unix_time[-ex_from:-to]\n",
        "            del self.dt[-ex_from:-to]\n",
        "            del self.open[-ex_from:-to]\n",
        "            del self.high[-ex_from:-to]\n",
        "            del self.low[-ex_from:-to]\n",
        "            del self.close[-ex_from:-to]\n",
        "            del self.open_change[-ex_from:-to]\n",
        "            del self.high_change[-ex_from:-to]\n",
        "            del self.low_change[-ex_from:-to]\n",
        "            del self.close_change[-ex_from:-to]\n",
        "            del self.size[-ex_from:-to]\n",
        "\n",
        "    def add_and_pop(self, unix_time, dt, open, high, low, close, size):\n",
        "        self.unix_time.append(unix_time)\n",
        "        self.unix_time.pop(0)\n",
        "        self.dt.append(dt)\n",
        "        self.dt.pop(0)\n",
        "        self.open.append(open)\n",
        "        self.open.pop(0)\n",
        "        self.high.append(high)\n",
        "        self.high.pop(0)\n",
        "        self.low.append(low)\n",
        "        self.low.pop(0)\n",
        "        self.close.append(close)\n",
        "        self.close.pop(0)\n",
        "        self.open_change.append(open)\n",
        "        self.open_change.pop(0)\n",
        "        self.high_change.append(high)\n",
        "        self.high_change.pop(0)\n",
        "        self.low_change.append(low)\n",
        "        self.low_change.pop(0)\n",
        "        self.close_change.append(close)\n",
        "        self.close_change.pop(0)\n",
        "        self.size.append(size)\n",
        "        self.size.pop(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "An4QTgSuvF7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OneMinMarketData:\n",
        "    @classmethod\n",
        "    def initialize_for_bot(cls, num_term, from_ind, to_ind, kijun_ratio, kijun_period, production_data_len):\n",
        "        cls.num_term = num_term\n",
        "        cls.kijun_ratio = kijun_ratio #0.001 - 0.1\n",
        "        cls.kijun_period = kijun_period\n",
        "        cls.term_list = cls.generate_term_list2(num_term)\n",
        "        cls.ohlc = cls.read_from_csv('/content/drive/My Drive/mex_data.csv')\n",
        "        if production_data_len == 0:\n",
        "            print('normal cut data')\n",
        "            cls.ohlc.cut_data2(from_ind, to_ind)\n",
        "        else: #[-production_data_len:]のデータを使う。\n",
        "            print('production use cut data')\n",
        "            cls.ohlc.cut_data2(-production_data_len, -1)\n",
        "        cls.__generate_all_func_dict()\n",
        "        cls.__calc_all_index_dict()\n",
        "        \n",
        "    @classmethod\n",
        "    def update_for_bot(cls):\n",
        "        cls.__calc_all_index()\n",
        "        \n",
        "\n",
        "    @classmethod\n",
        "    def read_from_csv(cls, file_name):\n",
        "        ohlc = OneMinData()\n",
        "        ohlc.initialize()\n",
        "        df = pd.read_csv(file_name)\n",
        "        ohlc.dt = list(map(lambda x: datetime.strptime(str(x), '%Y-%m-%d %H:%M:%S'), list(df['dt'])))\n",
        "        ohlc.unix_time = list(df['timestamp'])\n",
        "        ohlc.open = list(df['open'])\n",
        "        ohlc.high = list(df['high'])\n",
        "        ohlc.low = list(df['low'])\n",
        "        ohlc.close = list(df['close'])\n",
        "        ohlc.size = list(df['volume'])\n",
        "        return ohlc\n",
        "    \n",
        "    \n",
        "    @classmethod\n",
        "    def write_all_func_dict(cls):\n",
        "        with open('/content/drive/My Drive/Model/bpsp_cols.csv', 'w') as file:\n",
        "            writer = csv.writer(file, lineterminator='\\n')\n",
        "            writer.writerow(list(cls.ohlc.func_dict.keys()))\n",
        "        print('completed write bpsp columns')\n",
        "        \n",
        "        \n",
        "    @classmethod\n",
        "    def read_func_dict(cls):\n",
        "        #read from func / term list\n",
        "        cols = []\n",
        "        with open('/content/drive/My Drive/Model/bpsp_cols.csv', 'r') as f:\n",
        "            reader = csv.reader(f)\n",
        "            for r in reader:\n",
        "                cols.append(r)\n",
        "        #copy matched key func val\n",
        "        func_obj= {}\n",
        "        for col in cols[0]:\n",
        "            if col not in ['open', 'high', 'low', 'close']:\n",
        "                func_obj[col] = cls.ohlc.func_dict[col]\n",
        "        #replace ohlc.func_dict\n",
        "        cls.ohlc.func_dict = func_obj\n",
        "    \n",
        "    \n",
        "    \n",
        "    '''\n",
        "    generate all func / term as a dict\n",
        "    calc all index as a dict\n",
        "    generate df from the index data dict\n",
        "    calc correlation\n",
        "    remove correlated columns\n",
        "    renew fund / term dict with non-correlated func / term\n",
        "    calc index data of the renewed dict\n",
        "    '''\n",
        "    \n",
        "    @classmethod\n",
        "    def __generate_all_func_dict(cls):\n",
        "        for term in cls.term_list:\n",
        "            cls.ohlc.func_dict['ema:'+str(term)] = (OneMinMarketData.calc_ema,term)\n",
        "            cls.ohlc.func_dict['ema_size:'+str(term)] = (OneMinMarketData.calc_ema_size,term)\n",
        "            cls.ohlc.func_dict['ema_kairi:'+str(term)] = (OneMinMarketData.calc_ema_kairi,term)\n",
        "            cls.ohlc.func_dict['ema_gra:'+str(term)] = (OneMinMarketData.calc_ema_gra,term)\n",
        "            cls.ohlc.func_dict['dema:'+str(term)] = (OneMinMarketData.calc_dema,term)\n",
        "            cls.ohlc.func_dict['dema_kairi:'+str(term)] = (OneMinMarketData.calc_dema_kairi,term)\n",
        "            cls.ohlc.func_dict['dema_gra:'+str(term)] = (OneMinMarketData.calc_dema_gra,term)\n",
        "            cls.ohlc.func_dict['momentum:'+str(term)] = (OneMinMarketData.calc_momentum,term)\n",
        "            cls.ohlc.func_dict['momentum_size:'+str(term)] = (OneMinMarketData.calc_momentum_size,term)\n",
        "            cls.ohlc.func_dict['rate_of_change:'+str(term)] = (OneMinMarketData.calc_rate_of_change,term)\n",
        "            cls.ohlc.func_dict['rsi:'+str(term)] = (OneMinMarketData.calc_rsi,term)\n",
        "            cls.ohlc.func_dict['williams_R:'+str(term)] = (OneMinMarketData.calc_williams_R,term)\n",
        "            cls.ohlc.func_dict['beta:'+str(term)] = (OneMinMarketData.calc_beta,term)\n",
        "            cls.ohlc.func_dict['time_series_forecast:'+str(term)] = (OneMinMarketData.calc_time_series_forecast,term)\n",
        "            cls.ohlc.func_dict['correl:'+str(term)] = (OneMinMarketData.calc_correl,term)\n",
        "            cls.ohlc.func_dict['linear_reg:'+str(term)] = (OneMinMarketData.calc_linear_reg,term)\n",
        "            cls.ohlc.func_dict['linear_reg_angle:'+str(term)] = (OneMinMarketData.calc_linear_reg_angle,term)\n",
        "            cls.ohlc.func_dict['linear_reg_intercept:'+str(term)] = (OneMinMarketData.calc_linear_reg_intercept,term)\n",
        "            cls.ohlc.func_dict['linear_reg_slope:'+str(term)] = (OneMinMarketData.calc_linear_reg_slope,term)\n",
        "            cls.ohlc.func_dict['stdv:'+str(term)] = (OneMinMarketData.calc_stdv,term)\n",
        "            cls.ohlc.func_dict['stdv_size:'+str(term)] = (OneMinMarketData.calc_stdv_size,term)\n",
        "            cls.ohlc.func_dict['var:'+str(term)] = (OneMinMarketData.calc_var,term)\n",
        "            cls.ohlc.func_dict['adx:'+str(term)] = (OneMinMarketData.calc_adx,term)\n",
        "            cls.ohlc.func_dict['aroon_os:'+str(term)] = (OneMinMarketData.calc_aroon_os,term)\n",
        "            cls.ohlc.func_dict['cci:'+str(term)] = (OneMinMarketData.calc_cci,term)\n",
        "            cls.ohlc.func_dict['dx:'+str(term)] = (OneMinMarketData.calc_dx,term)\n",
        "            if term >= 10:\n",
        "                cls.ohlc.func_dict['macd:'+str(term)] = (OneMinMarketData.calc_macd,term)\n",
        "                cls.ohlc.func_dict['macd_signal:'+str(term)] = (OneMinMarketData.calc_macd_signal,term)\n",
        "                cls.ohlc.func_dict['macd_hist:'+str(term)] = (OneMinMarketData.calc_macd_hist,term)\n",
        "            if term <= 300:\n",
        "                cls.ohlc.func_dict['calc_high_kairi:'+str(term)] = (OneMinMarketData.calc_high_kairi,term)\n",
        "                cls.ohlc.func_dict['calc_low_kairi:'+str(term)] = (OneMinMarketData.calc_low_kairi,term)\n",
        "                \n",
        "            '''\n",
        "            cls.ohlc.func_dict['makairi_momentum:'+str(term)] = (OneMinMarketData.generate_makairi,OneMinMarketData.calc_momentum, term)\n",
        "            cls.ohlc.func_dict['makairi_rate_of_change:'+str(term)] = (OneMinMarketData.generate_makairi,OneMinMarketData.calc_rate_of_change, term)\n",
        "            cls.ohlc.func_dict['makairi_rsi:'+str(term)] = (OneMinMarketData.generate_makairi,OneMinMarketData.calc_rsi, term)\n",
        "            cls.ohlc.func_dict['makairi_williams_R:'+str(term)] = (OneMinMarketData.generate_makairi,OneMinMarketData.calc_williams_R, term)\n",
        "            cls.ohlc.func_dict['makairi_beta:'+str(term)] = (OneMinMarketData.generate_makairi,OneMinMarketData.calc_beta, term)\n",
        "            cls.ohlc.func_dict['makairi_time_series_forecast:'+str(term)] = (OneMinMarketData.generate_makairi,OneMinMarketData.calc_time_series_forecast, term)\n",
        "            cls.ohlc.func_dict['makairi_correl:'+str(term)] = (OneMinMarketData.generate_makairi,OneMinMarketData.calc_correl, term)\n",
        "            cls.ohlc.func_dict['makairi_linear_reg:'+str(term)] = (OneMinMarketData.generate_makairi,OneMinMarketData.calc_linear_reg, term)\n",
        "            cls.ohlc.func_dict['makairi_linear_reg_angle:'+str(term)] = (OneMinMarketData.generate_makairi,OneMinMarketData.calc_linear_reg_angle, term)\n",
        "            cls.ohlc.func_dict['makairi_linear_reg_intercept:'+str(term)] = (OneMinMarketData.generate_makairi,OneMinMarketData.calc_linear_reg_intercept, term)\n",
        "            cls.ohlc.func_dict['makairi_linear_reg_slope:'+str(term)] = (OneMinMarketData.generate_makairi,OneMinMarketData.calc_linear_reg_slope, term)\n",
        "            cls.ohlc.func_dict['makairi_stdv:'+str(term)] = (OneMinMarketData.generate_makairi,OneMinMarketData.calc_stdv, term)\n",
        "            cls.ohlc.func_dict['makairi_var:'+str(term)] = (OneMinMarketData.generate_makairi,OneMinMarketData.calc_var, term)\n",
        "            cls.ohlc.func_dict['makairi_adx:'+str(term)] = (OneMinMarketData.generate_makairi,OneMinMarketData.calc_adx, term)\n",
        "            cls.ohlc.func_dict['makairi_aroon_os:'+str(term)] = (OneMinMarketData.generate_makairi,OneMinMarketData.calc_aroon_os, term)\n",
        "            cls.ohlc.func_dict['makairi_cci:'+str(term)] = (OneMinMarketData.generate_makairi,OneMinMarketData.calc_cci, term)\n",
        "            cls.ohlc.func_dict['makairi_dx:'+str(term)] = (OneMinMarketData.generate_makairi,OneMinMarketData.calc_dx, term)\n",
        "            \n",
        "            cls.ohlc.func_dict['diff_momentum:'+str(term)] = (OneMinMarketData.generate_diff,OneMinMarketData.calc_momentum, term)\n",
        "            cls.ohlc.func_dict['diff_rate_of_change:'+str(term)] = (OneMinMarketData.generate_diff,OneMinMarketData.calc_rate_of_change, term)\n",
        "            cls.ohlc.func_dict['diff_rsi:'+str(term)] = (OneMinMarketData.generate_diff,OneMinMarketData.calc_rsi, term)\n",
        "            cls.ohlc.func_dict['diff_williams_R:'+str(term)] = (OneMinMarketData.generate_diff,OneMinMarketData.calc_williams_R, term)\n",
        "            cls.ohlc.func_dict['diff_beta:'+str(term)] = (OneMinMarketData.generate_diff,OneMinMarketData.calc_beta, term)\n",
        "            cls.ohlc.func_dict['diff_time_series_forecast:'+str(term)] = (OneMinMarketData.generate_diff,OneMinMarketData.calc_time_series_forecast, term)\n",
        "            cls.ohlc.func_dict['diff_correl:'+str(term)] = (OneMinMarketData.generate_diff,OneMinMarketData.calc_correl, term)\n",
        "            cls.ohlc.func_dict['diff_linear_reg:'+str(term)] = (OneMinMarketData.generate_diff,OneMinMarketData.calc_linear_reg, term)\n",
        "            cls.ohlc.func_dict['diff_linear_reg_angle:'+str(term)] = (OneMinMarketData.generate_diff,OneMinMarketData.calc_linear_reg_angle, term)\n",
        "            cls.ohlc.func_dict['diff_linear_reg_intercept:'+str(term)] = (OneMinMarketData.generate_diff,OneMinMarketData.calc_linear_reg_intercept, term)\n",
        "            cls.ohlc.func_dict['diff_linear_reg_slope:'+str(term)] = (OneMinMarketData.generate_diff,OneMinMarketData.calc_linear_reg_slope, term)\n",
        "            cls.ohlc.func_dict['diff_stdv:'+str(term)] = (OneMinMarketData.generate_diff,OneMinMarketData.calc_stdv, term)\n",
        "            cls.ohlc.func_dict['diff_var:'+str(term)] = (OneMinMarketData.generate_diff,OneMinMarketData.calc_var, term)\n",
        "            cls.ohlc.func_dict['diff_adx:'+str(term)] = (OneMinMarketData.generate_diff,OneMinMarketData.calc_adx, term)\n",
        "            cls.ohlc.func_dict['diff_aroon_os:'+str(term)] = (OneMinMarketData.generate_diff,OneMinMarketData.calc_aroon_os, term)\n",
        "            cls.ohlc.func_dict['diff_cci:'+str(term)] = (OneMinMarketData.generate_diff,OneMinMarketData.calc_cci, term)\n",
        "            cls.ohlc.func_dict['diff_dx:'+str(term)] = (OneMinMarketData.generate_diff,OneMinMarketData.calc_dx, term)\n",
        "            '''\n",
        "\n",
        "        cls.ohlc.func_dict['normalized_ave_true_range:'+str(0)] = (OneMinMarketData.calc_normalized_ave_true_range,0)\n",
        "        #cls.ohlc.func_dict['three_outside_updown:'+str(0)] = (OneMinMarketData.calc_three_outside_updown,0)\n",
        "        #cls.ohlc.func_dict['breakway:'+str(0)] = (OneMinMarketData.calc_breakway,0)\n",
        "        #cls.ohlc.func_dict['dark_cloud_cover:'+str(0)] = (OneMinMarketData.calc_dark_cloud_cover,0)\n",
        "        #cls.ohlc.func_dict['dragonfly_doji:'+str(0)] = (OneMinMarketData.calc_dragonfly_doji,0)\n",
        "        #cls.ohlc.func_dict['updown_sidebyside_white_lines:'+str(0)] = (OneMinMarketData.calc_updown_sidebyside_white_lines,0)\n",
        "        #cls.ohlc.func_dict['haramisen:'+str(0)] = (OneMinMarketData.calc_haramisen,0)\n",
        "        #cls.ohlc.func_dict['hikkake_pattern:'+str(0)] = (OneMinMarketData.calc_hikkake_pattern,0)\n",
        "        #cls.ohlc.func_dict['neck_pattern:'+str(0)] = (OneMinMarketData.calc_neck_pattern,0)\n",
        "        #cls.ohlc.func_dict['upsidedownside_gap_three_method:'+str(0)] = (OneMinMarketData.calc_upsidedownside_gap_three_method,0)\n",
        "        #cls.ohlc.func_dict['sar:'+str(0)] = (OneMinMarketData.calc_sar,0)\n",
        "        #cls.ohlc.func_dict['bop:'+str(0)] = (OneMinMarketData.calc_bop,0)\n",
        "        cls.ohlc.func_dict['uwahige:'+str(0)] = (OneMinMarketData.calc_uwahige_length,0)\n",
        "        cls.ohlc.func_dict['shitahige:'+str(0)] = (OneMinMarketData.calc_shitahige_length,0)\n",
        "        \n",
        "    \n",
        "    '''\n",
        "\n",
        "    '''\n",
        "    @classmethod\n",
        "    def __calc_all_index_dict(cls):\n",
        "        print('calculating all index dict')\n",
        "        start_time = time.time()\n",
        "        for k in cls.ohlc.func_dict:\n",
        "            if int(k.split(':')[1]) > 0:\n",
        "                if k.split('_')[0] != 'makairi' and k.split('_')[0] != 'diff' and k.split(':')[0] not in ['ema_kairi', 'ema_gra', 'dema_kairi', 'dema_gra']:\n",
        "                    cls.ohlc.index_data_dict[k] = cls.ohlc.func_dict[k][0](cls.ohlc.func_dict[k][1])\n",
        "            else:\n",
        "                cls.ohlc.index_data_dict[k] = cls.ohlc.func_dict[k][0]()\n",
        "        print('completed non makairi diff index. time=', time.time() - start_time)\n",
        "\n",
        "        start_time = time.time()\n",
        "        for k in cls.ohlc.func_dict:\n",
        "            if k.split('_')[0] == 'makairi':\n",
        "                data = cls.ohlc.func_dict[k][1](cls.ohlc.func_dict[k][2])\n",
        "                cls.ohlc.index_data_dict[k] = cls.ohlc.func_dict[k][0](data, cls.ohlc.func_dict[k][2])\n",
        "            elif k.split('_')[0] == 'diff':\n",
        "                data = cls.ohlc.func_dict[k][1](cls.ohlc.func_dict[k][2])\n",
        "                cls.ohlc.index_data_dict[k] = cls.ohlc.func_dict[k][0](data)\n",
        "            elif k.split(':')[0] in ['ema_kairi', 'ema_gra', 'dema_kairi', 'dema_gra']:\n",
        "                cls.ohlc.index_data_dict[k] = cls.ohlc.func_dict[k][0](cls.ohlc.func_dict[k][1])\n",
        "\n",
        "        cls.ohlc.future_side = cls.calc_future_side_bpsp_largesmall()\n",
        "        print('completed calc makairi diff index. time=', time.time() - start_time)\n",
        "\n",
        "            \n",
        "            \n",
        "    @classmethod\n",
        "    def genrate_df_from_dict(cls):\n",
        "        start_time = time.time()\n",
        "        cut_size = cls.term_list[-1] + 1\n",
        "        end = len(cls.ohlc.close) - cls.kijun_period #to ajust to index size of future_side\n",
        "        OneMinMarketData.ohlc.index_data_dict['dt'] = cls.ohlc.dt\n",
        "        OneMinMarketData.ohlc.index_data_dict['size'] = cls.ohlc.size\n",
        "        OneMinMarketData.ohlc.index_data_dict['close'] = cls.ohlc.close\n",
        "        df = pd.DataFrame(OneMinMarketData.ohlc.index_data_dict)\n",
        "        '''\n",
        "        df = df.assign(dt=cls.ohlc.dt)\n",
        "        df = df.assign(open=cls.ohlc.open)\n",
        "        df = df.assign(high=cls.ohlc.high)\n",
        "        df = df.assign(low=cls.ohlc.low)\n",
        "        df = df.assign(close=cls.ohlc.close)\n",
        "        df = df.assign(open_change=cls.ohlc.open_change)\n",
        "        df = df.assign(high_change=cls.ohlc.high_change)\n",
        "        df = df.assign(low_change=cls.ohlc.low_change)\n",
        "        df = df.assign(close_change=cls.ohlc.close_change)\n",
        "        df = df.assign(size=cls.ohlc.size)\n",
        "        '''\n",
        "        df = df.iloc[cut_size:end] \n",
        "        #df['future_side'] = cls.ohlc.future_side[cut_size:]\n",
        "        df = df.assign(future_side=cls.ohlc.future_side[cut_size:])\n",
        "        print('completed generate df from dict. time=', time.time() - start_time)\n",
        "        return df\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def remove_cols_contains_nan(cls,  df):\n",
        "        start_time = time.time()\n",
        "        remove_cols = []\n",
        "        tmp = df.copy()\n",
        "        for col in tmp.columns:\n",
        "            for ind,d in enumerate(tmp[col]):\n",
        "                if str(d) =='nan':\n",
        "                    remove_cols.append(col)\n",
        "                    break\n",
        "        if len(remove_cols) > 0:\n",
        "            df.drop(remove_cols, axis=1, inplace=True)\n",
        "            print('removed ', len(remove_cols), ' cols contains nan.')\n",
        "        print('completed remove cols contains nan. time=', time.time() - start_time)\n",
        "        return df\n",
        "        \n",
        "    @classmethod\n",
        "    def remove_cols_contains_nan2(cls, df):\n",
        "        start_time = time.time()\n",
        "        pre_n = len(df.columns)\n",
        "        after_n = len(df.dropna(axis = 1, how = 'any').columns)\n",
        "        print('removed ', pre_n - after_n, 'cols contains nan.')\n",
        "        print('completed remove cols contains nan. time=', time.time() - start_time)\n",
        "        return df.dropna(axis = 1, how = 'any')\n",
        "\n",
        "    @classmethod\n",
        "    def __calc_all_index(cls):\n",
        "        start_time = time.time()\n",
        "        cls.ohlc.ave_price = cls.calc_ave_price(cls.ohlc.open, cls.ohlc.high, cls.ohlc.low, cls.ohlc.close)\n",
        "        for term in cls.term_list:\n",
        "            cls.ohlc.ema[term] = cls.calc_ema(term, cls.ohlc.close)\n",
        "            cls.ohlc.ema_kairi[term] = cls.calc_ema_kairi(cls.ohlc.close, cls.ohlc.ema[term])\n",
        "            cls.ohlc.ema_gra[term] = cls.calc_ema_gra(cls.ohlc.ema[term])\n",
        "            cls.ohlc.dema[term] = cls.calc_dema(term, cls.ohlc.close)\n",
        "            cls.ohlc.dema_kairi[term] = cls.calc_dema_kairi(cls.ohlc.close, cls.ohlc.dema[term])\n",
        "            cls.ohlc.dema_gra[term] = cls.calc_dema_gra(cls.ohlc.dema[term])\n",
        "            cls.ohlc.momentum[term] = cls.calc_momentum(term, cls.ohlc.close)\n",
        "            cls.ohlc.rate_of_change[term] = cls.calc_rate_of_change(term, cls.ohlc.close)\n",
        "            cls.ohlc.rsi[term] = cls.calc_rsi(term, cls.ohlc.close)\n",
        "            cls.ohlc.williams_R[term] = cls.calc_williams_R(term, cls.ohlc.high, cls.ohlc.low, cls.ohlc.close)\n",
        "            cls.ohlc.beta[term] = cls.calc_beta(term, cls.ohlc.high, cls.ohlc.low)\n",
        "            cls.ohlc.tsf[term] = cls.calc_time_series_forecast(term, cls.ohlc.close)\n",
        "            cls.ohlc.correl[term] = cls.calc_correl(term, cls.ohlc.high, cls.ohlc.low)\n",
        "            cls.ohlc.linear_reg[term] = cls.calc_linear_reg(term, cls.ohlc.close)\n",
        "            cls.ohlc.linear_reg_angle[term] = cls.calc_linear_reg_angle(term, cls.ohlc.close)\n",
        "            cls.ohlc.linear_reg_intercept[term] = cls.calc_linear_reg_intercept(term, cls.ohlc.close)\n",
        "            cls.ohlc.linear_reg_slope[term] = cls.calc_linear_reg_slope(term, cls.ohlc.close)\n",
        "            cls.ohlc.stdv[term] = cls.calc_stdv(term, cls.ohlc.close)\n",
        "            cls.ohlc.var[term] = cls.calc_var(term, cls.ohlc.close)\n",
        "            cls.ohlc.linear_reg_ave[term] = cls.calc_linear_reg(term, cls.ohlc.ave_price)\n",
        "            cls.ohlc.linear_reg_angle_ave[term] = cls.calc_linear_reg_angle(term, cls.ohlc.ave_price)\n",
        "            cls.ohlc.linear_reg_intercept_ave[term] = cls.calc_linear_reg_intercept(term, cls.ohlc.ave_price)\n",
        "            cls.ohlc.linear_reg_slope_ave[term] = cls.calc_linear_reg_slope(term, cls.ohlc.ave_price)\n",
        "            cls.ohlc.stdv_ave[term] = cls.calc_stdv(term, cls.ohlc.ave_price)\n",
        "            cls.ohlc.var_ave[term] = cls.calc_var(term, cls.ohlc.ave_price)\n",
        "            cls.ohlc.adx[term] = cls.calc_adx(term, cls.ohlc.high, cls.ohlc.low, cls.ohlc.close)\n",
        "            cls.ohlc.aroon_os[term] = cls.calc_aroon_os(term, cls.ohlc.high, cls.ohlc.low)\n",
        "            cls.ohlc.cci[term] = cls.calc_cci(term, cls.ohlc.high, cls.ohlc.low, cls.ohlc.close)\n",
        "            cls.ohlc.dx[term] = cls.calc_dx(term, cls.ohlc.high, cls.ohlc.low, cls.ohlc.close)\n",
        "            if term >= 10:\n",
        "                cls.ohlc.macd[term], cls.ohlc.macdsignal[term], cls.ohlc.macdhist[term] = cls.calc_macd(cls.ohlc.close, int(float(term) / 2.0), term, int(float(term) / 3.0))\n",
        "                cls.ohlc.macd[term] = list(cls.ohlc.macd[term])\n",
        "                cls.ohlc.macdsignal[term] = list(cls.ohlc.macdsignal[term])\n",
        "                cls.ohlc.macdhist[term] = list(cls.ohlc.macdhist[term])\n",
        "                cls.ohlc.macd_ave[term], cls.ohlc.macdsignal_ave[term], cls.ohlc.macdhist_ave[term] = cls.calc_macd(cls.ohlc.ave_price, int(float(term) / 2.0), term,int(float(term) / 3.0))\n",
        "                cls.ohlc.macd_ave[term] = list(cls.ohlc.macd_ave[term])\n",
        "                cls.ohlc.macdsignal_ave[term] = list(cls.ohlc.macdsignal_ave[term])\n",
        "                cls.ohlc.macdhist_ave[term] = list(cls.ohlc.macdhist_ave[term])\n",
        "        cls.ohlc.normalized_ave_true_range = cls.calc_normalized_ave_true_range(cls.ohlc.high, cls.ohlc.low,\n",
        "                                                                                cls.ohlc.close)\n",
        "        cls.ohlc.three_outside_updown = cls.calc_three_outside_updown(cls.ohlc.open, cls.ohlc.high, cls.ohlc.low,\n",
        "                                                                      cls.ohlc.close)\n",
        "        cls.ohlc.breakway = cls.calc_breakway(cls.ohlc.open, cls.ohlc.high, cls.ohlc.low, cls.ohlc.close)\n",
        "        cls.ohlc.dark_cloud_cover = cls.calc_dark_cloud_cover(cls.ohlc.open, cls.ohlc.high, cls.ohlc.low,\n",
        "                                                              cls.ohlc.close)\n",
        "        cls.ohlc.dragonfly_doji = cls.calc_dragonfly_doji(cls.ohlc.open, cls.ohlc.high, cls.ohlc.low, cls.ohlc.close)\n",
        "        cls.ohlc.updown_sidebyside_white_lines = cls.calc_updown_sidebyside_white_lines(cls.ohlc.open, cls.ohlc.high,\n",
        "                                                                                        cls.ohlc.low, cls.ohlc.close)\n",
        "        cls.ohlc.haramisen = cls.calc_haramisen(cls.ohlc.open, cls.ohlc.high, cls.ohlc.low, cls.ohlc.close)\n",
        "        cls.ohlc.hikkake_pattern = cls.calc_hikkake_pattern(cls.ohlc.open, cls.ohlc.high, cls.ohlc.low, cls.ohlc.close)\n",
        "        cls.ohlc.neck_pattern = cls.calc_neck_pattern(cls.ohlc.open, cls.ohlc.high, cls.ohlc.low, cls.ohlc.close)\n",
        "        cls.ohlc.upsidedownside_gap_three_method = cls.calc_upsidedownside_gap_three_method(cls.ohlc.open,\n",
        "                                                                                            cls.ohlc.high, cls.ohlc.low,\n",
        "                                                                                            cls.ohlc.close)\n",
        "        cls.ohlc.sar = cls.calc_sar(cls.ohlc.high, cls.ohlc.low, 0.02, 0.2)\n",
        "        cls.ohlc.bop = cls.calc_bop(cls.ohlc.open, cls.ohlc.high, cls.ohlc.low, cls.ohlc.close)\n",
        "        #cls.ohlc.bp, cls.ohlc.sp = cls.calc_pl_ls_points()\n",
        "\n",
        "        #generate various index\n",
        "        for term in cls.term_list:\n",
        "            cls.ohlc.various_makairi['emakairi'+str(term)] = cls.ohlc.ema_kairi[term]\n",
        "            cls.ohlc.various_makairi['demakairi' + str(term)] = cls.ohlc.dema_kairi[term]\n",
        "            cls.ohlc.various_diff['emadiff'+str(term)] = cls.ohlc.ema_kairi[term]\n",
        "            cls.ohlc.various_diff['demadiff' + str(term)] = cls.ohlc.dema_kairi[term]\n",
        "            cls.ohlc.various_makairi['momkairi' + str(term)] = cls.ohlc.momentum[term]\n",
        "            cls.ohlc.various_diff['momdiff' + str(term)] = cls.ohlc.momentum[term]\n",
        "            cls.ohlc.various_makairi['rsikairi' + str(term)] = cls.ohlc.rsi[term]\n",
        "            cls.ohlc.various_diff['rsidiff' + str(term)] = cls.ohlc.rsi[term]\n",
        "            cls.ohlc.various_makairi['williams_Rkairi' + str(term)] = cls.ohlc.williams_R[term]\n",
        "            cls.ohlc.various_diff['williams_Rdiff' + str(term)] = cls.ohlc.williams_R[term]\n",
        "            cls.ohlc.various_makairi['betakairi' + str(term)] = cls.ohlc.beta[term]\n",
        "            cls.ohlc.various_diff['betadiff' + str(term)] = cls.ohlc.beta[term]\n",
        "            cls.ohlc.various_makairi['linear_regkairi' + str(term)] = cls.ohlc.linear_reg[term]\n",
        "            cls.ohlc.various_diff['linear_regdiff' + str(term)] = cls.ohlc.linear_reg[term]\n",
        "            cls.ohlc.various_makairi['linear_reg_slopekairi' + str(term)] = cls.ohlc.linear_reg_slope[term]\n",
        "            cls.ohlc.various_diff['linear_reg_slopediff' + str(term)] = cls.ohlc.linear_reg_slope[term]\n",
        "            cls.ohlc.various_makairi['adxkairi' + str(term)] = cls.ohlc.adx[term]\n",
        "            cls.ohlc.various_diff['adxdiff' + str(term)] = cls.ohlc.adx[term]\n",
        "            cls.ohlc.various_makairi['aroon_oskairi' + str(term)] = cls.ohlc.aroon_os[term]\n",
        "            cls.ohlc.various_diff['aroon_osdiff' + str(term)] = cls.ohlc.aroon_os[term]\n",
        "            cls.ohlc.various_makairi['ccikairi' + str(term)] = cls.ohlc.cci[term]\n",
        "            cls.ohlc.various_diff['ccidiff' + str(term)] = cls.ohlc.cci[term]\n",
        "            if term >= 10:\n",
        "                cls.ohlc.various_makairi['macdkairi' + str(term)] = cls.ohlc.macd[term]\n",
        "                cls.ohlc.various_diff['macddiff' + str(term)] = cls.ohlc.macd[term]\n",
        "                cls.ohlc.various_makairi['macdsignalkairi' + str(term)] = cls.ohlc.macdsignal[term]\n",
        "                cls.ohlc.various_diff['macdsignaldiff' + str(term)] = cls.ohlc.macdsignal[term]\n",
        "                cls.ohlc.various_makairi['macdhistkairi' + str(term)] = cls.ohlc.macdhist[term]\n",
        "                cls.ohlc.various_diff['macdhistdiff' + str(term)] = cls.ohlc.macdhist[term]\n",
        "        cls.ohlc.future_side = cls.calc_future_side_bpsp_largesmall()\n",
        "        print('calc all index1 time={}'.format(time.time() - start_time))\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def generate_raw_df(cls):\n",
        "        def __change_dict_key(d, col_name):\n",
        "            newd = dict(map(lambda k: (col_name + str(k), d[k][:]), d.keys()))\n",
        "            return newd\n",
        "        '''data_dict = {'dt':cls.ohlc.dt[:], 'open':cls.ohlc.open[:], 'high':cls.ohlc.high[:],'low':cls.ohlc.low[:],\n",
        "                    'close':cls.ohlc.close[:], 'size':cls.ohlc.size[:], 'normalized_ave_true_range':cls.ohlc.normalized_ave_true_range[:],\n",
        "                    'sar':cls.ohlc.sar[:],'bop':cls.ohlc.bop[:]}'''\n",
        "        data_dict = {'dt': cls.ohlc.dt[:], 'open': cls.ohlc.open[:], 'high': cls.ohlc.high[:], 'low': cls.ohlc.low[:],\n",
        "                     'close': cls.ohlc.close[:], 'size': cls.ohlc.size[:],\n",
        "                     'normalized_ave_true_range': cls.ohlc.normalized_ave_true_range[:],\n",
        "                     'three_outside_updown': cls.ohlc.three_outside_updown[:], 'breakway': cls.ohlc.breakway[:],\n",
        "                     'dark_cloud_cover': cls.ohlc.dark_cloud_cover[:],\n",
        "                     'dragonfly_doji': cls.ohlc.dragonfly_doji[:],\n",
        "                     'three_oupdown_sidebyside_white_linesutside_updown': cls.ohlc.updown_sidebyside_white_lines[:],\n",
        "                     'haramisen': cls.ohlc.haramisen[:], 'haramhikkake_patternisen': cls.ohlc.hikkake_pattern[:],\n",
        "                     'neck_pattern': cls.ohlc.neck_pattern[:],\n",
        "                     'upsidedownside_gap_three_method': cls.ohlc.upsidedownside_gap_three_method[:],\n",
        "                     'sar': cls.ohlc.sar[:], 'bop': cls.ohlc.bop[:]}\n",
        "        data_dict = {**data_dict, **__change_dict_key(cls.ohlc.ema, 'ema'),\n",
        "                     **__change_dict_key(cls.ohlc.ema_ave, 'ema_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.ema_kairi, 'ema_kairi'),\n",
        "                     **__change_dict_key(cls.ohlc.dema_kairi, 'dema_kairi'),\n",
        "                     **__change_dict_key(cls.ohlc.ema_gra, 'ema_gra'), **__change_dict_key(cls.ohlc.dema, 'dema'),\n",
        "                     **__change_dict_key(cls.ohlc.dema_ave, 'dema_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.dema_gra, 'dema_gra'),\n",
        "                     **__change_dict_key(cls.ohlc.midprice, 'midprice'),\n",
        "                     **__change_dict_key(cls.ohlc.momentum, 'momentum'),\n",
        "                     **__change_dict_key(cls.ohlc.momentum_ave, 'momentum_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.rate_of_change, 'rate_of_change'),\n",
        "                     **__change_dict_key(cls.ohlc.rsi, 'rsi'), **__change_dict_key(cls.ohlc.williams_R, 'williams_R'),\n",
        "                     **__change_dict_key(cls.ohlc.beta, 'beta'), **__change_dict_key(cls.ohlc.tsf, 'tsf'),\n",
        "                     **__change_dict_key(cls.ohlc.correl, 'correl'),\n",
        "                     **__change_dict_key(cls.ohlc.linear_reg, 'linear_reg'),\n",
        "                     **__change_dict_key(cls.ohlc.linear_reg_angle, 'linear_reg_angle'),\n",
        "                     **__change_dict_key(cls.ohlc.linear_reg_intercept, 'linear_reg_intercept'),\n",
        "                     **__change_dict_key(cls.ohlc.linear_reg_slope, 'linear_reg_slope'),\n",
        "                     **__change_dict_key(cls.ohlc.stdv, 'stdv'), **__change_dict_key(cls.ohlc.var, 'var'),\n",
        "                     **__change_dict_key(cls.ohlc.linear_reg_ave, 'linear_reg_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.linear_reg_angle_ave, 'linear_reg_angle_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.linear_reg_intercept_ave, 'linear_reg_intercept_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.linear_reg_slope_ave, 'linear_reg_slope_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.stdv_ave, 'stdv_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.var_ave, 'var_ave'), **__change_dict_key(cls.ohlc.adx, 'adx'),\n",
        "                     **__change_dict_key(cls.ohlc.aroon_os, 'aroon_os'),\n",
        "                     **__change_dict_key(cls.ohlc.cci, 'cci'), **__change_dict_key(cls.ohlc.dx, 'dx'),\n",
        "                     **__change_dict_key(cls.ohlc.macd, 'macd'),\n",
        "                     **__change_dict_key(cls.ohlc.macdsignal, 'macdsignal'),\n",
        "                     **__change_dict_key(cls.ohlc.macdhist, 'macdhist'),\n",
        "                     **__change_dict_key(cls.ohlc.macd_ave, 'macd_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.macdsignal_ave, 'macdsignal_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.macdhist_ave, 'macdhist_ave'),\n",
        "                     ** __change_dict_key(cls.ohlc.various_makairi, 'various_makairi'),\n",
        "                     **__change_dict_key(cls.ohlc.various_diff, 'various_diff')}\n",
        "        df = pd.DataFrame.from_dict(data_dict)\n",
        "        return df\n",
        "\n",
        "    '''\n",
        "    dema, adx, macdはnum_term * 2くらいnanが発生する\n",
        "    print(df.isnull().sum())\n",
        "    '''\n",
        "\n",
        "    @classmethod\n",
        "    def generate_df(cls):\n",
        "        def __change_dict_key(d, col_name):\n",
        "            newd = dict(map(lambda k: (col_name + '_'+str(k), d[k][cut_size:end]), d.keys()))\n",
        "            return newd\n",
        "\n",
        "        start_time = time.time()\n",
        "        cut_size = cls.term_list[-1] * 2\n",
        "        end = len(cls.ohlc.close) - 10 #remove last 700min data as future bp / sp maybe not precise in\n",
        "        data_dict = {'dt': cls.ohlc.dt[cut_size:end], 'open': cls.ohlc.open[cut_size:end],\n",
        "                     'high': cls.ohlc.high[cut_size:end], 'low': cls.ohlc.low[cut_size:end],\n",
        "                     'close': cls.ohlc.close[cut_size:end], 'size': cls.ohlc.size[cut_size:end],\n",
        "                     'normalized_ave_true_range': cls.ohlc.normalized_ave_true_range[cut_size:end],\n",
        "                     'three_outside_updown': cls.ohlc.three_outside_updown[cut_size:end],\n",
        "                     'breakway': cls.ohlc.breakway[cut_size:end],\n",
        "                     'dark_cloud_cover': cls.ohlc.dark_cloud_cover[cut_size:end],\n",
        "                     'dragonfly_doji': cls.ohlc.dragonfly_doji[cut_size:end],\n",
        "                     'three_oupdown_sidebyside_white_linesutside_updown': cls.ohlc.updown_sidebyside_white_lines[\n",
        "                                                                          cut_size:end],\n",
        "                     'haramisen': cls.ohlc.haramisen[cut_size:end],\n",
        "                     'haramhikkake_patternisen': cls.ohlc.hikkake_pattern[cut_size:end],\n",
        "                     'neck_pattern': cls.ohlc.neck_pattern[cut_size:end],\n",
        "                     'upsidedownside_gap_three_method': cls.ohlc.upsidedownside_gap_three_method[cut_size:end],\n",
        "                     'sar': cls.ohlc.sar[cut_size:end], 'bop': cls.ohlc.bop[cut_size:end]}\n",
        "        data_dict = {**data_dict, **__change_dict_key(cls.ohlc.ema, 'ema'),\n",
        "                     **__change_dict_key(cls.ohlc.ema_ave, 'ema_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.ema_kairi, 'ema_kairi'),\n",
        "                     **__change_dict_key(cls.ohlc.dema_kairi, 'dema_kairi'),\n",
        "                     **__change_dict_key(cls.ohlc.ema_gra, 'ema_gra'), **__change_dict_key(cls.ohlc.dema, 'dema'),\n",
        "                     **__change_dict_key(cls.ohlc.dema_ave, 'dema_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.dema_gra, 'dema_gra'),\n",
        "                     **__change_dict_key(cls.ohlc.midprice, 'midprice'),\n",
        "                     **__change_dict_key(cls.ohlc.momentum, 'momentum'),\n",
        "                     **__change_dict_key(cls.ohlc.momentum_ave, 'momentum_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.rate_of_change, 'rate_of_change'),\n",
        "                     **__change_dict_key(cls.ohlc.rsi, 'rsi'), **__change_dict_key(cls.ohlc.williams_R, 'williams_R'),\n",
        "                     **__change_dict_key(cls.ohlc.beta, 'beta'), **__change_dict_key(cls.ohlc.tsf, 'tsf'),\n",
        "                     **__change_dict_key(cls.ohlc.correl, 'correl'),\n",
        "                     **__change_dict_key(cls.ohlc.linear_reg, 'linear_reg'),\n",
        "                     **__change_dict_key(cls.ohlc.linear_reg_angle, 'linear_reg_angle'),\n",
        "                     **__change_dict_key(cls.ohlc.linear_reg_intercept, 'linear_reg_intercept'),\n",
        "                     **__change_dict_key(cls.ohlc.linear_reg_slope, 'linear_reg_slope'),\n",
        "                     **__change_dict_key(cls.ohlc.stdv, 'stdv'), **__change_dict_key(cls.ohlc.var, 'var'),\n",
        "                     **__change_dict_key(cls.ohlc.linear_reg_ave, 'linear_reg_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.linear_reg_angle_ave, 'linear_reg_angle_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.linear_reg_intercept_ave, 'linear_reg_intercept_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.linear_reg_slope_ave, 'linear_reg_slope_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.stdv_ave, 'stdv_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.var_ave, 'var_ave'), **__change_dict_key(cls.ohlc.adx, 'adx'),\n",
        "                     **__change_dict_key(cls.ohlc.aroon_os, 'aroon_os'),\n",
        "                     **__change_dict_key(cls.ohlc.cci, 'cci'), **__change_dict_key(cls.ohlc.dx, 'dx'),\n",
        "                     **__change_dict_key(cls.ohlc.macd, 'macd'),\n",
        "                     **__change_dict_key(cls.ohlc.macdsignal, 'macdsignal'),\n",
        "                     **__change_dict_key(cls.ohlc.macdhist, 'macdhist'),\n",
        "                     **__change_dict_key(cls.ohlc.macd_ave, 'macd_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.macdsignal_ave, 'macdsignal_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.macdhist_ave, 'macdhist_ave'),\n",
        "                     **__change_dict_key(cls.ohlc.various_makairi, 'various_makairi'),\n",
        "                     **__change_dict_key(cls.ohlc.various_diff, 'various_diff')}\n",
        "        data_dict['bpsp'] = cls.ohlc.bpsp[cut_size:end]\n",
        "#        data_dict['bp'] = cls.ohlc.bp[cut_size:end]\n",
        "#        data_dict['sp'] = cls.ohlc.sp[cut_size:end]\n",
        "        df = pd.DataFrame.from_dict(data_dict)\n",
        "        return df\n",
        "\n",
        "    @classmethod\n",
        "    def generate_term_list(cls, num):\n",
        "        term_list = []\n",
        "        category_n = [5, 50, 200]\n",
        "        term_list.extend(list(np.round(np.linspace(category_n[0], category_n[0] * num, num))))\n",
        "        term_list.extend(list(np.round(np.linspace(category_n[1] + (category_n[0] * num),category_n[1] + (category_n[0] * num) + category_n[1] * num), num)))\n",
        "        term_list.extend(list(np.round(np.linspace(category_n[2] + category_n[1] + (category_n[0] * num) + (category_n[1] * num),category_n[2] + (category_n[1] * num) + category_n[2] * num), num)))\n",
        "        return list(map(int, term_list))\n",
        "\n",
        "    @classmethod\n",
        "    def generate_term_list2(cls, max_term):\n",
        "        term_list = []\n",
        "        #term_list = list(np.linspace(10, max_term, num=int(round((max_term-10)/20))))\n",
        "        term_list = list(np.linspace(10, max_term, num=100))\n",
        "        return list(map(int, term_list))\n",
        "\n",
        "    @classmethod\n",
        "    def detect_max_term(cls):\n",
        "        max_term = 0\n",
        "        cols = []\n",
        "        with open(\"./Model/bpsp_cols.csv\", \"r\") as f:\n",
        "            reader = csv.reader(f)\n",
        "            for r in reader:\n",
        "                cols.append(r)\n",
        "        for col in cols[0]:\n",
        "            if col not in ['open', 'high', 'low', 'close']:\n",
        "                if max_term < int(col.split(':')[1]):\n",
        "                    max_term = int(col.split(':')[1])\n",
        "        return max_term\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def calc_ohlc_change(cls):\n",
        "        cls.ohlc.open_change.append(0)\n",
        "        cls.ohlc.high_change.append(0)\n",
        "        cls.ohlc.low_change.append(0)\n",
        "        cls.ohlc.close_change.append(0)\n",
        "        for i in range(len(cls.ohlc.close)-1):\n",
        "            close = cls.ohlc.close[i]\n",
        "            cls.ohlc.open_change.append(round(cls.ohlc.open[i+1] / close,5))\n",
        "            cls.ohlc.high_change.append(round(cls.ohlc.high[i + 1] / close, 5))\n",
        "            cls.ohlc.low_change.append(round(cls.ohlc.low[i + 1] / close, 5))\n",
        "            cls.ohlc.close_change.append(round(cls.ohlc.close[i + 1] / close,5))\n",
        "\n",
        "\n",
        "     #kairi of data\n",
        "    @classmethod\n",
        "    def generate_makairi(cls, data, ma_term):\n",
        "        ma = np.array(list(ta.MA(np.array(data, dtype='f8'), timeperiod=ma_term)),dtype='f8')\n",
        "        return list(map(lambda c, e: (c - e) / e, np.array(data, dtype='f8'), ma))\n",
        "\n",
        "    @classmethod\n",
        "    def generate_diff(cls, data):\n",
        "        return list(ta.ROC(np.array(data, dtype='f8'), timeperiod=1))\n",
        "        #return [0] + list(np.diff(np.array(data, dtype='f8')))\n",
        "    \n",
        "    \n",
        "\n",
        "    @classmethod\n",
        "    def calc_future_side2(cls):\n",
        "        future_side = []\n",
        "        num_buy = 0\n",
        "        num_sell = 0\n",
        "        num_no = 0\n",
        "        num_both = 0\n",
        "        for i in range(len(cls.ohlc.close) - cls.kijun_period):\n",
        "            buy_max = 0\n",
        "            sell_max = 0\n",
        "            entry_p = cls.ohlc.close[i]\n",
        "            kijun_price = cls.ohlc.close[i] * cls.kijun_ratio\n",
        "            for j in range(cls.kijun_period):\n",
        "                buy_max = max(buy_max, cls.ohlc.close[i+j] - entry_p)\n",
        "                sell_max = max(sell_max, entry_p - cls.ohlc.close[i+j])\n",
        "            if buy_max >= kijun_price and sell_max >= kijun_price:\n",
        "                future_side.append('both')\n",
        "                num_both += 1\n",
        "            elif buy_max >= kijun_price and sell_max < kijun_price:\n",
        "                future_side.append('buy')\n",
        "                num_buy += 1\n",
        "            elif buy_max < kijun_price and sell_max >= kijun_price:\n",
        "                future_side.append('sell')\n",
        "                num_sell += 1\n",
        "            elif buy_max < kijun_price and sell_max < kijun_price:\n",
        "                future_side.append('no')\n",
        "                num_no += 1\n",
        "\n",
        "        print('future_side allocation in Market Data:')\n",
        "        tsum = float(len(future_side))\n",
        "        print('no:', round(float(num_no) / tsum, 4), 'buy:', round(float(num_buy) / tsum, 4), 'sell:', round(float(num_sell) / tsum, 4), 'both:', round(float(num_both) / tsum, 4))\n",
        "        return future_side\n",
        "\n",
        "    @classmethod\n",
        "    def calc_future_side_bpsp_largesmall(cls):\n",
        "        future_side = []\n",
        "        num_buy_large = 0\n",
        "        num_buy_small = 0\n",
        "        num_sell_large = 0\n",
        "        num_sell_small = 0\n",
        "        for i in range(len(cls.ohlc.close) - cls.kijun_period):\n",
        "            kijun_pl = int(round(cls.kijun_ratio * cls.ohlc.close[i]))\n",
        "            diff = cls.ohlc.close[i + cls.kijun_period] - cls.ohlc.close[i]\n",
        "            if diff >= kijun_pl:\n",
        "                future_side.append('buy_large')\n",
        "                num_buy_large += 1\n",
        "            elif diff < kijun_pl and diff > 0:\n",
        "                future_side.append('buy_small')\n",
        "                num_buy_small += 1\n",
        "            elif diff > -kijun_pl and diff <= 0:\n",
        "                future_side.append('sell_small')\n",
        "                num_sell_small += 1\n",
        "            elif diff <= -kijun_pl:\n",
        "                future_side.append('sell_large')\n",
        "                num_sell_large += 1\n",
        "        print('future_side allocation in Market Data:')\n",
        "        tsum = float(len(future_side))\n",
        "        print('buy_large:', round(float(num_buy_large) / tsum, 4), 'buy_small:', round(float(num_buy_small) / tsum, 4), 'sell_large:', round(float(num_sell_large) / tsum, 4), 'sell_small:', round(float(num_sell_small) / tsum, 4))\n",
        "        return future_side\n",
        "\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def remove_all_correlated_cols(cls, df, corr_kijun):\n",
        "        def remove_high_corr_cols(df, col_name, kijun):\n",
        "            remove_cols = []\n",
        "            num_corr = 0\n",
        "            for i in range(len(df.columns) - 1):\n",
        "                if df.columns[i] != col_name and df.columns[i] != 'dt':\n",
        "                    corr = df[col_name].corr(df[df.columns[i]])\n",
        "                    if corr > kijun and df.columns[i] not in ['open', 'high', 'low', 'close', 'size', 'future_side']:\n",
        "                        num_corr += 1\n",
        "                        remove_cols.append(df.columns[i])\n",
        "            if len(remove_cols) > 0:\n",
        "                df.drop(remove_cols, axis = 1, inplace = True)\n",
        "                print('removed '+str(num_corr) + 'cols', ' total cols='+str(len(df.columns)))\n",
        "            print('completed remove all correlated cols. time=', time.time() - start_time)\n",
        "            return df\n",
        "\n",
        "        nt= 0\n",
        "        df2 = df.copy()\n",
        "        while True:\n",
        "            if len(df2.columns) <= nt:\n",
        "                print('kita')\n",
        "                break\n",
        "            elif df2.columns[nt] != 'dt':\n",
        "                df2 = remove_high_corr_cols(df2, df2.columns[nt], corr_kijun)\n",
        "            nt += 1\n",
        "        return df2\n",
        "\n",
        "    \n",
        "    @classmethod\n",
        "    def remove_all_correlated_cols2(self, df, corr_kijun, flg_abs):\n",
        "        print('removing all correlated columns..')\n",
        "        df2 = df.copy()\n",
        "        df3 = df.copy()\n",
        "        df2.drop(['dt'], axis=1, inplace=True)\n",
        "        #corrs = np.corrcoef(np.array(df2).transpose())\n",
        "        corrs = np.corrcoef(np.array(df2))\n",
        "        remove_cols = []\n",
        "        cols = list(df2.columns)\n",
        "        for cor in corrs:\n",
        "            for i in range(len(cor)):\n",
        "                if flg_abs:\n",
        "                    if cor[i] != 1.0 and abs(cor[i]) > corr_kijun:\n",
        "                        if cols[i] not in remove_cols and cols[i] not in ['open', 'high', 'low', 'close', 'size', 'future_side']:\n",
        "                            remove_cols.append(cols[i])\n",
        "                else:\n",
        "                    if cor[i] != 1.0 and cor[i] > corr_kijun:\n",
        "                        if cols[i] not in remove_cols and cols[i] not in ['open', 'high', 'low', 'close', 'size', 'future_side']:\n",
        "                            remove_cols.append(cols[i])\n",
        "        df3.drop(remove_cols, axis=1, inplace=True)\n",
        "        print('removed '+str(len(remove_cols))+' colums')\n",
        "        print(remove_cols)\n",
        "        return df3, corrs\n",
        "    \n",
        "    @classmethod\n",
        "    def remove_all_correlated_cols3(self, df, corr_kijun):\n",
        "        print('removing all correlated columns..')\n",
        "        start_time = time.time()\n",
        "        df2 = df.copy()\n",
        "        df3 = df.copy()\n",
        "        df2.drop(['dt','future_side'], axis=1, inplace=True)\n",
        "        corrs = np.corrcoef(np.array(df2).transpose())\n",
        "\n",
        "        # 1. 0番目から0.9以上のindexを検索\n",
        "        def check_corr_kijun(cor, cor_ind, kijun):\n",
        "            rem = []\n",
        "            for i, c in enumerate(cor):\n",
        "                if c >= kijun and i != cor_ind:\n",
        "                    rem.append(i)\n",
        "            return rem\n",
        "\n",
        "        tmp_remo = []\n",
        "        for i, cor in enumerate(corrs):\n",
        "            if i not in tmp_remo:  # 3. 該当indexを除いて次のindexを対象に1の操作を実行\n",
        "                # 2. 該当したindexをtmp_remoに記録\n",
        "                tmp_remo.extend(check_corr_kijun(cor, i, corr_kijun))\n",
        "        \n",
        "        cols = list(df2.columns)\n",
        "        for col in cols:\n",
        "            cor = 1 - correlation(df2['close'], df2[col])\n",
        "            if cor >= corr_kijun:\n",
        "                tmp_remo.extend(col)\n",
        "\n",
        "        # 4. tmp_remoに記録されたindexのcolumnをdfから削除\n",
        "        target_col = []\n",
        "        cols = list(df2.columns)\n",
        "        for tr in tmp_remo:\n",
        "            target_col.append(cols[tr])\n",
        "        excludes = ['dt', 'open', 'high', 'low', 'close', 'close_change', 'dt', 'future_side']\n",
        "        for ex in excludes:\n",
        "            if ex in target_col:\n",
        "                target_col.remove(ex)\n",
        "        df3.drop(target_col, axis=1, inplace=True)\n",
        "        print('removed ' + str(len(target_col)) + ' colums', 'remaining col=' + str(len(df3.columns)))\n",
        "        print('completed remove all correlated cols3. time=', time.time() - start_time)\n",
        "        return df3, corrs\n",
        "                    \n",
        "\n",
        "    @classmethod\n",
        "    def remove_all_correlated_cols4(cls, df, corr_kijun, flg_abs):\n",
        "        print('removing all correlated columns..')\n",
        "        start_time = time.time()\n",
        "        dff = df.copy()\n",
        "        dff.drop(['dt','future_side'], axis=1, inplace=True)\n",
        "        cols = list(dff.columns)\n",
        "        df_res = df.copy()\n",
        "        corr_matrix = np.corrcoef(np.array(dff).transpose())\n",
        "        df_new = pd.DataFrame(data=corr_matrix, index=cols, columns=cols, dtype='float')\n",
        "        upper = df_new.where(np.triu(np.ones(df_new.shape), k=1).astype(np.bool))\n",
        "        to_drop = None\n",
        "        if flg_abs:\n",
        "            to_drop = [column for column in upper.columns if any(abs(upper[column]) > corr_kijun)]\n",
        "        else:\n",
        "            to_drop = [column for column in upper.columns if any(abs(upper[column]) > corr_kijun)]\n",
        "        excludes = ['dt', 'open', 'high', 'low', 'close', 'close_change', 'future_side', 'size']\n",
        "        for ex in excludes:\n",
        "            if ex in to_drop:\n",
        "                to_drop.remove(ex)\n",
        "        df_res.drop(to_drop, axis=1, inplace=True)\n",
        "        print('removed ' + str(len(to_drop)) + ' colums', 'remaining col=' + str(len(df_res.columns)))\n",
        "        print('completed remove all correlated cols4. time=', time.time() - start_time)\n",
        "        return df_res\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def remove_price_dependent_cols(cls, df):\n",
        "        print('removing all price dependent columns..')\n",
        "        max_ind = np.array(list(df['close'])).argmax()\n",
        "        min_ind = np.array(list(df['close'])).argmin()\n",
        "        cols = list(df.columns)\n",
        "        target_cols = []\n",
        "        for col in cols:\n",
        "            if abs(np.array(df[col]).argmax() - max_ind) <= 10 and abs(np.array(df[col]).argmin() - min_ind) <= 10:\n",
        "                target_cols.append(col)\n",
        "        excludes = ['dt', 'open', 'high', 'low', 'close', 'close_change', 'future_side']\n",
        "        for ex in excludes:\n",
        "            if ex in target_cols:\n",
        "                target_cols.remove(ex)\n",
        "        df.drop(target_cols, axis=1, inplace=True)\n",
        "        print('removed ' + str(len(target_cols)) + ' colums', 'remaining col=' + str(len(df.columns)))\n",
        "        return df\n",
        "\n",
        "    @classmethod\n",
        "    def remove_price_dependent_cols2(cls, df, corr_kijun, flg_abs):\n",
        "        print('removing all price dependent columns..')\n",
        "        dff = df.copy()\n",
        "        df_res = df.copy()\n",
        "        dff.drop(['dt','future_side'], axis=1, inplace=True)\n",
        "        cols = list(dff.columns)\n",
        "        to_drop = []\n",
        "        for col in cols:\n",
        "            corr = np.corrcoef(dff['close'], dff[col], rowvar=False)[1][0]\n",
        "            if flg_abs:\n",
        "                if abs(corr) > corr_kijun:\n",
        "                    to_drop.append(col)\n",
        "            else:\n",
        "                if corr > corr_kijun:\n",
        "                    to_drop.append(col)\n",
        "        excludes = ['dt', 'open', 'high', 'low', 'close', 'future_side', 'size']\n",
        "        for ex in excludes:\n",
        "            if ex in to_drop:\n",
        "                to_drop.remove(ex)\n",
        "        df_res.drop(to_drop, axis=1, inplace=True)\n",
        "        print('removed ' + str(len(to_drop)) + ' colums', 'remaining col=' + str(len(df.columns)))\n",
        "        return df_res\n",
        "\n",
        "\n",
        "    #5min, 15min, 1hの足でのヒゲにしたほうがいい\n",
        "    @classmethod\n",
        "    def calc_uwahige_length(cls):\n",
        "        return list(map(lambda i: (cls.ohlc.high[i] - cls.ohlc.close[i])/ cls.ohlc.open[i] if cls.ohlc.close[i] > cls.ohlc.open[i] else (cls.ohlc.high[i] - cls.ohlc.open[i]) / cls.ohlc.open[i], range(0, len(cls.ohlc.close))))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_5min_uwahige_length(cls):\n",
        "        return list(map(lambda i: (cls.ohlc.high[i] - cls.ohlc.close[i])/ cls.ohlc.open[i] if cls.ohlc.close[i] > cls.ohlc.open[i] else (cls.ohlc.high[i] - cls.ohlc.open[i]) / cls.ohlc.open[i], range(0, len(cls.ohlc.close))))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_shitahige_length(cls):\n",
        "        return list(map(lambda i: (cls.ohlc.open[i] - cls.ohlc.low[i])/ cls.ohlc.open[i] if cls.ohlc.close[i] > cls.ohlc.open[i] else (cls.ohlc.close[i] - cls.ohlc.low[i]) / cls.ohlc.open[i], range(0, len(cls.ohlc.close))))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_high_kairi(cls, term):\n",
        "        max_list = []\n",
        "        max_list = list(map(lambda i: max(cls.ohlc.high[i:i+term]), range(0, len(cls.ohlc.high)-term)))\n",
        "        kairi = [0] * term\n",
        "        kairi.extend(list(map(lambda i: max_list[i]/cls.ohlc.close[i+term], range(0,len(max_list)))))\n",
        "        return kairi\n",
        "\n",
        "    @classmethod\n",
        "    def calc_low_kairi(cls, term):\n",
        "        low_list = []\n",
        "        low_list = list(map(lambda i: max(cls.ohlc.low[i:i+term]), range(0, len(cls.ohlc.low)-term)))\n",
        "        kairi = [0] * term\n",
        "        kairi.extend(list(map(lambda i: low_list[i]/cls.ohlc.close[i+term], range(0,len(low_list)))))\n",
        "        return kairi\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def calc_ema(cls, term):\n",
        "        return list(ta.EMA(np.array(cls.ohlc.close, dtype='f8'), timeperiod=term))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_ema_size(cls, term):\n",
        "        return list(ta.EMA(np.array(cls.ohlc.size, dtype='f8'), timeperiod=term))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_ema_kairi(cls, term):\n",
        "        ema = cls.calc_ema(term)\n",
        "        #return list(map(lambda c, e: (c - e) / e, np.array(cls.ohlc.close, dtype='f8'), np.array(cls.ohlc.index_data_dict['ema:'+str(term)], dtype='f8')))\n",
        "        return list(map(lambda c, e: (c - e) / e, np.array(cls.ohlc.close, dtype='f8'), np.array(ema, dtype='f8')))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_dema_kairi(cls, term):\n",
        "        dema = cls.calc_dema(term)\n",
        "        #return list(map(lambda c, d: (c - d) / d, np.array(cls.ohlc.close, dtype='f8'), np.array(cls.ohlc.index_data_dict['dema:'+str(term)], dtype='f8')))\n",
        "        return list(map(lambda c, d: (c - d) / d, np.array(cls.ohlc.close, dtype='f8'), np.array(dema, dtype='f8')))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_ema_gra(cls, term):\n",
        "        ema = cls.calc_ema(term)\n",
        "        #return list(pd.Series(cls.ohlc.index_data_dict['ema:'+str(term)]).diff())\n",
        "        return list(pd.Series(ema).diff())\n",
        "\n",
        "    @classmethod\n",
        "    def calc_dema_gra(cls, term):\n",
        "        dema = cls.calc_dema(term)\n",
        "        #return list(pd.Series(cls.ohlc.index_data_dict['dema:'+str(term)]).diff())\n",
        "        return list(pd.Series(dema).diff())\n",
        "\n",
        "    @classmethod\n",
        "    def calc_dema(cls, term):\n",
        "        return list(ta.DEMA(np.array(cls.ohlc.close, dtype='f8'), timeperiod=term))\n",
        "\n",
        "    #termの2倍くらいnanが続く\n",
        "    @classmethod\n",
        "    def calc_adx(cls, term):\n",
        "        return list(\n",
        "            ta.ADX(np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'), np.array(cls.ohlc.close, dtype='f8'), timeperiod=term))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_aroon_os(cls, term):\n",
        "        return list(ta.AROONOSC(np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'), timeperiod=term))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_cci(cls, term):\n",
        "        return list(\n",
        "            ta.CCI(np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'), np.array(cls.ohlc.close, dtype='f8'), timeperiod=term))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_dx(cls, term):\n",
        "        return list(\n",
        "            ta.DX(np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'), np.array(cls.ohlc.close, dtype='f8'), timeperiod=term))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_midprice(cls, term, high, low):\n",
        "        return list(ta.MIDPRICE(np.array(high, dtype='f8'), np.array(low, dtype='f8'), timeperiod=term))\n",
        "\n",
        "    \n",
        "    @classmethod\n",
        "    def calc_macd(cls, term):\n",
        "        slowperiod = term\n",
        "        fastperiod= int(term / 2.0)\n",
        "        signalperiod=int(term / 3.0)\n",
        "        macd, signal, hist =  ta.MACD(np.array(cls.ohlc.close, dtype='f8'), np.array(fastperiod, dtype='i8'), np.array(slowperiod, dtype='i8'), np.array(signalperiod, dtype='i8'))\n",
        "        return macd\n",
        "    \n",
        "    @classmethod\n",
        "    def calc_macd_signal(cls, term):\n",
        "        slowperiod = term\n",
        "        fastperiod= int(term / 2.0)\n",
        "        signalperiod=int(term / 3.0)\n",
        "        macd, signal, hist =  ta.MACD(np.array(cls.ohlc.close, dtype='f8'), np.array(fastperiod, dtype='i8'), np.array(slowperiod, dtype='i8'),\n",
        "                       np.array(signalperiod, dtype='i8'))\n",
        "        return signal\n",
        "    \n",
        "    @classmethod\n",
        "    def calc_macd_hist(cls, term):\n",
        "        slowperiod = term\n",
        "        fastperiod= int(term / 2.0)\n",
        "        signalperiod=int(term / 3.0)\n",
        "        macd, signal, hist = ta.MACD(np.array(cls.ohlc.close, dtype='f8'), np.array(fastperiod, dtype='i8'), np.array(slowperiod, dtype='i8'),\n",
        "                       np.array(signalperiod, dtype='i8'))\n",
        "        return hist\n",
        "\n",
        "    @classmethod\n",
        "    def calc_momentum(cls, term):\n",
        "        return list(ta.MOM(np.array(cls.ohlc.close, dtype='f8'), timeperiod=term))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_momentum_size(cls, term):\n",
        "        return list(ta.MOM(np.array(cls.ohlc.size, dtype='f8'), timeperiod=term))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_rate_of_change(cls, term):\n",
        "        return list(ta.ROC(np.array(cls.ohlc.close, dtype='f8'), timeperiod=term))\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def calc_rsi(cls, term):\n",
        "        return list(ta.RSI(np.array(cls.ohlc.close, dtype='f8'), timeperiod=term))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_williams_R(cls, term):\n",
        "        return list(ta.WILLR(np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'), np.array(cls.ohlc.close, dtype='f8'),timeperiod=term))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_beta(cls, term):\n",
        "        return list(ta.BETA(np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'), timeperiod=term))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_time_series_forecast(cls, term):\n",
        "        return list(ta.TSF(np.array(cls.ohlc.close, dtype='f8'), timeperiod=term))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_correl(cls, term):\n",
        "        return list(ta.CORREL(np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'), timeperiod=term))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_linear_reg(cls, term):\n",
        "        return list(ta.LINEARREG(np.array(cls.ohlc.close, dtype='f8'), timeperiod=term))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_linear_reg_angle(cls, term):\n",
        "        return list(ta.LINEARREG_ANGLE(np.array(cls.ohlc.close, dtype='f8'), timeperiod=term))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_linear_reg_intercept(cls, term):\n",
        "        return list(ta.LINEARREG_SLOPE(np.array(cls.ohlc.close, dtype='f8'), timeperiod=term))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_linear_reg_slope(cls, term):\n",
        "        return list(ta.LINEARREG_INTERCEPT(np.array(cls.ohlc.close, dtype='f8'), timeperiod=term))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_stdv(cls, term):\n",
        "        return list(ta.STDDEV(np.array(cls.ohlc.close, dtype='f8'), timeperiod=term, nbdev=1))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_stdv_size(cls, term):\n",
        "        return list(ta.STDDEV(np.array(cls.ohlc.size, dtype='f8'), timeperiod=term, nbdev=1))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_var(cls, term):\n",
        "        return list(ta.VAR(np.array(cls.ohlc.close, dtype='f8'), timeperiod=term, nbdev=1))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_normalized_ave_true_range(cls):\n",
        "        return list(ta.NATR(np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'), np.array(cls.ohlc.close, dtype='f8')))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_three_outside_updown(cls):\n",
        "        return list(ta.CDL3OUTSIDE(np.array(cls.ohlc.open, dtype='f8'), np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'),\n",
        "                                   np.array(cls.ohlc.close, dtype='f8')))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_breakway(cls):\n",
        "        return list(ta.CDLBREAKAWAY(np.array(cls.ohlc.open, dtype='f8'), np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'),\n",
        "                                    np.array(cls.ohlc.close, dtype='f8')))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_dark_cloud_cover(cls):\n",
        "        return list(ta.CDLDARKCLOUDCOVER(np.array(cls.ohlc.open, dtype='f8'), np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'),\n",
        "                                 np.array(cls.ohlc.close, dtype='f8'), penetration=0))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_dragonfly_doji(cls):\n",
        "        return list(ta.CDLDRAGONFLYDOJI(np.array(cls.ohlc.open, dtype='f8'), np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'),\n",
        "                                np.array(cls.ohlc.close, dtype='f8')))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_updown_sidebyside_white_lines(cls):\n",
        "        return list(\n",
        "            ta.CDLGAPSIDESIDEWHITE(np.array(cls.ohlc.open, dtype='f8'), np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'),\n",
        "                                   np.array(cls.ohlc.close, dtype='f8')))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_haramisen(cls):\n",
        "        return list(ta.CDLHARAMI(np.array(cls.ohlc.open, dtype='f8'), np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'), np.array(cls.ohlc.close, dtype='f8')))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_hikkake_pattern(cls):\n",
        "        return list(ta.CDLHIKKAKEMOD(np.array(cls.ohlc.open, dtype='f8'), np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'),np.array(cls.ohlc.close, dtype='f8')))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_neck_pattern(cls):\n",
        "        return list(ta.CDLINNECK(np.array(cls.ohlc.open, dtype='f8'), np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'), np.array(cls.ohlc.close, dtype='f8')))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_sar(cls):\n",
        "        accelation = 0.02\n",
        "        maximum = 0.2\n",
        "        return list(ta.SAR(np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'), np.array(accelation, dtype='f8'), np.array(maximum, dtype='f8')))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_bop(cls):\n",
        "        return list(ta.BOP(np.array(cls.ohlc.open, dtype='f8'), np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'),np.array(cls.ohlc.close, dtype='f8')))\n",
        "\n",
        "    @classmethod\n",
        "    def calc_upsidedownside_gap_three_method(cls):\n",
        "        return list(ta.CDLXSIDEGAP3METHODS(np.array(cls.ohlc.open, dtype='f8'), np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'),np.array(cls.ohlc.close, dtype='f8')))\n",
        "\n",
        "    @classmethod\n",
        "    def check_matched_index(cls, test_x):\n",
        "        test = list(test_x['open'])\n",
        "        op = cls.ohlc.open\n",
        "        for i in range(len(op)):\n",
        "            flg = True\n",
        "            for j in range(30):\n",
        "                if test[j] != op[i + j]:\n",
        "                    flg = False\n",
        "                    break\n",
        "            if flg:\n",
        "                return i\n",
        "        print('no matche index found!')\n",
        "        return -1\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def check_matched_index_change(cls, test_x):\n",
        "        test = list(test_x['close_change'])\n",
        "        op = cls.ohlc.close_change\n",
        "        for i in range(len(op)):\n",
        "            flg = True\n",
        "            for j in range(30):\n",
        "                if test[j] != op[i + j]:\n",
        "                    flg = False\n",
        "                    break\n",
        "            if flg:\n",
        "                return i\n",
        "        print('no matche index found!')\n",
        "        return -1\n",
        "\n",
        "    @classmethod\n",
        "    def check_matched_dt(cls, test_x, df2):\n",
        "        col = list(test_x.columns)[0]\n",
        "        test_data = list(test_x[col].iloc[0:30])\n",
        "\n",
        "        for ind,data in enumerate(df2[col]):\n",
        "            if data == test_data[0]:\n",
        "                if test_data == list(df2[col].iloc[ind:ind+30]):\n",
        "                    return cls.ohlc.dt.index(df2['dt'].iloc[ind])\n",
        "        print('matched index was not found')\n",
        "        return -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uak-g5I0vI0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "send order with current ohlc (t)\n",
        "executed with open price of (t+1), send order with ohlc(t+1)\n",
        "executed with open price of (t+2), send order with ohlc(t+2)\n",
        "\n",
        "・消す order idを記録しておいて、move to nextの最後で対象を全部消す。\n",
        "・\n",
        "'''\n",
        "\n",
        "\n",
        "class SimAccount:\n",
        "    def __init__(self):\n",
        "        self.__initialize_order()\n",
        "        self.__initialize_holding()\n",
        "\n",
        "        self.log_data_list = []\n",
        "        self.log_data_df = pd.DataFrame()\n",
        "\n",
        "        self.base_margin_rate = 1.2\n",
        "        self.leverage = 4.0\n",
        "        self.slip_page = 0\n",
        "        self.taker_fee = 0.00075\n",
        "        self.maker_fee = -0.00025\n",
        "        self.force_loss_cut_rate = 0.5\n",
        "        self.initial_asset = 1500000\n",
        "        self.order_cancel_delay = 1\n",
        "        self.ls_penalty = 0\n",
        "\n",
        "        self.pl_kijun = 0\n",
        "        self.ls_kijun = 0\n",
        "\n",
        "        self.total_pl = 0\n",
        "        self.realized_pl = 0\n",
        "        self.current_pl = 0\n",
        "        self.total_fee = 0\n",
        "        self.num_trade = 0\n",
        "        self.num_sell = 0\n",
        "        self.num_buy = 0\n",
        "        self.num_win = 0\n",
        "        self.win_rate = 0\n",
        "        self.asset = self.initial_asset\n",
        "\n",
        "        self.dt_log = []\n",
        "        self.i_log = []\n",
        "        self.order_log = []\n",
        "        self.holding_log = []\n",
        "        self.total_pl_log = []\n",
        "        self.action_log = []\n",
        "        self.price_log = []\n",
        "        self.performance_total_pl_log = []\n",
        "        self.performance_dt_log = []\n",
        "        self.pl_stability = 0\n",
        "\n",
        "        self.start_dt = ''\n",
        "        self.end_dt = ''\n",
        "\n",
        "    def __initialize_order(self):\n",
        "        self.order_serial_num = 0\n",
        "        self.order_serial_list = []\n",
        "        self.order_serial = {}\n",
        "        self.order_side ={}\n",
        "        self.order_price = {}\n",
        "        self.order_size = {}\n",
        "        self.order_i = {}\n",
        "        self.order_dt = {}\n",
        "        self.order_ut = {}\n",
        "        self.order_type = {}  # market / limit / limit-market (limit orderとしてentryして最初の1分で約定しなかったらmarket orderにする）\n",
        "        self.order_cancel = {} #True / False\n",
        "        self.order_expire = {}\n",
        "\n",
        "    def __del_order(self, target_serial):\n",
        "        if target_serial in self.order_serial_list:\n",
        "            self.order_serial_list.remove(target_serial)\n",
        "            del self.order_serial[target_serial]\n",
        "            del self.order_side[target_serial]\n",
        "            del self.order_price[target_serial]\n",
        "            del self.order_size[target_serial]\n",
        "            del self.order_i[target_serial]\n",
        "            del self.order_dt[target_serial]\n",
        "            del self.order_ut[target_serial]\n",
        "            del self.order_type[target_serial]  # market / limit\n",
        "            del self.order_cancel[target_serial] #True / False\n",
        "            del self.order_expire[target_serial]\n",
        "\n",
        "    def __initialize_holding(self):\n",
        "        self.holding_side = ''\n",
        "        self.holding_price = 0\n",
        "        self.holding_size = 0\n",
        "        self.holding_i = 0\n",
        "        self.holding_dt = ''\n",
        "        self.holding_ut = 0\n",
        "\n",
        "\n",
        "    def check_executions(self, i, dt, openp, high, low):\n",
        "        #self.__check_loss_cut(i, dt, high, low)\n",
        "        self.__check_execution(i, dt, openp, high, low)\n",
        "        self.__check_cancel(i, dt)\n",
        "        self.__check_pl(i, dt, high, low)\n",
        "        self.__check_ls(i, dt, high, low)\n",
        "\n",
        "    def move_to_next(self, i, dt, openp, high, low, close):\n",
        "        if len(str(self.start_dt)) < 3:\n",
        "            self.start_dt = dt\n",
        "        if self.holding_side != '':\n",
        "            self.current_pl = (close - self.holding_price) * self.holding_size if self.holding_side == 'buy' else (self.holding_price - close) * self.holding_size\n",
        "        else:\n",
        "            self.current_pl = 0\n",
        "        self.total_pl = self.realized_pl + self.current_pl - self.total_fee\n",
        "        if self.num_trade > 0:\n",
        "            self.win_rate = round(float(self.num_win) / float(self.num_trade), 4)\n",
        "        self.performance_total_pl_log.append(self.total_pl)\n",
        "        self.performance_dt_log.append(dt)\n",
        "        self.asset = self.initial_asset + self.total_pl\n",
        "        self.price_log.append(close)\n",
        "        self.__add_log('i:'+str(i)+' Move to next', i, dt)\n",
        "\n",
        "    def last_day_operation(self, i, dt, openp, high, low, close):\n",
        "        #self.__check_loss_cut(i, dt, high, low)\n",
        "        self.__check_execution(i, dt, openp, high, low)\n",
        "        self.__check_cancel(i, dt)\n",
        "        #if self.holding_side != '':\n",
        "        #    self.__calc_executed_pl(close, self.holding_size, i) #to avoid double count of realized pl and current pl\n",
        "        if self.holding_side != '':\n",
        "            self.current_pl = (close - self.holding_price) * self.holding_size if self.holding_side == 'buy' else (self.holding_price - close) * self.holding_size\n",
        "        else:\n",
        "            self.current_pl = 0\n",
        "        self.total_pl = self.realized_pl + self.current_pl - self.total_fee\n",
        "        self.total_pl_log.append(self.total_pl)\n",
        "        self.performance_total_pl_log.append(self.total_pl)\n",
        "        self.performance_dt_log.append(dt)\n",
        "        if self.num_trade > 0:\n",
        "            self.win_rate = round(float(self.num_win) / float(self.num_trade), 4)\n",
        "        self.__add_log('Sim Finished.', i, dt)\n",
        "        self.end_dt = dt\n",
        "        self.__calc_pl_stability()\n",
        "        self.log_data_df = pd.DataFrame.from_dict(self.log_data_list, orient='columns')\n",
        "\n",
        "    def entry_order(self, side, price, size, type, expire, pl, ls, i, dt):\n",
        "        if side == 'buy':\n",
        "            self.num_buy += 1\n",
        "        elif side == 'sell':\n",
        "            self.num_sell += 1\n",
        "        self.order_serial[self.order_serial_num] = self.order_serial_num\n",
        "        self.order_side[self.order_serial_num] =side\n",
        "        self.order_price[self.order_serial_num] = price\n",
        "        self.order_size[self.order_serial_num] = size\n",
        "        self.order_i[self.order_serial_num] = i\n",
        "        self.order_dt[self.order_serial_num] = dt\n",
        "        self.order_ut[self.order_serial_num] = 0\n",
        "        self.order_type[self.order_serial_num] = type  # limit, market\n",
        "        self.order_cancel[self.order_serial_num] = False\n",
        "        self.order_expire[self.order_serial_num] = expire\n",
        "        self.pl_kijun = pl\n",
        "        self.ls_kijun = ls\n",
        "        self.order_serial_list.append(self.order_serial_num)\n",
        "        self.order_serial_num += 1\n",
        "        self.__add_log('entry order' + side + ' type=' + type, i, dt)\n",
        "\n",
        "    def __calc_fee(self, size, price, maker_taker):\n",
        "        if maker_taker == 'maker':\n",
        "            self.total_fee += size * price * self.maker_fee\n",
        "        elif maker_taker == 'taker':\n",
        "            self.total_fee += size * price * self.taker_fee\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    def __update_holding(self, side, price, size, pl, ls, i, dt):\n",
        "        self.holding_side = side\n",
        "        self.holding_price = price\n",
        "        self.holding_size = size\n",
        "        self.holding_i = i\n",
        "        self.holding_dt = dt\n",
        "        self.pl_kijun = pl\n",
        "        self.ls_kijun = ls\n",
        "\n",
        "    #always cancel latest order\n",
        "    def cancel_order(self, i, dt):\n",
        "        num = self.order_serial_list[-1]\n",
        "        if self.order_type[num] != 'losscut' and self.order_cancel[num] == False:\n",
        "            self.order_cancel[num] = True\n",
        "            self.order_i[num] = i\n",
        "\n",
        "    def __check_cancel(self, i, dt):\n",
        "        ks = copy.copy(list(self.order_cancel.keys()))\n",
        "        for k in ks:\n",
        "            if self.order_cancel[k]:\n",
        "                self.__del_order(k)\n",
        "                self.__add_log('order cancelled.', i, dt)\n",
        "\n",
        "    def __check_expiration(self, i, dt):\n",
        "        ks = list(self.order_i.keys())\n",
        "        for k in ks:\n",
        "            if k in self.order_type[k]:\n",
        "                if i - self.order_i[k] >= self.order_expire[k] and self.order_type[k] == 'limit':\n",
        "                    self.__del_order(k)\n",
        "                    self.__add_log('order expired.', i, dt)\n",
        "\n",
        "    '''\n",
        "    直前のpredictionが反対出なければpl判定させずにholdした方が効率的\n",
        "    '''\n",
        "    def __check_pl(self, i, dt, high, low):\n",
        "        if self.holding_side != '' and self.pl_kijun > 0:\n",
        "            if self.holding_side == 'buy' and self.holding_price + self.pl_kijun < high:\n",
        "                self.__add_log('pl executed.', i, dt)\n",
        "                self.__calc_fee(self.holding_size, self.holding_price + self.pl_kijun, 'maker')\n",
        "                self.__calc_executed_pl(self.holding_price + self.pl_kijun, self.holding_size, i)\n",
        "                self.__initialize_holding()\n",
        "                # self.__update_holding(self.holding_side, self.holding_price + self.pl_kijun + 100, self.holding_size, self.pl_kijun, self.ls_kijun, True, i, dt, ut)\n",
        "            if self.holding_side == 'sell' and self.holding_price - self.pl_kijun > low:\n",
        "                self.__add_log('pl executed.', i, dt)\n",
        "                self.__calc_fee(self.holding_size, self.holding_price + self.pl_kijun, 'maker')\n",
        "                self.__calc_executed_pl(self.holding_price - self.pl_kijun, self.holding_size, i)\n",
        "                self.__initialize_holding()\n",
        "                # self.__update_holding(self.holding_side, self.holding_price - self.pl_kijun - 100, self.holding_size, self.pl_kijun, self.ls_kijun, True, i, dt, ut)\n",
        "\n",
        "    def __check_ls(self, i, dt, high, low):\n",
        "        if self.holding_side != '' and self.ls_kijun > 0:\n",
        "            if self.holding_side == 'buy' and low - self.holding_price<= -self.ls_kijun:\n",
        "                self.__add_log('ls executed.', i, dt)\n",
        "                self.__calc_fee(self.holding_size, self.holding_price + self.pl_kijun, 'taker')\n",
        "                self.__calc_executed_pl(self.holding_price - self.ls_kijun, self.holding_size, i)\n",
        "                self.__initialize_holding()\n",
        "            if self.holding_side == 'sell' and self.holding_price - high <= -self.ls_kijun:\n",
        "                self.__add_log('ls executed.', i, dt)\n",
        "                self.__calc_fee(self.holding_size, self.holding_price + self.pl_kijun, 'taker')\n",
        "                self.__calc_executed_pl(self.holding_price + self.ls_kijun, self.holding_size, i)\n",
        "                self.__initialize_holding()\n",
        "\n",
        "    def __check_execution(self, i, dt, openp, high, low):\n",
        "        ks = list(self.order_i.keys())\n",
        "        for k in ks:\n",
        "            if k in self.order_side:\n",
        "                if self.order_side[k] != '' and self.order_i[k] < i:\n",
        "                    if self.order_type[k] == 'market':\n",
        "                        self.__process_execution(openp, self.order_type[k], i, dt, k)\n",
        "                        self.__del_order(k)\n",
        "                    elif self.order_type[k] == 'limit' and ((self.order_side[k] == 'buy' and self.order_price[k] > low) or (self.order_side[k] == 'sell' and self.order_price[k] < high)):\n",
        "                        self.__process_execution(self.order_price[k], self.order_type[k], i, dt, k)\n",
        "                        self.__del_order(k)\n",
        "                    elif self.order_type[k] == 'limit-market':\n",
        "                        if self.order_i == i and ((self.order_side[k] == 'buy' and self.order_price[k] > low) or (self.order_side[k] == 'sell' and self.order_price[k] < high)): #limit orderが約定したときは普通に処理\n",
        "                            self.__process_execution(self.order_price[k], self.order_type[k], i, dt, k)\n",
        "                            self.__del_order(k)\n",
        "                        else:\n",
        "                            self.__process_execution(openp, self.order_type[k], i, dt, k) #process as a market order\n",
        "                            self.__del_order(k)\n",
        "                    elif self.order_type[k] == 'losscut':\n",
        "                        self.__process_execution(high if self.order_side[k] == 'sell' else 'low', self.order_type[k], i, dt, k)\n",
        "                        self.__del_order(k)\n",
        "                    elif self.order_type[k] != 'market' and self.order_type[k] != 'limit' and self.order_type[k] != 'losscut':\n",
        "                        print('Invalid order type!' + self.order_type[k])\n",
        "                        self.__add_log('invalid order type!' + self.order_type[k], i, dt)\n",
        "\n",
        "    def __process_execution(self, exec_price, order_type, i, dt, k):\n",
        "        if self.order_side[k] != '':\n",
        "            if type != 'losscut':\n",
        "                self.__calc_fee(self.order_size[k], exec_price, 'maker' if order_type == 'limit' else 'taker')\n",
        "            else:\n",
        "                self.__calc_fee(self.order_size[k], exec_price, 'taker')\n",
        "            if self.holding_side == '':  # no position\n",
        "                self.__update_holding(self.order_side[k], exec_price, self.order_size[k], self.pl_kijun, self.ls_kijun, i, dt)\n",
        "                self.__add_log('New Entry:' + self.order_type[k], i, dt)\n",
        "            else:\n",
        "                if self.holding_side == self.order_side[k]:  # order side and position side is matched\n",
        "                    ave_price = round(((self.holding_price * self.holding_size) + (exec_price * self.order_size[k])) / (self.order_size[k] + self.holding_size))  # averaged holding price\n",
        "                    self.__update_holding(self.holding_side, ave_price, self.order_size[k] + self.holding_size, self.pl_kijun, self.ls_kijun, i, dt)\n",
        "                    self.__add_log('Additional Entry:' + self.order_type[k], i, dt)\n",
        "                elif self.holding_size > self.order_size[k]:  # side is not matched and holding size > order size\n",
        "                    self.__calc_executed_pl(exec_price, self.order_size[k], i)\n",
        "                    self.__update_holding(self.holding_side, self.holding_price, self.holding_size - self.order_size[k], self.pl_kijun, self.ls_kijun, i, dt)\n",
        "                    self.__add_log('Exit Order (h>o):' + self.order_type[k], i, dt)\n",
        "                elif self.holding_size == self.order_size[k]:\n",
        "                    self.__add_log('Exit Order (h=o):' + self.order_type[k], i, dt)\n",
        "                    self.__calc_executed_pl(exec_price, self.order_size[k], i)\n",
        "                    self.__initialize_holding()\n",
        "                else:  # in case order size is bigger than holding size\n",
        "                    self.__calc_executed_pl(exec_price, self.holding_size, i)\n",
        "                    self.__add_log('Exit & Entry Order (h<o):' + self.holding_side, i, dt)\n",
        "                    self.__update_holding(self.order_side[k], exec_price, self.order_size[k] - self.holding_size, self.pl_kijun, self.ls_kijun, i, dt)\n",
        "\n",
        "    def __calc_executed_pl(self, exec_price, size, i):  # assume all order size was executed\n",
        "        #pl = (exec_price - self.holding_price * (self.fee + 1)) * size if self.holding_side == 'buy' else (self.holding_price * (1-self.fee) - exec_price) * size\n",
        "        pl = (exec_price - self.holding_price) * size if self.holding_side == 'buy' else (self.holding_price - exec_price) * size\n",
        "        self.realized_pl += round(pl,6)\n",
        "        self.num_trade += 1\n",
        "        if pl > 0:\n",
        "            self.num_win += 1\n",
        "\n",
        "    def __check_loss_cut(self, i, dt, high, low):\n",
        "        if self.holding_side != '':\n",
        "            price = high if self.holding_side == 'sell' else low\n",
        "            req_collateral = self.holding_size * price / self.leverage\n",
        "            pl = price - self.holding_price if self.holding_side == 'buy' else self.holding_price - price\n",
        "            pl = pl * self.holding_size\n",
        "            margin_rate = (self.initial_asset + self.realized_pl + pl) / req_collateral\n",
        "            if margin_rate <= self.force_loss_cut_rate:\n",
        "                self.__force_exit(i, dt)\n",
        "                self.__add_log('Loss cut postion! margin_rate=' + str(margin_rate), i, dt)\n",
        "\n",
        "    def __force_exit(self, i, dt):\n",
        "        #self.__initialize_order()\n",
        "        print('losscut!')\n",
        "        #self.__process_execution(exec_price, order_type, i, dt, k):\n",
        "        self.entry_order('buy' if self.holding_side == 'sell' else 'sell', 0, self.holding_size, 'losscut', 10, 9999, 9999, i, dt)\n",
        "        \n",
        "    def __calc_pl_stability(self):\n",
        "        m = np.mean(np.diff(self.performance_total_pl_log))\n",
        "        self.pl_stability = round(sum(map(lambda x: pow(m-x,2), np.diff(self.performance_total_pl_log))), 4)\n",
        "\n",
        "    def __add_log(self, log, i, dt):\n",
        "        self.total_pl_log.append(self.total_pl)\n",
        "        self.action_log.append(log)\n",
        "        self.holding_log.append(self.holding_side + ' @' + str(self.holding_price) + ' x' + str(self.holding_size))\n",
        "        if len(self.order_i) > 0:\n",
        "            k = self.order_serial_list[-1]\n",
        "            self.order_log.append(self.order_side[k] + ' @' + str(self.order_price[k]) + ' x' + str(self.order_size[k]) + ' cancel=' + str(self.order_cancel[k]) + ' type=' + self.order_type[k])\n",
        "        else:\n",
        "            self.order_log.append('' + ' @' + '0' + ' x' + '0' + ' cancel=' + 'False' + ' type=' + '')\n",
        "        self.i_log.append(i)\n",
        "        self.dt_log.append(dt)\n",
        "        if len(self.order_serial_list) > 0: \n",
        "            k=self.order_serial_list[-1]\n",
        "            #print('i={}, dt={}, action={}, holding side={}, holding price={}, holding size={}, order side={}, order price={}, order size={}, pl={}, num_trade={}'\n",
        "            #.format(i, dt, log, self.holding_side, self.holding_price, self.holding_size, self.order_side[k], self.order_price[k], self.order_size[k], self.total_pl, self.num_trade))\n",
        "            self.log_data_list.append({'i':i, 'dt':dt, 'action':log, 'holding_side':self.holding_side,'holding_price':self.holding_price, 'holding_size':self.holding_size, 'order_side':self.order_side[k], 'order_price':self.order_price[k],\n",
        "                                       'order_size':self.order_size[k], 'total_pl':self.total_pl, 'total_fee':self.total_fee, 'num_trade':self.num_trade})\n",
        "        else:\n",
        "            #print(';i={}, dt={}, action={}, holding side={}, holding price={}, holding size={}, order side={}, order price={}, order size={}, pl={}, num_trade={}'.format(i, dt, log, self.holding_side, self.holding_price, self.holding_size, '', '0', '0', self.total_pl, self.num_trade))\n",
        "            self.log_data_list.append({'i':i, 'dt':dt, 'action':log, 'holding_side':self.holding_side, 'holding_price':self.holding_price, 'holding_size':self.holding_size, 'order_side':0, 'order_price':0, \n",
        "                                       'order_size':0, 'total_pl':self.total_pl, 'total_fee':self.total_fee, 'num_trade':self.num_trade})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihnPOiMnvMPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class Strategy:\n",
        "    @classmethod\n",
        "    def model_prediction_onemin(cls, start_ind, prediction, pt_ratio, lc_ratio, i, ac, flg_only_large, kyuhen_period, kyuhen_kijun):\n",
        "        dd = DecisionData()\n",
        "        omd = OneMinMarketData\n",
        "        pred_side ={0:'buy_large', 1:'buy_small', 2:'sell_large', 3:'sell_small', -1:'no'}[prediction[i]]\n",
        "\n",
        "        if kyuhen_period > 0 and kyuhen_kijun > 0: #check kyuhen\n",
        "            if abs((omd.ohlc.close[i + start_ind] - omd.ohlc.close[i + start_ind - kyuhen_period]) / omd.ohlc.close[i + start_ind - kyuhen_period]) >= kyuhen_kijun:\n",
        "                kyuhen_side = 'buy' if (omd.ohlc.close[i + start_ind] - omd.ohlc.close[i + start_ind - kyuhen_period]) > 0 else 'sell'\n",
        "                if ac.holding_side != kyuhen_side:\n",
        "                    dd.set_decision(kyuhen_side, 0, cls.__calc_opt_size(omd.ohlc.open[start_ind + i], ac) + ac.holding_size, omd.ohlc.close[start_ind + i] * pt_ratio , omd.ohlc.close[start_ind + i] * lc_ratio, 'market', False, 10)\n",
        "        else:\n",
        "            if flg_only_large:\n",
        "                if ac.holding_side != 'buy' and pred_side == 'buy_large':\n",
        "                    dd.set_decision('buy', 0, cls.__calc_opt_size(omd.ohlc.open[start_ind + i], ac) + ac.holding_size, omd.ohlc.close[start_ind + i] * pt_ratio , omd.ohlc.close[start_ind + i] * lc_ratio, 'market', False, 10)\n",
        "                elif ac.holding_side != 'sell' and pred_side == 'sell_large':\n",
        "                    dd.set_decision('sell', 0, cls.__calc_opt_size(omd.ohlc.open[start_ind + i], ac) + ac.holding_size, omd.ohlc.close[start_ind + i] * pt_ratio , omd.ohlc.close[start_ind + i] * lc_ratio, 'market', False, 10)\n",
        "            else:\n",
        "                if ac.holding_side != 'buy' and (pred_side == 'buy_large' or pred_side == 'buy_small'):\n",
        "                    dd.set_decision('buy', 0, cls.__calc_opt_size(omd.ohlc.open[start_ind + i], ac) + ac.holding_size, omd.ohlc.close[start_ind + i] * pt_ratio , omd.ohlc.close[start_ind + i] * lc_ratio, 'market', False, 10)\n",
        "                elif ac.holding_side != 'sell' and (pred_side == 'sell_large' or pred_side == 'sell_small'):\n",
        "                    dd.set_decision('sell', 0, cls.__calc_opt_size(omd.ohlc.open[start_ind + i], ac) + ac.holding_size, omd.ohlc.close[start_ind + i] * pt_ratio , omd.ohlc.close[start_ind + i] * lc_ratio, 'market', False, 10)\n",
        "        return dd\n",
        "    \n",
        "    @classmethod\n",
        "    def model_prediction_onemin_limit_entry(cls, start_ind, prediction, pt_ratio, lc_ratio, i, ac):\n",
        "        dd = DecisionData()\n",
        "        omd = OneMinMarketData\n",
        "        pred_side ={0: 'no', 1: 'buy', 2: 'sell', 3: 'both'}[prediction[i]]\n",
        "\n",
        "        if ac.holding_side != pred_side:\n",
        "            if ac.holding_side == '' and (pred_side == 'buy' or pred_side == 'sell') and len(ac.order_side) ==0:  # no position no order\n",
        "                dd.set_decision(pred_side, 0, cls.__calc_opt_size(OneMinMarketData.ohlc.open[start_ind + i], ac), omd.ohlc.close[i] * pt_ratio , omd.ohlc.close[i] * lc_ratio, 'limit', False, 10)\n",
        "            elif (ac.holding_side == 'buy' or ac.holding_side == 'sell') and (pred_side == 'buy' or pred_side == 'sell') and ac.holding_side != pred_side and len(ac.order_side) == 0:\n",
        "                dd.set_decision(pred_side, 0,ac.holding_size + cls.__calc_opt_size(OneMinMarketData.ohlc.open[start_ind + i], ac),omd.ohlc.close[i] * pt_ratio , omd.ohlc.close[i] * lc_ratio, 'limit', False, 10)  # exit and re-entry\n",
        "        return dd\n",
        "\n",
        "    \n",
        "    @classmethod\n",
        "    def model_prediction_opt(cls, time_exit, zero_three_exit_loss, zero_three_exit_profit, stdata, i, ac: SimAccount):\n",
        "        dd = DecisionData()\n",
        "        pred_side ={0: 'no', 1: 'buy', 2: 'sell', 3: 'both'}[stdata.prediction[i]]\n",
        "        if ac.holding_side == '' and ac.order_side == '' and (pred_side == 'buy' or pred_side == 'sell'):  # no position no order\n",
        "            dd.set_decision(pred_side, 0, cls.__calc_opt_size(stdata.price[i], ac), 'market', False, 10)\n",
        "        elif (ac.holding_side == 'buy' or ac.holding_side == 'sell') and (pred_side == 'buy' or pred_side == 'sell') and \\\n",
        "                ac.holding_side != pred_side and ac.order_side != '' and ac.order_side != ac.holding_side and ac.order_type == 'limit':  # holding side != pred side and pl ordering -> cancel pl order\n",
        "            dd.set_decision(pred_side, 0, 0, '', True, 10)  # cancel order\n",
        "        elif (ac.holding_side == 'buy' or ac.holding_side == 'sell') and (pred_side == 'buy' or pred_side == 'sell') and ac.holding_side != pred_side and ac.order_side == '':\n",
        "            dd.set_decision(pred_side, 0, ac.holding_size + cls.__calc_opt_size(stdata.price[i], ac), 'market', False, 10)  # exit and re-entry\n",
        "        elif time_exit >= 60 and ac.holding_side != '' and (stdata.ut[i] - ac.holding_ut) >= time_exit and (pred_side =='no' or pred_side =='both'):\n",
        "            if ac.order_side != '':\n",
        "                dd.set_decision(pred_side, 0, 0, '', True, 10)  # cancel order\n",
        "            else:\n",
        "                dd.set_decision('buy' if ac.holding_side == 'sell' else 'sell', 0, ac.holding_size, 'market', False, 10)\n",
        "        elif zero_three_exit_loss and ac.holding_side != '' and ac.current_pl < 0 and (pred_side =='no' or pred_side =='both'):\n",
        "            if ac.order_side != '':\n",
        "                dd.set_decision(pred_side, 0, 0, '', True, 10)  # cancel order\n",
        "            else:\n",
        "                dd.set_decision('buy' if ac.holding_side == 'sell' else 'sell', 0, ac.holding_size, 'market', False, 10)\n",
        "        elif zero_three_exit_profit and ac.holding_side != '' and ac.current_pl > 0 and (pred_side =='no' or pred_side =='both'):\n",
        "            if ac.order_side != '':\n",
        "                dd.set_decision(pred_side, 0, 0, '', True, 10)  # cancel order\n",
        "            else:\n",
        "                dd.set_decision('buy' if ac.holding_side == 'sell' else 'sell', 0, ac.holding_size, 'market', False, 10)\n",
        "        return dd\n",
        "            \n",
        "            \n",
        "    @classmethod\n",
        "    def __calc_opt_size(cls, price, ac):\n",
        "        return 0.01\n",
        "#        return round((ac.asset * ac.leverage) / (price * 1.0 * ac.base_margin_rate), 2)\n",
        "\n",
        "class DecisionData:\n",
        "    def __init__(self):\n",
        "        self.side = ''\n",
        "        self.size = 0\n",
        "        self.price = 0\n",
        "        self.type = 0\n",
        "        self.cancel = False\n",
        "        self.expire = 0  #sec\n",
        "        self.pt = 0\n",
        "        self.lc = 0\n",
        "\n",
        "    def set_decision(self, side, price, size, pt, lc, type, cancel, expire):\n",
        "        self.side = side\n",
        "        self.price = price\n",
        "        self.size = size\n",
        "        self.type = type\n",
        "        self.cancel = cancel\n",
        "        self.expire = expire\n",
        "        self.pt = pt\n",
        "        self.lc= lc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RMw6VsQITmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class StrategyAction:\n",
        "    @classmethod\n",
        "    def model_prediction_onemin(cls, start_ind, i, prediction, amount, pt_ratio, lc_ratio, ac):\n",
        "        ad = ActionData()\n",
        "        omd = OneMinMarketData\n",
        "        pred_side = {0: 'no', 1:'buy', 2:'sell', 3:'both'}[prediction[i]]\n",
        "        pt_price = int(round(omd.ohlc.close[start_ind + i] * (1+pt_ratio))) if pred_side == 'buy' else int(round(omd.ohlc.close[start_ind + i] * (1-pt_ratio)))\n",
        "        lc_price = int(round(omd.ohlc.close[start_ind + i] * (1-lc_ratio))) if pred_side == 'buy' else int(round(omd.ohlc.close[start_ind + i] * (1+lc_ratio)))\n",
        "\n",
        "        if pred_side == 'buy' or pred_side == 'sell':\n",
        "            if ac.holding_side == '' and len(ac.order_side) ==0: #no holding and no orders\n",
        "                ad.add_action('entry', pred_side, omd.ohlc.close[start_ind + i], amount, 'limit', pt_price, lc_price, 'new entry')\n",
        "            elif ac.holding_side == '' and len(ac.order_side) > 0 and pred_side not in list(ac.order_side.values()): #no holding, opposite existing order\n",
        "                ad.add_action('cancel', '',0,0,'',0,0,'cancel order')\n",
        "                ad.add_action('entry', pred_side, omd.ohlc.close[start_ind + i], amount, 'limit', pt_price, lc_price, 'new entry')\n",
        "            elif ac.holding_side != '' and ac.holding_side != pred_side and len(ac.order_side) > 0 and pred_side not in list(ac.order_side.values()): #opposite holding, opposite existing order\n",
        "                ad.add_action('cancel', '',0,0,'',0,0,'cancel order')\n",
        "                ad.add_action('entry', pred_side, omd.ohlc.close[start_ind + i], ac.holding_size + amount, 'limit', pt_price, lc_price, 'exit & entry')\n",
        "            else:\n",
        "                pass\n",
        "        else:\n",
        "            pass\n",
        "        return ad\n",
        "\n",
        "\n",
        "\n",
        "class ActionData:\n",
        "    def __init__(self):\n",
        "        self.action = []\n",
        "        self.order_side = []\n",
        "        self.order_price = []\n",
        "        self.order_size = []\n",
        "        self.order_type = []\n",
        "        self.pt_price = []\n",
        "        self.lc_price = []\n",
        "        self.message = []\n",
        "    \n",
        "    def add_action(self, action ,order_side, order_price, order_size, order_type, pt_price, lc_price, message):\n",
        "        self.action.append(action)\n",
        "        self.order_side.append(order_side)\n",
        "        self.order_price.append(order_price)\n",
        "        self.order_size.append(order_size)\n",
        "        self.order_type.append(order_type)\n",
        "        self.pt_price.append(pt_price)\n",
        "        self.lc_price.append(lc_price)\n",
        "        self.message.append(message)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufPKubF8OaZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimAction:\n",
        "    @classmethod\n",
        "    def sim_model_pred_onemin(cls, start_ind, prediction, pt_ratio, lc_ratio, ac, last_day):\n",
        "        omd = OneMinMarketData\n",
        "        for i in range(len(prediction) - 1):\n",
        "            ac.check_executions(i, omd.ohlc.dt[start_ind + i], omd.ohlc.open[start_ind + i], omd.ohlc.high[start_ind + i], omd.ohlc.low[start_ind + i])\n",
        "            dd = Strategy.model_prediction_onemin(start_ind, prediction, pt_ratio, lc_ratio, i, ac)\n",
        "            if dd.side != '':\n",
        "                ac.entry_order(dd.side, dd.price, dd.size, dd.type, dd.expire, dd.pt, dd.lc, i, omd.ohlc.dt[start_ind + i])\n",
        "            ac.move_to_next(i, omd.ohlc.dt[start_ind + i], omd.ohlc.open[start_ind + i],omd.ohlc.high[start_ind + i], omd.ohlc.low[start_ind + i],omd.ohlc.close[start_ind + i])\n",
        "        end_i = len(prediction) - 1\n",
        "        if last_day:\n",
        "            ac.last_day_operation(end_i, omd.ohlc.dt[start_ind + end_i], omd.ohlc.open[start_ind + end_i],omd.ohlc.high[start_ind + end_i], omd.ohlc.low[start_ind + end_i], omd.ohlc.close[start_ind + end_i])\n",
        "        else:\n",
        "            ac.move_to_next(i, omd.ohlc.dt[start_ind + end_i], omd.ohlc.open[start_ind + end_i], omd.ohlc.high[start_ind + end_i], omd.ohlc.low[start_ind + end_i],omd.ohlc.close[start_ind + end_i])\n",
        "        return ac"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfHbbL3EvOV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "'''\n",
        "class Sim:\n",
        "    @classmethod\n",
        "    def sim_model_pred(cls, start_ind, bp, sp, pt, lc, ac):\n",
        "        end_i = len(bp)\n",
        "        for i in range(len(bp)-1):\n",
        "            dd = Strategy.model_prediction(start_ind,bp,sp,i,ac)\n",
        "            if dd.side != '':\n",
        "                ac.entry_order(dd.side, dd.price, dd.size, dd.type, dd.expire, 0, 0, i, OneMinMarketData.ohlc.dt[start_ind + i])\n",
        "            ac.move_to_next(i, OneMinMarketData.ohlc.dt[start_ind + i], OneMinMarketData.ohlc.open[start_ind + i], OneMinMarketData.ohlc.high[start_ind + i], OneMinMarketData.ohlc.low[start_ind + i],OneMinMarketData.ohlc.close[start_ind + i])\n",
        "        ac.last_day_operation(end_i, omd.ohlc.dt[start_ind + end_i], OneMinMarketData.ohlc.open[start_ind + end_i], OneMinMarketData.ohlc.high[start_ind + end_i], OneMinMarketData.ohlc.low[start_ind + end_i], OneMinMarketData.ohlc.close[start_ind + end_i])\n",
        "        return ac\n",
        "    \n",
        "    \n",
        "    @classmethod\n",
        "    def sim_model_pred_onemin(cls, start_ind, prediction, pt_ratio, lc_ratio, ac, last_day, flg_only_large, kyuhen_period, kyuhen_kijun):\n",
        "        omd = OneMinMarketData\n",
        "        for i in range(len(prediction) - 1):\n",
        "            ac.check_executions(i, omd.ohlc.dt[start_ind + i], omd.ohlc.open[start_ind + i], omd.ohlc.high[start_ind + i], omd.ohlc.low[start_ind + i])\n",
        "            dd = Strategy.model_prediction_onemin(start_ind, prediction, pt_ratio, lc_ratio, i, ac, flg_only_large, kyuhen_period, kyuhen_kijun)\n",
        "            if dd.side != '':\n",
        "                ac.entry_order(dd.side, dd.price, dd.size, dd.type, dd.expire, dd.pt, dd.lc, i, omd.ohlc.dt[start_ind + i])\n",
        "            ac.move_to_next(i, omd.ohlc.dt[start_ind + i], omd.ohlc.open[start_ind + i],omd.ohlc.high[start_ind + i], omd.ohlc.low[start_ind + i],omd.ohlc.close[start_ind + i])\n",
        "        end_i = len(prediction) - 1\n",
        "        if last_day:\n",
        "            ac.last_day_operation(end_i, omd.ohlc.dt[start_ind + end_i], omd.ohlc.open[start_ind + end_i],omd.ohlc.high[start_ind + end_i], omd.ohlc.low[start_ind + end_i], omd.ohlc.close[start_ind + end_i])\n",
        "        else:\n",
        "            ac.move_to_next(i, omd.ohlc.dt[start_ind + end_i], omd.ohlc.open[start_ind + end_i], omd.ohlc.high[start_ind + end_i], omd.ohlc.low[start_ind + end_i],omd.ohlc.close[start_ind + end_i])\n",
        "        return ac\n",
        "\n",
        "    \n",
        "    '''\n",
        "    limit entryする -> ok\n",
        "    limit entryして約定する前にpredが変わった。buy/sell -> sell/buy (今のlimit entry orderをcancelして、sell side limit order)、cancel完了後に1loop経過しているので、その時点のpredはbuy/sellでは無くなっていることがあるため、statusを返す仕様に変更しないといけない。\n",
        "    '''\n",
        "    @classmethod\n",
        "    def sim_model_pred_onemin_limit_entry(cls, start_ind, prediction, pt_ratio, lc_ratio, ac, last_day):\n",
        "        omd = OneMinMarketData\n",
        "        for i in range(len(prediction) - 1):\n",
        "            ac.check_executions(i, omd.ohlc.dt[start_ind + i], omd.ohlc.open[start_ind + i], omd.ohlc.high[start_ind + i], omd.ohlc.low[start_ind + i])\n",
        "            dd = Strategy.model_prediction_onemin(start_ind, prediction, pt_ratio, lc_ratio, i, ac)\n",
        "            if dd.side != '':\n",
        "                ac.entry_order(dd.side, dd.price, dd.size, dd.type, dd.expire, dd.pt, dd.lc, i, omd.ohlc.dt[start_ind + i])\n",
        "            ac.move_to_next(i, omd.ohlc.dt[start_ind + i], omd.ohlc.open[start_ind + i],omd.ohlc.high[start_ind + i], omd.ohlc.low[start_ind + i],omd.ohlc.close[start_ind + i])\n",
        "        end_i = len(prediction) - 1\n",
        "        if last_day:\n",
        "            ac.last_day_operation(end_i, omd.ohlc.dt[start_ind + end_i], omd.ohlc.open[start_ind + end_i],omd.ohlc.high[start_ind + end_i], omd.ohlc.low[start_ind + end_i],\n",
        "                                omd.ohlc.close[start_ind + end_i])\n",
        "        else:\n",
        "            ac.move_to_next(i, omd.ohlc.dt[start_ind + end_i], omd.ohlc.open[start_ind + end_i], omd.ohlc.high[start_ind + end_i], omd.ohlc.low[start_ind + end_i],omd.ohlc.close[start_ind + end_i])\n",
        "        return ac\n",
        "\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def sim_model_pred_onemin_avert(cls, start_ind, prediction, pt_ratio, lc_ratio, ac, ac2, avert_period_kijun, avert_val_kijun, last_day, flg_only_large, kyuhen_period, kyuhen_kijun):\n",
        "        omd = OneMinMarketData\n",
        "        for i in range(len(prediction) - 1):\n",
        "            ac.check_executions(i, omd.ohlc.dt[start_ind + i], omd.ohlc.open[start_ind + i], omd.ohlc.high[start_ind + i], omd.ohlc.low[start_ind + i])\n",
        "            ac2.check_executions(i, omd.ohlc.dt[start_ind + i], omd.ohlc.open[start_ind + i], omd.ohlc.high[start_ind + i], omd.ohlc.low[start_ind + i])\n",
        "            dd2 = Strategy.model_prediction_onemin(start_ind, prediction, pt_ratio, lc_ratio, i, ac2, flg_only_large, kyuhen_period, kyuhen_kijun)\n",
        "            dd = Strategy.model_prediction_onemin(start_ind, prediction, pt_ratio, lc_ratio, i, ac, flg_only_large, kyuhen_period, kyuhen_kijun)\n",
        "            if dd2.side == 'no' or dd2.side == 'both':\n",
        "                print('invalid dd2side!')\n",
        "                print(dd2.side)\n",
        "            if ac.holding_size > 0.01:\n",
        "                print('large holding!', ac.holding_size)\n",
        "            if dd2.side != '':\n",
        "                ac2.entry_order(dd2.side, dd2.price, dd2.size, dd2.type, dd2.expire, dd.pt, dd.lc, i, omd.ohlc.dt[start_ind + i]) #ac2は常にトレード\n",
        "            if len(ac2.performance_total_pl_log) > avert_period_kijun: #pl_check_term以上のpl logが溜まったらcheckを開始\n",
        "                #if ac2.performance_total_pl_log[-1] - ac2.performance_total_pl_log[-pl_check_term] > 0: #check pl of ac2\n",
        "                if np.gradient(ta.MA(np.array(ac2.performance_total_pl_log[-avert_period_kijun:], dtype='f8'), timeperiod=avert_period_kijun))[-1] > avert_val_kijun:\n",
        "                    if dd2.side != '':\n",
        "                        if dd2.side != ac.holding_side and ac.holding_side != '':#ac2と同じポジションを取る\n",
        "                            ac.entry_order('buy' if ac.holding_side=='sell' else 'sell', 0, 0.02, 'market', 10, dd.pt, dd.lc, i, omd.ohlc.dt[start_ind + i])\n",
        "                        elif dd2.side != ac.holding_side and ac.holding_side == '':#ac2と同じポジションを取る\n",
        "                            ac.entry_order(dd2.side, 0, 0.01, 'market', 10, dd.pt, dd.lc, i, omd.ohlc.dt[start_ind + i])\n",
        "                        else: #ac2のddと同じときは何もしない\n",
        "                            pass\n",
        "                    else: #\n",
        "                        pass\n",
        "                        #if ac.holding_side != '': #ac2に合わせるためにexit all\n",
        "                        #    ac.entry_order('buy' if ac.holding_side=='sell' else 'sell', 0, 0.01, 'market', 10, pt, lc, i, omd.ohlc.dt[start_ind + i])\n",
        "                else: #ac2のpl_check_termにおけるplがマイナスの時はacでのトレードを停止\n",
        "                    if ac.holding_side != '':\n",
        "                        ac.entry_order('buy' if ac.holding_side=='sell' else 'sell', 0, 0.01, 'market', 10, dd.pt, dd.lc, i, omd.ohlc.dt[start_ind + i])\n",
        "            else:#logがたまるまでは普通にトレード\n",
        "                if dd.side != '':\n",
        "                    ac.entry_order(dd.side, dd.price, dd.size, dd.type, dd.expire, dd.pt, dd.lc, i, omd.ohlc.dt[start_ind + i])\n",
        "            ac.move_to_next(i, omd.ohlc.dt[start_ind + i], omd.ohlc.open[start_ind + i],omd.ohlc.high[start_ind + i], omd.ohlc.low[start_ind + i],omd.ohlc.close[start_ind + i])\n",
        "            ac2.move_to_next(i, omd.ohlc.dt[start_ind + i], omd.ohlc.open[start_ind + i],omd.ohlc.high[start_ind + i], omd.ohlc.low[start_ind + i],omd.ohlc.close[start_ind + i])\n",
        "        end_i = len(prediction) - 1\n",
        "        if last_day:\n",
        "            ac.last_day_operation(end_i, omd.ohlc.dt[start_ind + end_i], omd.ohlc.open[start_ind + end_i],omd.ohlc.high[start_ind + end_i], omd.ohlc.low[start_ind + end_i],omd.ohlc.close[start_ind + end_i])\n",
        "        else:\n",
        "            ac.move_to_next(i, omd.ohlc.dt[start_ind + end_i], omd.ohlc.open[start_ind + end_i], omd.ohlc.high[start_ind + end_i], omd.ohlc.low[start_ind + end_i],omd.ohlc.close[start_ind + end_i])\n",
        "        return ac\n",
        "    \n",
        "    @classmethod\n",
        "    def sim_lgbmodel(cls, stdata, pl_kijun, ac):\n",
        "        print('sim length:'+str(stdata.dt[0]) + str(stdata.dt[-1]))\n",
        "        for i in range(len(stdata.prediction)-1):\n",
        "            dd = Strategy.model_prediction(pl_kijun, stdata,i,ac)\n",
        "            if dd.cancel:\n",
        "                ac.cancel_order(i, stdata.dt[i],stdata.ut[i])\n",
        "            elif dd.side != '':\n",
        "                ac.entry_order(dd.side,dd.price,dd.size,dd.type,dd.expire,i,stdata.dt[i],stdata.ut[i],stdata.price[i])\n",
        "            ac.move_to_next(i,stdata.dt[i],stdata.ut[i],stdata.price[i])\n",
        "        ac.last_day_operation(len(stdata.prediction)-1,stdata.dt[len(stdata.prediction)-1],stdata.ut[len(stdata.prediction)-1],stdata.price[len(stdata.prediction)-1])\n",
        "        return ac\n",
        "    \n",
        "    \n",
        "    @classmethod\n",
        "    def sim_bp(cls, stdata, pl, ls, ac):\n",
        "        print('sim length:'+str(stdata.dt[0]) + str(stdata.dt[-1]))\n",
        "        for i in range(len(stdata.prediction)-1):\n",
        "            dd = Strategy.model_bp_prediction(pl, ls, stdata,i,ac)\n",
        "            if dd.side != '':\n",
        "                ac.entry_order(dd.side,dd.price,dd.size,dd.type,dd.expire,pl,ls,i,stdata.dt[i],stdata.ut[i],stdata.price[i]) #ntry_order(self, side, price, size, type, expire, pl, ls, i, dt, ut, tick_price):\n",
        "            ac.move_to_next(i,stdata.dt[i],stdata.ut[i],stdata.price[i])\n",
        "        ac.last_day_operation(len(stdata.prediction)-1,stdata.dt[len(stdata.prediction)-1],stdata.ut[len(stdata.prediction)-1],stdata.price[len(stdata.prediction)-1])\n",
        "        return ac\n",
        "    \n",
        "    @classmethod\n",
        "    def sim_sp(cls, stdata, pl, ls, ac):\n",
        "        print('sim length:'+str(stdata.dt[0]) + str(stdata.dt[-1]))\n",
        "        for i in range(len(stdata.prediction)-1):\n",
        "            dd = Strategy.model_sp_prediction(pl, ls, stdata,i,ac)\n",
        "            if dd.side != '':\n",
        "                ac.entry_order(dd.side,dd.price,dd.size,dd.type,dd.expire,pl,ls,i,stdata.dt[i],stdata.ut[i],stdata.price[i]) #ntry_order(self, side, price, size, type, expire, pl, ls, i, dt, ut, tick_price):\n",
        "            ac.move_to_next(i,stdata.dt[i],stdata.ut[i],stdata.price[i])\n",
        "        ac.last_day_operation(len(stdata.prediction)-1,stdata.dt[len(stdata.prediction)-1],stdata.ut[len(stdata.prediction)-1],stdata.price[len(stdata.prediction)-1])\n",
        "        return ac\n",
        "    \n",
        "    @classmethod\n",
        "    def sim_buysell(cls, stdata, pl, ls, ac):\n",
        "        print('sim length:'+str(stdata.dt[0]) + str(stdata.dt[-1]))\n",
        "        one_min_checker = 1\n",
        "        for i in range(len(stdata.prediction)-1):\n",
        "            if ac.suspension_flg  == False:\n",
        "                dd = Strategy.model_buysell_prediction(pl, ls, stdata, i, ac)\n",
        "                if dd.side != '':\n",
        "                    ac.entry_order(dd.side,dd.price,dd.size,dd.type,dd.expire,pl,ls,i,stdata.dt[i],stdata.ut[i],stdata.price[i]) #ntry_order(self, side, price, size, type, expire, pl, ls, i, dt, ut, tick_price):\n",
        "            if i > one_min_checker * 60:\n",
        "                one_min_checker += 1\n",
        "                ac.suspension_flg = False\n",
        "            ac.move_to_next(i,stdata.dt[i],stdata.ut[i],stdata.price[i])\n",
        "        ac.last_day_operation(len(stdata.prediction)-1,stdata.dt[len(stdata.prediction)-1],stdata.ut[len(stdata.prediction)-1],stdata.price[len(stdata.prediction)-1])\n",
        "        return ac\n",
        "    \n",
        "    \n",
        "    @classmethod\n",
        "    def sim_lgbmodel_opt(cls, stdata, pl, losscut, time_exit, zero_three_exit_loss, zero_three_exit_profit, ac:SimAccount):\n",
        "        print('sim length:' + str(stdata.dt[0]) + str(stdata.dt[-1]))\n",
        "        one_min_checker = 1\n",
        "        for i in range(len(stdata.prediction) -1):\n",
        "            if ac.suspension_flg  == False:\n",
        "                dd =Strategy.model_prediction_opt(time_exit, zero_three_exit_loss, zero_three_exit_profit, stdata, i, ac)\n",
        "                if dd.cancel:\n",
        "                    ac.cancel_order(i, stdata.dt[i], stdata.ut[i])\n",
        "                elif dd.side != '':\n",
        "                    ac.entry_order(dd.side,dd.price,dd.size,dd.type,dd.expire, pl, losscut, i, stdata.dt[i], stdata.ut[i], stdata.price[i])\n",
        "            if i > one_min_checker * 60:\n",
        "                one_min_checker += 1\n",
        "                ac.suspension_flg = False\n",
        "            ac.move_to_next(i, stdata.dt[i], stdata.ut[i], stdata.price[i])\n",
        "        ac.last_day_operation(len(stdata.prediction) - 1, stdata.dt[len(stdata.prediction) - 1],stdata.ut[len(stdata.prediction) - 1], stdata.price[len(stdata.prediction) - 1])\n",
        "        return ac\n",
        "    \n",
        "    @classmethod\n",
        "    def sim_ema_trend_follow(cls, stdata, ac):\n",
        "        print('sim length:'+str(stdata.dt[0]) + str(stdata.dt[-1]))\n",
        "        for i in range(len(stdata.prediction)-1):\n",
        "            dd = Strategy.ema_trend_follow(stdata,i,ac)\n",
        "            if dd.side != '':\n",
        "                ac.entry_order(dd.side,dd.price,dd.size,dd.type,dd.expire,i,stdata.dt[i],stdata.ut[i],stdata.price[i])\n",
        "            ac.move_to_next(i,stdata.dt[i],stdata.ut[i],stdata.price[i])\n",
        "        ac.last_day_operation(len(stdata.prediction)-1,stdata.dt[len(stdata.prediction)-1],stdata.ut[len(stdata.prediction)-1],stdata.price[len(stdata.prediction)-1])\n",
        "        return ac\n",
        "    \n",
        "    \n",
        "    @classmethod\n",
        "    def sim_ema_trend_contrarian(cls, stdata, ac):\n",
        "        print('sim length:'+str(stdata.dt[0]) + str(stdata.dt[-1]))\n",
        "        for i in range(len(stdata.prediction)-1):\n",
        "            dd = Strategy.ema_trend_contrarian(stdata,i,ac)\n",
        "            if dd.side != '':\n",
        "                ac.entry_order(dd.side,dd.price,dd.size,dd.type,dd.expire,i,stdata.dt[i],stdata.ut[i],stdata.price[i])\n",
        "            ac.move_to_next(i,stdata.dt[i],stdata.ut[i],stdata.price[i])\n",
        "        ac.last_day_operation(len(stdata.prediction)-1,stdata.dt[len(stdata.prediction)-1],stdata.ut[len(stdata.prediction)-1],stdata.price[len(stdata.prediction)-1])\n",
        "        return ac\n",
        "    \n",
        "    @classmethod\n",
        "    def sim_ema_tftc_switch(cls, stdata, ac, pl_sma_term):\n",
        "        print('sim length:'+str(stdata.dt[0]) + str(stdata.dt[-1]))\n",
        "        tf_ac = SimAccount()\n",
        "        tc_ac = SimAccount()\n",
        "        tf_pl_sma = []\n",
        "        tc_pl_sma = []\n",
        "        tf_pl_sum = 0\n",
        "        tc_pl_sum = 0\n",
        "        sim_min_count = 60\n",
        "        switch_flg = 0 #0:tf, 1:tc\n",
        "        for i in range(len(stdata.prediction)-1):\n",
        "            #sim for tf\n",
        "            dd = Strategy.ema_trend_follow(stdata,i,tf_ac)\n",
        "            if dd.side != '':\n",
        "                tf_ac.entry_order(dd.side,dd.price,dd.size,dd.type,dd.expire,i,stdata.dt[i],stdata.ut[i],stdata.price[i])\n",
        "            tf_ac.move_to_next(i,stdata.dt[i],stdata.ut[i],stdata.price[i])\n",
        "            #sim for tc\n",
        "            dd = Strategy.ema_trend_contrarian(stdata,i,tc_ac)\n",
        "            if dd.side != '':\n",
        "                tc_ac.entry_order(dd.side,dd.price,dd.size,dd.type,dd.expire,i,stdata.dt[i],stdata.ut[i],stdata.price[i])\n",
        "            tc_ac.move_to_next(i,stdata.dt[i],stdata.ut[i],stdata.price[i])\n",
        "        return ac"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn3BrnKRvQat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import lightgbm as lgb\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from numba import jit\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class LgbModel:\n",
        "    def load_model(self):\n",
        "        with open('/content/drive/My Drive/Model/lgb_bpsp_model.dat', mode='rb') as f:\n",
        "            self.model = pickle.load(f)\n",
        "\n",
        "    def check_train_test_index_duplication(self, train_x, test_x):\n",
        "        train_list = list(train_x.index.values)\n",
        "        test_list = list(test_x.index.values)\n",
        "        dupli = set(train_list) & set(test_list)\n",
        "        if len(dupli) > 0:\n",
        "            print('Index duplication in train and test df was found!')\n",
        "            print(dupli)\n",
        "\n",
        "    def generate_bpsp_data(self, train_df_lgb, test_df_lgb, opt_len, valid_size, rs, display=False):\n",
        "        train_df_lgb['future_side'] = train_df_lgb['future_side'].map({'buy_large': 0, 'buy_small': 1, 'sell_large': 2, 'sell_small': 3}).astype(int)\n",
        "        test_df_lgb['future_side'] = test_df_lgb['future_side'].map({'buy_large': 0, 'buy_small': 1, 'sell_large': 2, 'sell_small': 3}).astype(int)\n",
        "        if display:\n",
        "            print('train / valid period=', train_df_lgb['dt'].iloc[0], ' - ', train_df_lgb['dt'].iloc[-opt_len])\n",
        "            print('opt period=', train_df_lgb['dt'].iloc[-opt_len], ' - ', train_df_lgb['dt'].iloc[-1])\n",
        "            print('test period=', test_df_lgb['dt'].iloc[0], ' - ', test_df_lgb['dt'].iloc[-1])\n",
        "\n",
        "        cols = list(train_df_lgb.columns)\n",
        "        remove_cols = ['open', 'high', 'low', 'close', 'open_change', 'high_change' , 'low_change', 'close_change', 'dt', 'size']\n",
        "        for col in remove_cols:\n",
        "            if col in cols:\n",
        "                cols.remove(col)\n",
        "        cols.sort()\n",
        "        \n",
        "        train_df_lgb = train_df_lgb.loc[:,cols]\n",
        "        opt_df_lgb = train_df_lgb.iloc[-opt_len:]\n",
        "        train_df_lgb = train_df_lgb.iloc[:-opt_len]\n",
        "        test_df_lgb = test_df_lgb.loc[:,cols]\n",
        "\n",
        "        new_train_df = train_df_lgb.sample(frac=1, random_state = rs)\n",
        "        #train_x, valid_x = train_test_split(new_train_df.drop(['size', 'future_side'], axis=1), train_size=(1.0-valid_size), shuffle=False)\n",
        "        #y = new_train_df['future_side']\n",
        "        #y.columns = ['future_side']\n",
        "        #train_y, valid_y = train_test_split(y, train_size=(1.0-valid_size), shuffle=False)\n",
        "        train_ind = int(len(new_train_df) * (1.0-valid_size))\n",
        "        train_x = new_train_df.iloc[:train_ind].drop(['future_side'], axis=1)\n",
        "        train_y = new_train_df['future_side'].iloc[:train_ind]\n",
        "        train_y.columns = ['future_side']\n",
        "        valid_x = new_train_df.iloc[train_ind:].drop(['future_side'], axis=1)\n",
        "        valid_y = new_train_df['future_side'].iloc[train_ind:]\n",
        "        valid_y.columns = ['future_side']\n",
        "\n",
        "        opt_x = opt_df_lgb.drop(['future_side'], axis=1)\n",
        "        opt_y = opt_df_lgb['future_side']\n",
        "\n",
        "        test_x = test_df_lgb.drop(['future_side'], axis=1)\n",
        "        test_y = test_df_lgb['future_side']\n",
        "        test_y.columns = ['future_side']\n",
        "\n",
        "        self.check_train_test_index_duplication(train_x, test_x)\n",
        "        if display:\n",
        "            print('buy sell point data description:')\n",
        "            print('train_x', train_x.shape)\n",
        "            print('train_y', train_y.shape)\n",
        "            print('test_x', test_x.shape)\n",
        "            print('test_y', test_y.shape)\n",
        "            print('valid_x', valid_x.shape)\n",
        "            print('valid_y', valid_y.shape)\n",
        "            print('opt_x', opt_x.shape)\n",
        "            print('opt_y', opt_y.shape)\n",
        "        del train_df_lgb, test_df_lgb, new_train_df, opt_df_lgb, cols\n",
        "        return train_x, test_x, train_y, test_y, valid_x, valid_y, opt_x, opt_y\n",
        "\n",
        "\n",
        "    def generate_bpsp_data2(self, train_df_lgb, test_df_lgb, opt_len, valid_size=0.2, rs=None, display=False):\n",
        "        train_df_lgb['future_side'] = train_df_lgb['future_side'].map({'buy_large': 0, 'buy_small': 1, 'sell_large': 2, 'sell_small': 3}).astype(int)\n",
        "        test_df_lgb['future_side'] = test_df_lgb['future_side'].map({'buy_large': 0, 'buy_small': 1, 'sell_large': 2, 'sell_small': 3}).astype(int)\n",
        "        if display:\n",
        "            print('train / valid period=', train_df_lgb['dt'].iloc[0], ' - ', train_df_lgb['dt'].iloc[-opt_len])\n",
        "            print('opt period=', train_df_lgb['dt'].iloc[-opt_len], ' - ', train_df_lgb['dt'].iloc[-1])\n",
        "            print('test period=', test_df_lgb['dt'].iloc[0], ' - ', test_df_lgb['dt'].iloc[-1])\n",
        "\n",
        "        cols = list(train_df_lgb.columns)\n",
        "        remove_cols = ['open', 'high', 'low', 'close', 'open_change', 'high_change' , 'low_change', 'close_change', 'dt', 'size']\n",
        "        for col in remove_cols:\n",
        "            if col in cols:\n",
        "                cols.remove(col)\n",
        "        cols.sort()\n",
        "        \n",
        "        train_df_lgb = train_df_lgb.loc[:,cols]\n",
        "        opt_df_lgb = train_df_lgb.iloc[-opt_len:]\n",
        "        train_df_lgb = train_df_lgb.iloc[:-opt_len]\n",
        "        test_df_lgb = test_df_lgb.loc[:,cols]\n",
        "\n",
        "        # generate training data to include same num of buy / sell bpsp\n",
        "        buy_df = train_df_lgb[train_df_lgb.future_side == 1]\n",
        "        sell_df = train_df_lgb[train_df_lgb.future_side == 2]\n",
        "        no_df = train_df_lgb[train_df_lgb.future_side == 0]\n",
        "        both_df = train_df_lgb[train_df_lgb.future_side == 3]\n",
        "        max_data = max([len(buy_df), len(sell_df), len(no_df), len(both_df)])\n",
        "        new_train_df = pd.DataFrame()\n",
        "\n",
        "        if max_data > len(buy_df) and len(buy_df) > 0:\n",
        "            selected = buy_df.sample(n=max_data - len(buy_df), replace=True, random_state = rs)\n",
        "            new_train_df = new_train_df.append(selected)\n",
        "            new_train_df = new_train_df.append(buy_df)\n",
        "        elif len(buy_df) > 0:\n",
        "            new_train_df = buy_df\n",
        "        if max_data > len(sell_df)  and len(sell_df) > 0:\n",
        "            selected = sell_df.sample(n=max_data - len(sell_df), replace=True, random_state = rs)\n",
        "            new_train_df = new_train_df.append(selected)\n",
        "            new_train_df = new_train_df.append(sell_df)\n",
        "        elif len(sell_df) > 0:\n",
        "            new_train_df = new_train_df.append(sell_df)\n",
        "        if max_data > len(no_df) and len(no_df) > 0:\n",
        "            selected = no_df.sample(n=max_data - len(no_df), replace=True, random_state = rs)\n",
        "            new_train_df = new_train_df.append(selected)\n",
        "            new_train_df = new_train_df.append(no_df)\n",
        "        elif len(no_df) > 0:\n",
        "            new_train_df = new_train_df.append(no_df)\n",
        "        if max_data > len(both_df) and len(both_df) > 0:\n",
        "            selected = both_df.sample(n=max_data - len(both_df), replace=True, random_state = rs)\n",
        "            new_train_df = new_train_df.append(selected)\n",
        "        elif len(both_df) > 0:\n",
        "            new_train_df = new_train_df.append(both_df)\n",
        "            new_train_df = new_train_df.append(both_df)\n",
        "\n",
        "        new_train_df = new_train_df.sample(frac=1, random_state = rs)\n",
        "        #train_x, valid_x = train_test_split(new_train_df.drop(['size', 'future_side'], axis=1), train_size=(1.0-valid_size), shuffle=False)\n",
        "        #y = new_train_df['future_side']\n",
        "        #y.columns = ['future_side']\n",
        "        #train_y, valid_y = train_test_split(y, train_size=(1.0-valid_size), shuffle=False)\n",
        "        train_ind = int(len(new_train_df) * (1.0-valid_size))\n",
        "\n",
        "        train_x = new_train_df.iloc[:train_ind].drop(['future_side'], axis=1)\n",
        "        train_y = new_train_df['future_side'].iloc[:train_ind]\n",
        "        train_y.columns = ['future_side']\n",
        "        valid_x = new_train_df.iloc[train_ind:].drop(['future_side'], axis=1)\n",
        "        valid_y = new_train_df['future_side'].iloc[train_ind:]\n",
        "        valid_y.columns = ['future_side']\n",
        "\n",
        "        opt_x = opt_df_lgb.drop(['future_side'], axis=1)\n",
        "        opt_y = opt_df_lgb['future_side']\n",
        "\n",
        "        test_x = test_df_lgb.drop(['future_side'], axis=1)\n",
        "        test_y = test_df_lgb['future_side']\n",
        "        test_y.columns = ['future_side']\n",
        "\n",
        "        self.check_train_test_index_duplication(train_x, test_x)\n",
        "        if display:\n",
        "            print('buy sell point data description:')\n",
        "            print('train_x', train_x.shape)\n",
        "            print('train_y', train_y.shape)\n",
        "            print('test_x', test_x.shape)\n",
        "            print('test_y', test_y.shape)\n",
        "            print('valid_x', valid_x.shape)\n",
        "            print('valid_y', valid_y.shape)\n",
        "            print('opt_x', opt_x.shape)\n",
        "            print('opt_y', opt_y.shape)\n",
        "        del train_df_lgb, test_df_lgb, new_train_df, opt_df_lgb, buy_df, sell_df, no_df, both_df, cols\n",
        "        return train_x, test_x, train_y, test_y, valid_x, valid_y, opt_x, opt_y\n",
        "    \n",
        "    \n",
        "    def genrate_col_removed_data(self, train_x, test_x, valid_x, cols):\n",
        "        return train_x[cols], test_x[cols], valid_x[cols]\n",
        "    \n",
        "    \n",
        "    def generate_bsp_data_no_random(self, df:pd.DataFrame, side, train_size=0.6, valid_size = 0.2):\n",
        "        dfx = None\n",
        "        dfy = None\n",
        "        col_name ='bp' if side =='buy' else 'sp'\n",
        "        dfx = df.drop(['dt','size',col_name],axis = 1)\n",
        "        dfy = df[col_name]\n",
        "        dfy.columns = [col_name]\n",
        "        train_x, test_x, train_y, test_y = train_test_split(dfx, dfy, train_size=train_size, shuffle = False)\n",
        "        count_buy_in_train = train_y.values.sum()\n",
        "        non_buy_list = []\n",
        "        buy_list = []\n",
        "\n",
        "        for i in range(len(train_y)): #train_y = 0のdataをリスト化\n",
        "            if train_y.iloc[i] == 0:\n",
        "                non_buy_list.append(train_x.iloc[i])\n",
        "            elif train_y.iloc[i] == 1:\n",
        "                    buy_list.append(train_x.iloc[i])\n",
        "        if len(buy_list) != count_buy_in_train:\n",
        "            print('len(buy_list) is not matched with count_buy_in_train !!')\n",
        "        new_train_df = pd.DataFrame()\n",
        "        new_train_df = new_train_df.append(non_buy_list)\n",
        "        num = len(non_buy_list) // len(buy_list)\n",
        "        for i in range(num):\n",
        "            new_train_df = new_train_df.append(buy_list)\n",
        "        num = len(non_buy_list) % len(buy_list)\n",
        "        amari = int(round(len(buy_list) * num))\n",
        "        new_train_df = new_train_df.append(buy_list[:amari])\n",
        "        new_buy_points = [0] * len(non_buy_list)\n",
        "        new_buy_points.extend([1] *  (len(new_train_df) - len(non_buy_list)))\n",
        "        if side == 'buy':\n",
        "            new_train_df = new_train_df.assign(bp=new_buy_points)\n",
        "        else:\n",
        "            new_train_df = new_train_df.assign(sp=new_buy_points)\n",
        "        train_y = new_train_df[col_name]\n",
        "        new_train_df = new_train_df.drop([col_name],axis = 1)\n",
        "        train_xx, valid_x, train_yy, valid_y = train_test_split(new_train_df, train_y, train_size=1.0-valid_size, random_state=42)\n",
        "        print('buy sell point data description:')\n",
        "        print('side=',side)\n",
        "        print('train_x', train_xx.shape)\n",
        "        print('train_y', train_yy.shape)\n",
        "        print('test_x', test_x.shape)\n",
        "        print('test_y', test_y.shape)\n",
        "        print('valid_x', valid_x.shape)\n",
        "        print('valid_y', valid_y.shape)\n",
        "        return train_xx, test_x, train_yy, test_y, valid_x, valid_y\n",
        "    \n",
        "    def select_important_cols(self, model, train_xb):\n",
        "        importance = pd.DataFrame(model.feature_importance(), index=list(train_xb.columns), columns=['importance'])\n",
        "        data = importance.sort_values('importance',ascending=False)\n",
        "\n",
        "        col = list(data.columns)[0]\n",
        "        indicies = list(data.index)\n",
        "        kijun = 0.9 * data[col].sum()\n",
        "\n",
        "        cols = []\n",
        "        current_sum = 0\n",
        "        target = kijun\n",
        "        i = 0\n",
        "        while current_sum < target:\n",
        "            current_sum += data[col].iloc[i]\n",
        "            cols.append(indicies[i])\n",
        "            i += 1\n",
        "        return cols\n",
        "    \n",
        "    def select_important_cols2(self, model, train_xb):\n",
        "        importance = pd.DataFrame(model.feature_importance(), index=list(train_xb.columns), columns=['importance'])\n",
        "        data = importance.sort_values('importance',ascending=False)\n",
        "\n",
        "        col = list(data.columns)[0]\n",
        "        indicies = list(data.index)\n",
        "        print('selected 200 cols, total importance =', data[col].iloc[:200].sum())\n",
        "        return indicies[:200]\n",
        "    \n",
        "    \n",
        "    \n",
        "    def train(self, train_x, train_y):\n",
        "        #print('training data description')\n",
        "        #print('train_x:',train_x.shape)\n",
        "        #print('train_y:',train_y.shape)\n",
        "        train_start_ind = OneMinMarketData.check_matched_index(train_x)\n",
        "        print('train period:', OneMinMarketData.ohlc.dt[train_start_ind], OneMinMarketData.ohlc.dt[train_start_ind + len(train_y)])\n",
        "        train = lgb.Dataset(train_x.values.astype(np.float32), train_y.values.astype(np.float32))\n",
        "        lgbm_params = {\n",
        "        'objective': 'multiclass',\n",
        "        'num_class': 4,\n",
        "            'boosting': 'dart',\n",
        "            'tree_learner': 'data',\n",
        "            'learning_rate':0.05,\n",
        "            'num_iterations':200,\n",
        "#            'device':'gpu',\n",
        "        }\n",
        "        model = lgb.train(lgbm_params, train)\n",
        "        return model\n",
        "\n",
        "    def train_refit(slef, model, train_x, train_y, decay_rate):\n",
        "        return model.refit(train_x.values.astype(np.float32), train_y.values.astype(np.float32), decay_rate)\n",
        "    \n",
        "    def train_params(self, train_x, train_y, params):\n",
        "        #print('training data description')\n",
        "        #print('train_x:',train_x.shape)\n",
        "        #print('train_y:',train_y.shape)\n",
        "        train = lgb.Dataset(train_x.values.astype(np.float32), train_y.values.astype(np.float32))\n",
        "        model = lgb.train(params, train)\n",
        "        return model\n",
        "    \n",
        "    def load_model(self):\n",
        "        model_buy = None\n",
        "        model_sell = None\n",
        "        with open('/content/drive/My Drive/Model/lgb_model_buy.dat', 'rb') as f:\n",
        "            model_buy = pickle.load(f)\n",
        "        with open('/content/drive/My Drive/Model/lgb_model_sell.dat', 'rb') as f:\n",
        "            model_sell = pickle.load(f)\n",
        "        return model_buy, model_sell\n",
        "    \n",
        "    def train_params_with_validations(self, train_x, train_y, valid_x, valid_y, params, verbose=None):\n",
        "        #print('training data description')\n",
        "        #print('train_x:',train_x.shape)\n",
        "        #print('train_y:',train_y.shape)\n",
        "        #train_start_ind = OneMinMarketData.check_matched_index(train_x)\n",
        "        #print('train period:', OneMinMarketData.ohlc.dt[train_start_ind], OneMinMarketData.ohlc.dt[train_start_ind + len(train_y)])\n",
        "        train = lgb.Dataset(train_x.values.astype(np.float32), train_y.values.astype(np.float32))\n",
        "        lgb_eval = lgb.Dataset(valid_x.values.astype(np.float32), valid_y.values.astype(np.float32), reference=train)\n",
        "        #train = lgb.Dataset(data=train_x, label=train_y, categorical_feature='auto')\n",
        "        #lgb_eval = lgb.Dataset(data=valid_x, label=valid_y, reference=train, categorical_feature='auto')\n",
        "        model = lgb.train(params, train, valid_sets = lgb_eval, verbose_eval=verbose)\n",
        "        return model\n",
        "    \n",
        "    def bpsp_prediction(self, model, test_x, uppder_kijun):\n",
        "        prediction = []\n",
        "        pval = model.predict(test_x.values.astype(np.float32), num_iteration=model.best_iteration)\n",
        "        \n",
        "        for p in pval:\n",
        "            res = list(map(lambda x: 1.0 if x >= uppder_kijun else 0, p))\n",
        "            if (res[0] == 1 and res[1] == 0 and res[2] == 0 and res[3] == 0):\n",
        "                prediction.append(0)\n",
        "            elif res[0] == 0 and res[1] == 1 and res[2] == 0 and res[3] == 0:\n",
        "                prediction.append(1)\n",
        "            elif res[0] == 0 and res[1] == 0 and res[2] == 1 and res[3] == 0:\n",
        "                prediction.append(2)\n",
        "            elif res[0] == 0 and res[1] == 0 and res[2] == 0 and res[3] == 1:\n",
        "                prediction.append(3)\n",
        "            elif res[0] == 1 and res[1] == 1 and res[2] == 0 and res[3] == 1:\n",
        "                prediction.append(0)\n",
        "            elif res[0] == 0 and res[1] == 0 and res[2] == 1 and res[3] == 1:\n",
        "                prediction.append(2)\n",
        "            else:\n",
        "                prediction.append(-1) #複数は発火した時は0にする\n",
        "        return prediction\n",
        "\n",
        "\n",
        "    def bpsp_prediction2(self, model, test_x):\n",
        "        prediction = []\n",
        "        pval = model.predict(test_x.values.astype(np.float32), num_iteration=model.best_iteration)\n",
        "        for p in pval:\n",
        "            prediction.append(np.argmax(p))\n",
        "        return prediction\n",
        "\n",
        "    def bpsp_prediction2_kai(self, model, test_x):\n",
        "        return list(np.argmax(model.predict(test_x.values.astype(np.float32), num_iteration=model.best_iteration), axis=1))\n",
        "\n",
        "    def bpsp_prediction3(self, model, test_x, pred_kijun):\n",
        "        prediction = []\n",
        "        pval = model.predict(test_x.values.astype(np.float32), num_iteration=model.best_iteration)\n",
        "        for p in pval:\n",
        "            if max(p) > pred_kijun:\n",
        "                prediction.append(np.argmax(p))\n",
        "            else:\n",
        "                prediction.append(0)\n",
        "        return prediction\n",
        "\n",
        "    def bpsp_prediction4(self, model, test_x):\n",
        "        return list(np.argmax(model.predict(test_x.values.astype(np.float32), num_iteration=model.best_iteration, raw_score=True), axis=1))\n",
        "\n",
        "\n",
        "    def calc_bpsp_accuracy(self, prediction, test_y):\n",
        "        num = len(prediction)\n",
        "        matched = 0\n",
        "        y = np.array(test_y)\n",
        "        for i in range(len(prediction)):\n",
        "            if prediction[i] == y[i]:\n",
        "                matched += 1\n",
        "        if num > 0:\n",
        "            return round(float(matched) / float(num), 4)\n",
        "        else:\n",
        "            return 0\n",
        "                \n",
        "    \n",
        "    def bp_prediciton(self, model, test_x,  kijun):\n",
        "        pred = model.predict(test_x, num_iteration=model.best_iteration)\n",
        "        res = []\n",
        "        for i in pred:\n",
        "            if i >= kijun:\n",
        "                res.append(1)\n",
        "            else:\n",
        "                res.append(0)\n",
        "        return res\n",
        "    \n",
        "    def bp_buysell_prediction(self, prediction_buy, prediction_sell, upper_kijun, lower_kijun):\n",
        "        if len(prediction_buy) == len(prediction_sell):\n",
        "            res = []\n",
        "            for i in range(len(prediction_buy)):\n",
        "                if prediction_buy[i] >= upper_kijun and prediction_sell[i] <= lower_kijun:\n",
        "                    res.append(1)\n",
        "                elif prediction_sell[i] >= upper_kijun and prediction_buy[i] <= lower_kijun:\n",
        "                    res.append(-1)\n",
        "                else:\n",
        "                    res.append(0)\n",
        "            return res\n",
        "        else:\n",
        "            print('bp_buysell_prediction - buy prediction and sell predition num is not matched!!')\n",
        "            return []\n",
        "            \n",
        "    \n",
        "    def bp_buysell_prediction2(self, model_buy, model_sell, test_x, upper_kijun, lower_kijun):\n",
        "        p_buy = model_buy.predict(test_x, num_iteration=model_buy.best_iteration)\n",
        "        p_sell = model_sell.predict(test_x, num_iteration=model_sell.best_iteration)\n",
        "        res = []\n",
        "        for i in range(len(p_buy)):\n",
        "            if p_buy[i] >= upper_kijun and p_sell[i] <= lower_kijun:\n",
        "                res.append(1)\n",
        "            elif p_sell[i] >= upper_kijun and p_buy[i] <= lower_kijun:\n",
        "                res.append(-1)\n",
        "            else:\n",
        "                res.append(0)\n",
        "        return res\n",
        "\n",
        "    def calc_buysell_accuracy(self, predictions, test_y):\n",
        "        num = predictions.count(1) + predictions.count(2)\n",
        "        matched = 0\n",
        "        y = np.array(test_y)\n",
        "        for i in range(len(predictions)):\n",
        "            if predictions[i] == 1 and y[i] == 1 or predictions[i] == 2 and y[i] == 2:\n",
        "                matched += 1\n",
        "        if num >0:\n",
        "            return float(matched) / float(num)\n",
        "        else:\n",
        "            return 0\n",
        "        \n",
        "    def calc_total_accuracy(self, predictions, test_y):\n",
        "        matched = 0\n",
        "        y = np.array(test_y)\n",
        "        for i in range(len(predictions)):\n",
        "            if predictions[i] == y[i]:\n",
        "                matched += 1\n",
        "        return float(matched) / float(len(predictions))\n",
        "            \n",
        "    def calc_bp_accuracy(self, predictions, test_y):\n",
        "        matched = 0\n",
        "        y = np.array(test_y)\n",
        "        for i in range(len(predictions)):\n",
        "            if predictions[i] == 1 and y[i] ==1:\n",
        "                matched += 1\n",
        "        if sum(predictions) > 0:\n",
        "            return float(matched) / float(sum(predictions))\n",
        "        else:\n",
        "            return 0\n",
        "        \n",
        "    \n",
        "    \n",
        "    #count only matched with test_y (0 or 1)\n",
        "    def calc_bp_accuracy2(self, predictions, test_y):\n",
        "        matched = 0\n",
        "        y = np.array(test_y)\n",
        "        for i in range(len(predictions)):\n",
        "            if predictions[i] == y[i]:\n",
        "                matched += 1\n",
        "        if sum(predictions) > 0:\n",
        "            return float(matched) / float(len(predictions))\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def eval_multi_score(self, pred, test_y):\n",
        "        correct = [0,0,0,0]\n",
        "        for i in range(len(pred)):\n",
        "            if pred[i] == test_y.iloc[i]:\n",
        "                correct[pred[i]] += 1\n",
        "        \n",
        "        if correct[0] > 0:\n",
        "            bar_val = [correct[0]/float((test_y==0).sum()),correct[1]/float((test_y==1).sum()),correct[2]/float((test_y==2).sum()),correct[3]/float((test_y==3).sum())]\n",
        "        else:\n",
        "            ar_val = 0\n",
        "        plt.bar(['no','buy','sell','both'],bar_val)\n",
        "        print('accuracy=',accuracy_score(pred, test_y))\n",
        "        print('f1=',f1_score(pred, test_y, average='macro'))\n",
        "        print('buy/sell accuracy=',np.mean([bar_val[1], bar_val[2]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNCHshB0el-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class XgbModel:\n",
        "    def train_valid_with_params(self, train_x, train_y, valid_x, valid_y, params):\n",
        "        dtrain = xgb.DMatrix(train_x, label=train_y)\n",
        "        dvalid = xgb.DMatrix(valid_x, label=valid_y)\n",
        "        evals = [(dtrain, 'train'), (dvalid, 'eval')]\n",
        "        evals_result = {}\n",
        "        bst = xgb.train(params,\n",
        "                    dtrain,\n",
        "                    num_boost_round=1000,\n",
        "                    early_stopping_rounds=50,\n",
        "                    evals=evals,\n",
        "                    evals_result=evals_result,\n",
        "                    )\n",
        "        return bst\n",
        "\n",
        "\n",
        "    def train_valid_with_params_scikit(self, train_x, train_y, valid_x, valid_y, params):\n",
        "        clf = xgb.XGBClassifier(params)\n",
        "        return clf.fit()\n",
        "    \n",
        "    def bpsp_prediction(self, model, test_x, test_y):\n",
        "        dtest = xgb.DMatrix(test_x, label=test_y)\n",
        "        return model.predict(dtest)\n",
        "        \n",
        "\n",
        "\n",
        "    def bpsp_prediction2(self, model, test_x, test_y):\n",
        "        prediction = []\n",
        "        dtest = xgb.DMatrix(test_x, label=test_y)\n",
        "        pval = model.predict(dtest)\n",
        "        for p in pval:\n",
        "            prediction.append(np.argmax(p))\n",
        "        return prediction\n",
        "\n",
        "    def bpsp_prediction2_kai(self, model, test_x, test_y):\n",
        "        dtest = xgb.DMatrix(test_x, label=test_y)\n",
        "        return list(np.argmax(pval = model.predict(dtest), axis=1))\n",
        "\n",
        "    def bpsp_prediction3(self, model, test_x, test_y, pred_kijun):\n",
        "        prediction = []\n",
        "        dtest = xgb.DMatrix(test_x, label=test_y)\n",
        "        pval = model.predict(dtest)\n",
        "        for p in pval:\n",
        "            if max(p) > pred_kijun:\n",
        "                prediction.append(np.argmax(p))\n",
        "            else:\n",
        "                prediction.append(0)\n",
        "        return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcw4PtlFvVnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class OptuningBP:\n",
        "    def objective(trial):\n",
        "        params = {'objective': 'multiclass', 'num_class':4, 'learning_rate':0.1, 'num_iterations':1000,'early_stopping_rounds':50, 'device_type':'gpu', 'metric':'multi_logloss', 'boosting':'gbdt'} \n",
        "        #params['boosting'] = trial.suggest_categorical('boosting', ['gbdt', 'dart'])\n",
        "        params['max_depth'] = trial.suggest_int('max_depth',2, 10)\n",
        "        params['max_bin'] = trial.suggest_int('max_bin', 10, 250)\n",
        "        params['num_leaves'] = trial.suggest_int('num_leaves', 10, 1000)\n",
        "        params['min_data_in_leaf'] = trial.suggest_int('min_data_in_leaf', 0, 200)\n",
        "        params['min_sum_hessian_in_leaf'] = trial.suggest_uniform('min_sum_hessian_in_leaf',1e-5, 1e+1)\n",
        "        params['bagging_fraction'] = trial.suggest_uniform('bagging_fraction',1e-4, 1)\n",
        "        params['bagging_freq'] = trial.suggest_int('bagging_freq',0, 100)\n",
        "        params['feature_fraction'] = trial.suggest_uniform('feature_fraction', 0, 1)\n",
        "        params['lambda_l1'] = trial.suggest_int('lambda_l1',0, 100)\n",
        "        params['lambda_l2'] = trial.suggest_int('lambda_l2',0, 100)\n",
        "        params['min_gain_to_split'] = trial.suggest_int('min_gain_to_split',0, 100)\n",
        "        if params['boosting'] == 'dart':\n",
        "            params['drop_rate'] = trial.suggest_uniform('drop_rate',0, 1.0)\n",
        "            params['max_drop'] = trial.suggest_int('max_drop', 1, 10)\n",
        "            params['skip_drop'] = trial.suggest_uniform('skip_drop',0, 1.0)\n",
        "            params['xgboost_dart_mode'] = trial.suggest_categorical('xgboost_dart_mode', [True, False])\n",
        "            params['uniform_drop'] = trial.suggest_categorical('uniform_drop', [True, False])\n",
        "        #params['upper_kijun'] = trial.suggest_discrete_uniform('upper_kijun', 0.1, 0.95, 0.05)\n",
        "\n",
        "        sum_accuracy = 0\n",
        "        sum_pl_x_stability = 0\n",
        "        for i in range(num_loop):\n",
        "            sim = Sim()\n",
        "            ac = None\n",
        "            ac2 = None\n",
        "            ac = SimAccount()\n",
        "            ac2 = SimAccount()\n",
        "            lgbmodel = LgbModel()\n",
        "            train_df = df2.iloc[test_start_ind - train_len + (test_len * i):(test_len * i) + test_start_ind].copy()\n",
        "            test_df = df2.iloc[kijun_period + (test_len * i) + test_start_ind:kijun_period + test_start_ind + (test_len * i) + test_len].copy()\n",
        "            #train_xb, test_xb, train_yb, test_yb, valid_xb, valid_yb, opt_xb, opt_yb = lgbmodel.generate_bpsp_data(train_df, test_df, valid_size, opt_len, random_state)\n",
        "            train_xb, test_xb, train_yb, test_yb, valid_xb, valid_yb, opt_xb, opt_yb = lgbmodel.generate_bpsp_data2(train_df, test_df, opt_len, valid_size, random_state)\n",
        "\n",
        "            if list(train_xb.columns) == list(test_xb.columns) == list(valid_xb.columns):\n",
        "                pass\n",
        "            else:\n",
        "                print('train col, test col, valid col are not matched!')\n",
        "\n",
        "            model = lgbmodel.train_params_with_validations(train_xb, train_yb, valid_xb, valid_yb, params, verbose_eval)\n",
        "            print(model.best_score)\n",
        "\n",
        "            #prediction = lgbmodel.bpsp_prediction2(model, test_xb)\n",
        "            prediction = lgbmodel.bpsp_prediction(model, test_xb, upper_kijun)\n",
        "            #prediction = lgbmodel.bpsp_prediction4(model, test_xb)\n",
        "            prediction = None\n",
        "            if pred_method == 0:\n",
        "                prediction = lgbmodel.bpsp_prediction(model, test_xb, upper_kijun)\n",
        "            elif pred_method == 1:\n",
        "                prediction = lgbmodel.bpsp_prediction2(model, test_xb)\n",
        "            elif pred_method == 2:\n",
        "                prediction = lgbmodel.bpsp_prediction2_kai(model, test_xb)\n",
        "            elif pred_method == 3:\n",
        "                prediction = lgbmodel.bpsp_prediction3(model, test_xb, upper_kijun)\n",
        "            elif pred_method == 4:\n",
        "                prediction = lgbmodel.bpsp_prediction4(model, test_xb)\n",
        "            print('test accuracy={}'.format(lgbmodel.calc_bpsp_accuracy(prediction, test_yb)))\n",
        "\n",
        "            start_ind = OneMinMarketData.check_matched_dt(test_xb, df2)\n",
        "            #last_day = True if i == num_loop -1 else False\n",
        "            last_day = True\n",
        "            #ac = sim.sim_model_pred_onemin_avert(start_ind, prediction, pt_ratio, lc_ratio, ac, ac2, avert_period_kijun, avert_val_kijun, last_day)\n",
        "            ac = sim.sim_model_pred_onemin(start_ind, prediction, pt_ratio, lc_ratio, ac, last_day, True, kyuhen_period, kyuhen_kijun)\n",
        "            print('total pl={},num trade={},win rate={}, pl_stability={}, num_buy={}, num_sell={}'.format(ac.total_pl,ac.num_trade,ac.win_rate, ac.pl_stability, ac.num_buy, ac.num_sell))\n",
        "            sum_accuracy += copy.copy(lgbmodel.calc_bpsp_accuracy(prediction, test_yb))\n",
        "            sum_pl_x_stability += copy.copy(ac.total_pl) * copy.copy(ac.pl_stability)\n",
        "            del sim, ac, ac2, lgbmodel, train_df, test_df, train_xb, test_xb, train_yb, test_yb, valid_xb, valid_yb, opt_xb, opt_yb\n",
        "        return -sum_pl_x_stability\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "num_term = 1500\n",
        "upper_kijun = 0.6\n",
        "corr_kijun = 0.3\n",
        "from_ind = 0\n",
        "to_ind = 124000\n",
        "production_data_len = 0 #set 0 when testing\n",
        "\n",
        "train_len = 25000\n",
        "test_len = 10000\n",
        "opt_len = 1\n",
        "test_start_ind = 25000 #should be larger than train_len\n",
        "valid_size = 0.1\n",
        "num_loop = 9\n",
        "\n",
        "kijun_ratio =0.0075\n",
        "kijun_period = 300\n",
        "pt_ratio = kijun_ratio\n",
        "lc_ratio = 0.03\n",
        "random_state = 1\n",
        "lgb_random_state = 1\n",
        "verbose_eval = 0\n",
        "\n",
        "pred_method = 0\n",
        "avert_period_kijun = 480\n",
        "avert_val_kijun = -0.003\n",
        "\n",
        "flg_large_only = True\n",
        "flg_abs = True\n",
        "kyuhen_period = 0\n",
        "kyuhen_kijun = 0\n",
        "\n",
        "OneMinMarketData.initialize_for_bot(num_term, from_ind, to_ind, kijun_ratio, kijun_period, production_data_len)\n",
        "df = OneMinMarketData.genrate_df_from_dict()\n",
        "df = OneMinMarketData.remove_cols_contains_nan2(df)\n",
        "#df = OneMinMarketData.remove_all_correlated_cols4(df, corr_kijun)\n",
        "df2 = OneMinMarketData.remove_price_dependent_cols2(df, corr_kijun, flg_abs)\n",
        "\n",
        "#con = sqlite3.connect('/content/drive/My Drive/Model/optuna.db')\n",
        "study = optuna.create_study(study_name='opt_bpsp_28',storage='sqlite:///../content/drive/My Drive/Model/optuna.db')\n",
        "#study = optuna.study.load_study(study_name='opt_bpsp_26', storage='sqlite:///../content/drive/My Drive/Model/optuna.db')\n",
        "f = partial(OptuningBP.objective)\n",
        "optuna.logging.enable_default_handler()\n",
        "study.optimize(f, n_trials=100)\n",
        "print('time to calc data={}'.format(time.time() - start))\n",
        "print('best params:',study.best_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkG17OT-OlGs",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8j4WErupsMRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OptuningAll:\n",
        "    def objective(trial):\n",
        "        params = {'objective': 'multiclass', 'num_class':4, 'learning_rate':0.1, 'num_iterations':2000,'early_stopping_rounds':50, 'device_type':'gpu', 'metric':'multi_logloss', 'silent':True} \n",
        "        params['boosting'] = trial.suggest_categorical('boosting', ['gbdt', 'dart'])\n",
        "        params['max_depth'] = trial.suggest_int('max_depth',2, 10)\n",
        "        params['max_bin'] = trial.suggest_int('max_bin', 10, 250)\n",
        "        params['num_leaves'] = trial.suggest_int('num_leaves', 10, 1000)\n",
        "        params['min_data_in_leaf'] = trial.suggest_int('min_data_in_leaf', 0, 200)\n",
        "        params['min_sum_hessian_in_leaf'] = trial.suggest_uniform('min_sum_hessian_in_leaf',1e-5, 1e+1)\n",
        "        params['bagging_fraction'] = trial.suggest_uniform('bagging_fraction',1e-4, 1)\n",
        "        params['bagging_freq'] = trial.suggest_int('bagging_freq',0, 100)\n",
        "        params['feature_fraction'] = trial.suggest_uniform('feature_fraction', 0, 1)\n",
        "        params['lambda_l1'] = trial.suggest_int('lambda_l1',0, 100)\n",
        "        params['lambda_l2'] = trial.suggest_int('lambda_l2',0, 100)\n",
        "        params['min_gain_to_split'] = trial.suggest_int('min_gain_to_split',0, 100)\n",
        "        if params['boosting'] == 'dart':\n",
        "            params['drop_rate'] = trial.suggest_uniform('drop_rate',0, 1.0)\n",
        "            params['max_drop'] = trial.suggest_int('max_drop', 1, 10)\n",
        "            params['skip_drop'] = trial.suggest_uniform('skip_drop',0, 1.0)\n",
        "            params['xgboost_dart_mode'] = trial.suggest_categorical('xgboost_dart_mode', [True, False])\n",
        "            params['uniform_drop'] = trial.suggest_categorical('uniform_drop', [True, False])\n",
        "        params['upper_kijun'] = trial.suggest_discrete_uniform('upper_kijun', 0.1, 0.95, 0.05)\n",
        "        params['avert_onemin'] = trial.suggest_int('avert_onemine',0,1)\n",
        "        params['avert_period_kijun'] = trial.suggest_int('avert_period_kijun',10,1000)\n",
        "        params['avert_val_kijun'] = trial.suggest_int('avert_val_kijun',-500,500)\n",
        "        params['pred_method'] = trial.suggest_int('pred_method',0,4)\n",
        "\n",
        "        lgbparams = {'objective': params['objective'], 'num_class':params['num_class'], 'learning_rate':params['learning_rate'], 'num_iterations':params['num_iterations'], 'early_stopping_rounds':params['early_stopping_rounds'], \n",
        "                    'device_type':params['device_type'], 'metric':params['metric'], 'silent':params['silent'], 'bagging_fraction': params['bagging_fraction'], 'bagging_freq': params['bagging_freq'], \n",
        "                    'boosting': params['boosting'], 'feature_fraction': params['feature_fraction'], 'lambda_l1': params['lambda_l1'], 'lambda_l2': params['lambda_l2'], 'max_bin': params['max_bin'], \n",
        "                    'max_depth': params['max_depth'], 'min_data_in_leaf': params['min_data_in_leaf'], 'min_gain_to_split': params['min_gain_to_split'], 'min_sum_hessian_in_leaf': params['min_sum_hessian_in_leaf']}\n",
        "\n",
        "        sum_accuracy = 0\n",
        "        sum_pl_x_stability = 0\n",
        "        for i in range(num_loop):\n",
        "            sim = Sim()\n",
        "            ac = SimAccount()\n",
        "            ac2 = SimAccount()\n",
        "            lgbmodel = LgbModel()\n",
        "            train_df = df2.iloc[test_start_ind - train_len + (test_len * i):(test_len * i) + test_start_ind].copy()\n",
        "            test_df = df2.iloc[kijun_period + (test_len * i) + test_start_ind:kijun_period + test_start_ind + (test_len * i) + test_len].copy()\n",
        "            #train_xb, test_xb, train_yb, test_yb, valid_xb, valid_yb, opt_xb, opt_yb = lgbmodel.generate_bpsp_data(train_df, test_df, valid_size, opt_len, random_state)\n",
        "            train_xb, test_xb, train_yb, test_yb, valid_xb, valid_yb, opt_xb, opt_yb = lgbmodel.generate_bpsp_data2(train_df, test_df, opt_len, valid_size, random_state)\n",
        "\n",
        "            if list(train_xb.columns) == list(test_xb.columns) == list(valid_xb.columns):\n",
        "                pass\n",
        "            else:\n",
        "                print('train col, test col, valid col are not matched!')\n",
        "\n",
        "            train_time = time.time()\n",
        "            model = lgbmodel.train_params_with_validations(train_xb, train_yb, valid_xb, valid_yb, lgbparams, verbose_eval)\n",
        "            print(model.best_score, 'train time=', time.time() - train_time)\n",
        "            \n",
        "            prediction = None\n",
        "            if params['pred_method'] == 0:\n",
        "                prediction = lgbmodel.bpsp_prediction(model, test_xb, params['upper_kijun'])\n",
        "            elif params['pred_method'] == 1:\n",
        "                prediction = lgbmodel.bpsp_prediction2(model, test_xb)\n",
        "            elif params['pred_method'] == 2:\n",
        "                prediction = lgbmodel.bpsp_prediction2_kai(model, test_xb)\n",
        "            elif params['pred_method'] == 3:\n",
        "                prediction = lgbmodel.bpsp_prediction3(model, test_xb, params['upper_kijun'])\n",
        "            elif params['pred_method'] == 4:\n",
        "                prediction = lgbmodel.bpsp_prediction4(model, test_xb)\n",
        "            \n",
        "            print('test accuracy={}'.format(lgbmodel.calc_bpsp_accuracy(prediction, test_yb)))\n",
        "\n",
        "            start_ind = OneMinMarketData.check_matched_dt(test_xb, df2)\n",
        "            #last_day = True if i == num_loop -1 else False\n",
        "            last_day = True\n",
        "            if params['avert_onemin'] == 0:\n",
        "                ac = sim.sim_model_pred_onemin(start_ind, prediction, pt_ratio, lc_ratio, ac, True)\n",
        "            elif params['avert_onemin'] == 1:\n",
        "                ac = sim.sim_model_pred_onemin_avert(start_ind, prediction, pt_ratio, lc_ratio, ac, ac2, params['avert_period_kijun'], params['avert_val_kijun'] / 10000.0, True)\n",
        "            print('total pl={},num trade={},win rate={}, pl_stability={}, num_buy={}, num_sell={}'.format(ac.total_pl,ac.num_trade,ac.win_rate, ac.pl_stability, ac.num_buy,ac.num_sell))\n",
        "            sum_accuracy += copy.copy(lgbmodel.calc_bpsp_accuracy(prediction, test_yb))\n",
        "            sum_pl_x_stability += copy.copy(ac.total_pl) * copy.copy(ac.pl_stability)\n",
        "        return -sum_pl_x_stability\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "num_term = 1500\n",
        "upper_kijun = 0.7\n",
        "corr_kijun = 0.7\n",
        "from_ind = 100000\n",
        "to_ind = 244000\n",
        "production_data_len = 0 #set 0 when testing\n",
        "\n",
        "train_len = 25000\n",
        "test_len = 5000\n",
        "opt_len = 1\n",
        "test_start_ind = 25000 #should be larger than train_len\n",
        "valid_size = 0.1\n",
        "num_loop = 10\n",
        "\n",
        "kijun_ratio =0.0075\n",
        "kijun_period = 300\n",
        "pt_ratio = kijun_ratio\n",
        "lc_ratio = 0.03\n",
        "random_state = None\n",
        "lgb_random_state = None\n",
        "verbose_eval = 0\n",
        "\n",
        "OneMinMarketData.initialize_for_bot(num_term, from_ind, to_ind, kijun_ratio, kijun_period, production_data_len)\n",
        "df = OneMinMarketData.genrate_df_from_dict()\n",
        "df = OneMinMarketData.remove_cols_contains_nan2(df)\n",
        "#df = OneMinMarketData.remove_all_correlated_cols4(df, corr_kijun)\n",
        "df2 = OneMinMarketData.remove_price_dependent_cols2(df, corr_kijun)\n",
        "\n",
        "#con = sqlite3.connect('/content/drive/My Drive/Model/optuna_all.db')\n",
        "#study = optuna.create_study(study_name='opt_all_1', storage='sqlite:///../content/drive/My Drive/Model/optuna_all.db')\n",
        "study = optuna.study.load_study(study_name='opt_all_1', storage='sqlite:///../content/drive/My Drive/Model/optuna_all.db')\n",
        "f = partial(OptuningAll.objective)\n",
        "optuna.logging.enable_default_handler()\n",
        "study.optimize(f, n_trials=100)\n",
        "print('time to calc data={}'.format(time.time() - start))\n",
        "print('best params:',study.best_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDeg0zp_z5y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class OptuningOtherParams:\n",
        "    def objective(trial):\n",
        "        params = {'objective': 'multiclass', 'num_class':4, 'learning_rate':0.1, 'num_iterations':1000,'early_stopping_rounds':50, 'device_type':'gpu', 'metric':'multi_logloss', 'boosting':'gbdt', 'silent':True,\n",
        "                  'max_depth':10, 'max_bin':100, 'num_leaves':100, 'lambda_l1':15, 'lambda_l2':15}\n",
        "\n",
        "        '''\n",
        "        params['max_depth'] = trial.suggest_int('max_depth',2, 10)\n",
        "        params['max_bin'] = trial.suggest_discrete_uniform('max_bin', 10, 250, 10)\n",
        "        params['num_leaves'] = trial.suggest_discrete_uniform('num_leaves', 10, 1060, 50)\n",
        "        params['min_data_in_leaf'] = trial.suggest_discrete_uniform('min_data_in_leaf', 0, 200, 10)\n",
        "        params['min_sum_hessian_in_leaf'] = trial.suggest_uniform('min_sum_hessian_in_leaf',1e-5, 1e+1)\n",
        "        params['bagging_fraction'] = trial.suggest_uniform('bagging_fraction',1e-4, 1)\n",
        "        params['bagging_freq'] = trial.suggest_discrete_uniform('bagging_freq',0, 100, 10)\n",
        "        params['feature_fraction'] = trial.suggest_discrete_uniform('feature_fraction', 0, 1, 0.1)\n",
        "        params['lambda_l1'] = trial.suggest_discrete_uniform('lambda_l1',0, 100, 10)\n",
        "        params['lambda_l2'] = trial.suggest_discrete_uniform('lambda_l2',0, 100, 10)\n",
        "        params['min_gain_to_split'] = trial.suggest_discrete_uniform('min_gain_to_split',0, 100, 10)\n",
        "        '''\n",
        "\n",
        "        params['num_term'] = trial.suggest_discrete_uniform('num_term',0, 3000, 100)\n",
        "        params['upper_kijun'] = trial.suggest_discrete_uniform('upper_kijun',0.2, 0.9, 0.1)\n",
        "        params['corr_kijun'] = trial.suggest_discrete_uniform('corr_kijun',0.1, 0.9, 0.1)\n",
        "        params['train_len'] = trial.suggest_discrete_uniform('train_len',5000, 50000, 5000)\n",
        "        params['test_len'] = trial.suggest_discrete_uniform('test_len',1000, 50000, 1000)\n",
        "        num_loop = math.ceil(50000  / params['test_len'] )\n",
        "        params['valid_size'] = trial.suggest_discrete_uniform('valid_size',0.1, 0.9, 0.1)\n",
        "        params['avert_onemin'] = trial.suggest_categorical('avert_onemin', [True, False])\n",
        "        if params['avert_onemin']:\n",
        "            params['avert_period_kijun'] = trial.suggest_discrete_uniform('avert_period_kijun',60, 1080, 60)\n",
        "            params['avert_val_kijun'] = trial.suggest_discrete_uniform('avert_val_kijun',-0.01, 0.01, 0.001)\n",
        "        params['kyuhen_period'] = trial.suggest_discrete_uniform('kyuhen_period',0, 60, 5)\n",
        "        params['kyuhen_kijun'] = trial.suggest_discrete_uniform('kyuhen_kijun', 0.005, 0.05, 0.005)\n",
        "        \n",
        "\n",
        "\n",
        "        lgbparams = {'objective': params['objective'], 'num_class':params['num_class'], 'learning_rate':params['learning_rate'], 'num_iterations':params['num_iterations'], 'early_stopping_rounds':params['early_stopping_rounds'], \n",
        "                    'device_type':params['device_type'], 'metric':params['metric'], 'boosting': params['boosting'], 'lambda_l1': params['lambda_l1'], 'lambda_l2': params['lambda_l2'], 'max_bin': int(params['max_bin']), \n",
        "                    'max_depth': params['max_depth']}\n",
        "\n",
        "\n",
        "        total_performance  = 0\n",
        "\n",
        "        for main_loop in range(3):\n",
        "            sum_accuracy = 0\n",
        "            sum_pl_x_stability = 0\n",
        "            from_ind = 20000 + (main_loop * 50000)\n",
        "            to_ind = 130000 + (main_loop * 50000)\n",
        "\n",
        "            OneMinMarketData.initialize_for_bot(int(params['num_term']) , from_ind, to_ind, kijun_ratio, kijun_period, production_data_len)\n",
        "            df = OneMinMarketData.genrate_df_from_dict()\n",
        "            df = OneMinMarketData.remove_cols_contains_nan2(df)\n",
        "            df2 = OneMinMarketData.remove_price_dependent_cols2(df, params['corr_kijun'], flg_abs)\n",
        "            for i in range(num_loop):\n",
        "                sim = Sim()\n",
        "                ac = None\n",
        "                ac2 = None\n",
        "                ac = SimAccount()\n",
        "                ac2 = SimAccount()\n",
        "                lgbmodel = LgbModel()\n",
        "                train_df = df2.iloc[test_start_ind - int(params['train_len']) + (int(params['test_len']) * i):(int(params['test_len']) * i) + test_start_ind].copy()\n",
        "                test_df = df2.iloc[kijun_period + (int(params['test_len']) * i) + test_start_ind:kijun_period + test_start_ind + (int(params['test_len']) * i) + int(params['test_len'])].copy()\n",
        "                #train_xb, test_xb, train_yb, test_yb, valid_xb, valid_yb, opt_xb, opt_yb = lgbmodel.generate_bpsp_data(train_df, test_df, valid_size, opt_len, random_state)\n",
        "                train_xb, test_xb, train_yb, test_yb, valid_xb, valid_yb, opt_xb, opt_yb = lgbmodel.generate_bpsp_data2(train_df, test_df, opt_len, params['valid_size'], random_state)\n",
        "\n",
        "                if list(train_xb.columns) == list(test_xb.columns) == list(valid_xb.columns):\n",
        "                    pass\n",
        "                else:\n",
        "                    print('train col, test col, valid col are not matched!')\n",
        "\n",
        "                model = lgbmodel.train_params_with_validations(train_xb, train_yb, valid_xb, valid_yb, lgbparams, verbose_eval)\n",
        "                print(model.best_score)\n",
        "\n",
        "                #prediction = lgbmodel.bpsp_prediction2(model, test_xb)\n",
        "                prediction = lgbmodel.bpsp_prediction(model, test_xb, params['upper_kijun'])\n",
        "                #prediction = lgbmodel.bpsp_prediction4(model, test_xb)\n",
        "                prediction = None\n",
        "                if pred_method == 0:\n",
        "                    prediction = lgbmodel.bpsp_prediction(model, test_xb, params['upper_kijun'])\n",
        "                elif pred_method == 1:\n",
        "                    prediction = lgbmodel.bpsp_prediction2(model, test_xb)\n",
        "                elif pred_method == 2:\n",
        "                    prediction = lgbmodel.bpsp_prediction2_kai(model, test_xb)\n",
        "                elif pred_method == 3:\n",
        "                    prediction = lgbmodel.bpsp_prediction3(model, test_xb, params['upper_kijun'])\n",
        "                elif pred_method == 4:\n",
        "                    prediction = lgbmodel.bpsp_prediction4(model, test_xb)\n",
        "                print('test accuracy={}'.format(lgbmodel.calc_bpsp_accuracy(prediction, test_yb)))\n",
        "\n",
        "                start_ind = OneMinMarketData.check_matched_dt(test_xb, df2)\n",
        "                #last_day = True if i == num_loop -1 else False\n",
        "                last_day = True\n",
        "                if params['avert_onemin']:\n",
        "                    #def sim_model_pred_onemin_avert(cls, start_ind, prediction, pt_ratio, lc_ratio, ac, ac2, avert_period_kijun, avert_val_kijun, last_day, flg_only_large, kyuhen_period, kyuhen_kijun):\n",
        "                    ac = sim.sim_model_pred_onemin_avert(start_ind, prediction, pt_ratio, lc_ratio, ac, ac2, int(params['avert_period_kijun']), params['avert_val_kijun'], last_day, True, int(params['kyuhen_period']), params['kyuhen_kijun'])\n",
        "                else:\n",
        "                    ac = sim.sim_model_pred_onemin(start_ind, prediction, pt_ratio, lc_ratio, ac, last_day, True, int(params['kyuhen_period']), params['kyuhen_kijun'])\n",
        "                print('total pl={},num trade={},win rate={}, pl_stability={}, num_buy={}, num_sell={}'.format(ac.total_pl,ac.num_trade,ac.win_rate, ac.pl_stability, ac.num_buy, ac.num_sell))\n",
        "                sum_accuracy += copy.copy(lgbmodel.calc_bpsp_accuracy(prediction, test_yb))\n",
        "                sum_pl_x_stability += copy.copy(ac.total_pl) * copy.copy(ac.pl_stability)\n",
        "                del sim, ac, ac2, lgbmodel, train_df, test_df, train_xb, test_xb, train_yb, test_yb, valid_xb, valid_yb, opt_xb, opt_yb\n",
        "            del df, df2, OneMinMarketData.ohlc\n",
        "            total_performance += -sum_pl_x_stability\n",
        "        return total_performance\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "from_ind = 0\n",
        "to_ind = 110000\n",
        "production_data_len = 0 #set 0 when testing\n",
        "\n",
        "opt_len = 1\n",
        "test_start_ind = 50500 #should be larger than train_len\n",
        "\n",
        "kijun_ratio =0.0075\n",
        "kijun_period = 300\n",
        "pt_ratio = kijun_ratio\n",
        "lc_ratio = 0.03\n",
        "random_state = 1\n",
        "lgb_random_state = 1\n",
        "verbose_eval = 0\n",
        "\n",
        "pred_method = 0\n",
        "\n",
        "flg_large_only = True\n",
        "flg_abs = True\n",
        "\n",
        "\n",
        "#con = sqlite3.connect('/content/drive/My Drive/Model/optuna.db')\n",
        "#study = optuna.create_study(study_name='opt_bpsp_31',storage='sqlite:///../content/drive/My Drive/Model/optuna.db')\n",
        "study = optuna.study.load_study(study_name='opt_bpsp_31', storage='sqlite:///../content/drive/My Drive/Model/optuna.db')\n",
        "f = partial(OptuningOtherParams.objective)\n",
        "optuna.logging.enable_default_handler()\n",
        "study.optimize(f, n_trials=100)\n",
        "print('time to calc data={}'.format(time.time() - start))\n",
        "print('best params:',study.best_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2Zzi5HtDBL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OptunaSim:\n",
        "    def objective(self, trial):\n",
        "        params['avert_onemin'] = trial.suggest_int('avert_onemine',0,1)\n",
        "        params['upper_kijun'] = trial.suggest_discrete_uniform('upper_kijun', 0.1, 0.95, 0.05)\n",
        "        params['avert_period_kijun'] = trial.suggest_int('avert_period_kijun',10,1000)\n",
        "        params['avert_val_kijun'] = trial.suggest_int('avert_val_kijun',-500,500)\n",
        "        params['pred_method'] = trial.suggest_int('pred_method',0,4)\n",
        "\n",
        "        prediction = None\n",
        "        if params['pred_method'] == 0:\n",
        "            prediction = self.lgbmodel.bpsp_prediction(self.model, self.opt_xb, params['upper_kijun'])\n",
        "        elif params['pred_method'] == 1:\n",
        "            prediction = self.lgbmodel.bpsp_prediction2(self.model, self.opt_xb)\n",
        "        elif params['pred_method'] == 2:\n",
        "            prediction = self.lgbmodel.bpsp_prediction2_kai(self.model, self.opt_xb)\n",
        "        elif params['pred_method'] == 3:\n",
        "            prediction = self.lgbmodel.bpsp_prediction3(self.model, self.opt_xb, params['upper_kijun'])\n",
        "        elif params['pred_method'] == 4:\n",
        "            prediction = self.lgbmodel.bpsp_prediction4(self.model, self.opt_xb)\n",
        "            \n",
        "        sim = Sim()\n",
        "        ac = SimAccount()\n",
        "        ac2 = SimAccount()\n",
        "        #accuracy = self.lgbmodel.calc_bpsp_accuracy(prediction, self.opt_yb)\n",
        "        if params['avert_onemin'] == 0:\n",
        "            ac = sim.sim_model_pred_onemin(self.start_ind, prediction, self.pt_ratio, self.lc_ratio, ac, True)\n",
        "        elif params['avert_onemin'] == 1:\n",
        "            ac = sim.sim_model_pred_onemin_avert(self.start_ind, prediction, self.pt_ratio, self.lc_ratio, ac, ac2, params['avert_period_kijun'], params['avert_val_kijun'] / 10000.0, True)\n",
        "        #print('total pl={},num trade={},win rate={}, pl_stability={}, num_buy={}, num_sell={}'.format(ac.total_pl,ac.num_trade,ac.win_rate, ac.pl_stability, ac.num_buy,ac.num_sell))\n",
        "        if self.best_performance > -ac.total_pl * ac.pl_stability:\n",
        "            self.best_performance = -1.0 * copy.copy(ac.total_pl) * copy.copy(ac.pl_stability)\n",
        "            self.best_ac = copy.copy(ac)\n",
        "            #print('current best pl =', ac.total_pl)\n",
        "        return -1.0 * copy.copy(ac.total_pl) * copy.copy(ac.pl_stability)\n",
        "\n",
        "    def start_opt_sim(self, model, opt_xb, opt_yb, df2, pt_ratio, lc_ratio):\n",
        "        self.model = model\n",
        "        self.opt_xb = opt_xb\n",
        "        self.opt_yb = opt_yb\n",
        "        self.df2 = df2\n",
        "        self.pt_ratio = pt_ratio\n",
        "        self.lc_ratio = lc_ratio\n",
        "        self.best_ac = None\n",
        "        self.start_ind = OneMinMarketData.check_matched_dt(opt_xb, df2)\n",
        "        self.best_performance = 9999\n",
        "        self.total_pl_log = []\n",
        "        self.lgbmodel = LgbModel()\n",
        "\n",
        "        study = optuna.create_study()\n",
        "        optuna.logging.disable_default_handler()\n",
        "        f = partial(self.objective)\n",
        "        study.optimize(f, n_trials=50)\n",
        "        #print('best params:',study.best_params)\n",
        "        return study.best_params , self.best_ac"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6zvcXv-s4da",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OptunaSimXgb:\n",
        "    def objective(self, trial):\n",
        "        params['avert_onemin'] = trial.suggest_int('avert_onemine',0,1)\n",
        "        params['avert_period_kijun'] = trial.suggest_int('avert_period_kijun',10,1000)\n",
        "        params['avert_val_kijun'] = trial.suggest_int('avert_val_kijun',-500,500)\n",
        "\n",
        "        prediction = self.bst.bpsp_prediction(self.model, self.opt_xb, self.opt_yb)\n",
        "        sim = Sim()\n",
        "        ac = SimAccount()\n",
        "        ac2 = SimAccount()\n",
        "        #accuracy = self.lgbmodel.calc_bpsp_accuracy(prediction, self.opt_yb)\n",
        "        if params['avert_onemin'] == 0:\n",
        "            ac = sim.sim_model_pred_onemin(self.start_ind, prediction, self.pt_ratio, self.lc_ratio, ac, True)\n",
        "        elif params['avert_onemin'] == 1:\n",
        "            ac = sim.sim_model_pred_onemin_avert(self.start_ind, prediction, self.pt_ratio, self.lc_ratio, ac, ac2, params['avert_period_kijun'], params['avert_val_kijun'] / 10000.0, True)\n",
        "        #print('total pl={},num trade={},win rate={}, pl_stability={}, num_buy={}, num_sell={}'.format(ac.total_pl,ac.num_trade,ac.win_rate, ac.pl_stability, ac.num_buy,ac.num_sell))\n",
        "        if self.best_performance > -ac.total_pl * ac.pl_stability:\n",
        "            self.best_performance = copy.copy(-ac.total_pl * ac.pl_stability)\n",
        "            self.best_ac = copy.copy(ac)\n",
        "        return -ac.total_pl * ac.pl_stability\n",
        "\n",
        "    def start_opt_sim(self, model, opt_xb, opt_yb, df2, pt_ratio, lc_ratio):\n",
        "        self.model = model\n",
        "        self.opt_xb = opt_xb\n",
        "        self.opt_yb = opt_yb\n",
        "        self.df2 = df2\n",
        "        self.pt_ratio = pt_ratio\n",
        "        self.lc_ratio = lc_ratio\n",
        "        self.best_ac = None\n",
        "        self.start_ind = OneMinMarketData.check_matched_dt(opt_xb, df2)\n",
        "        self.best_performance = 9999\n",
        "        self.total_pl_log = []\n",
        "        self.bst = XgbModel()\n",
        "\n",
        "        study = optuna.create_study()\n",
        "        optuna.logging.disable_default_handler()\n",
        "        f = partial(self.objective)\n",
        "        study.optimize(f, n_trials=50)\n",
        "        #print('best params:',study.best_params)\n",
        "        return study.best_params , self.best_ac"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roqLx6XcA5jX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "baysian opt sim\n",
        "'''\n",
        "class BaysOptSim:\n",
        "    def Objective(self, upper_kijun, avert_period_kijun, avert_val_kijun, avert_onemine, pred_method):\n",
        "        upper_kijun = upper_kijun / 100.0\n",
        "        avert_val_kijun = avert_val_kijun / 10000.0\n",
        "        avert_period_kijun = int(round(avert_period_kijun))\n",
        "        \n",
        "        prediction = None\n",
        "        pred_method = int(round(pred_method))\n",
        "        if pred_method == 0:\n",
        "            prediction = self.lgbmodel.bpsp_prediction(self.model, self.opt_xb, upper_kijun)\n",
        "        elif pred_method == 1:\n",
        "            prediction = self.lgbmodel.bpsp_prediction2(self.model, self.opt_xb)\n",
        "        elif pred_method == 2:\n",
        "            prediction = self.lgbmodel.bpsp_prediction2_kai(self.model, self.opt_xb)\n",
        "        elif pred_method == 3:\n",
        "            prediction = self.lgbmodel.bpsp_prediction3(self.model, self.opt_xb, upper_kijun)\n",
        "        else:\n",
        "            print('invalid bpsp func!', pred_method)\n",
        "        \n",
        "        sim = Sim()\n",
        "        ac = SimAccount()\n",
        "        ac2 = SimAccount()\n",
        "        avert_onemine = int(round(avert_onemine))\n",
        "        if avert_onemine == 0:\n",
        "            ac = sim.sim_model_pred_onemin_avert(self.start_ind, prediction, self.pt_ratio, self.lc_ratio, ac, ac2, avert_period_kijun, avert_val_kijun)\n",
        "        else:\n",
        "            ac = sim.sim_model_pred_onemin(self.start_ind, prediction, self.pt_ratio, self.lc_ratio, ac)\n",
        "        print('total pl={},num trade={},win rate={}, pl_stability={}, num_buy={}, num_sell={}'.format(ac.total_pl,ac.num_trade,ac.win_rate, ac.pl_stability, ac.num_buy,ac.num_sell))\n",
        "        if self.best_eva < ac.total_pl:\n",
        "            self.best_eva = ac.total_pl\n",
        "            self.total_pl_log = ac.total_pl_log\n",
        "        return ac.total_pl\n",
        "\n",
        "    def start_opt(self, n_iter, model, opt_xb, df2, pt_ratio, lc_ratio):\n",
        "        pbounds = {'upper_kijun':(30, 95), 'avert_period_kijun':(30, 1000), 'avert_val_kijun':(-500, 500), 'avert_onemine':(0,1), 'pred_method':(0,3)}\n",
        "        self.model = model\n",
        "        self.lgbmodel = LgbModel()\n",
        "        self.opt_xb = opt_xb\n",
        "        self.df2 = df2\n",
        "        self.start_ind = OneMinMarketData.check_matched_dt(opt_xb, df2)\n",
        "        self.pt_ratio = pt_ratio\n",
        "        self.lc_ratio = lc_ratio\n",
        "        self.best_eva = 0\n",
        "        self.total_pl_log = []\n",
        "        optimizer = BayesianOptimization(f=self.Objective, pbounds=pbounds)\n",
        "\n",
        "        optimizer.maximize(\n",
        "            init_points = 5,\n",
        "            n_iter = n_iter\n",
        "        )\n",
        "        return optimizer.max['params'], self.total_pl_log\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zwQ7PDBKlol",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SAd3NI9ouIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Opt Sim Lgb\n",
        "'''\n",
        "\n",
        "import time\n",
        "num_term = 1500\n",
        "upper_kijun = 0.7\n",
        "corr_kijun = 0.7\n",
        "from_ind = 170000\n",
        "to_ind = 244000\n",
        "production_data_len = 0 #set 0 when testing\n",
        "\n",
        "train_len = 25000\n",
        "test_len = 2500\n",
        "opt_len = 5000\n",
        "test_start_ind = 25000 #should be larger than train_len\n",
        "valid_size = 0.1\n",
        "num_loop = 17\n",
        "num_opt_trial = 1\n",
        "\n",
        "kijun_ratio =0.0075\n",
        "kijun_period = 300\n",
        "pt_ratio = kijun_ratio\n",
        "lc_ratio = 0.03\n",
        "random_state = None\n",
        "lgb_random_state = None\n",
        "\n",
        "\n",
        "#params = {'objective': 'multiclass', 'num_class':4, 'learning_rate':0.1, 'boosting': 'gbdt', 'num_iterations':1000,'early_stopping_rounds':50, 'device_type':'gpu', 'metric':'multi_logloss'}\n",
        "params = {'objective': 'multiclass', 'num_class':4, 'learning_rate':0.1, 'boosting': 'gbdt', 'num_iterations':1000,'early_stopping_rounds':50, 'device_type':'gpu', 'metric':'multi_logloss', 'silent':True, \n",
        "           'bagging_fraction': 0.7825992150055953, 'bagging_freq': 27, 'boosting': 'gbdt', 'feature_fraction': 0.9268455510684652, 'lambda_l1': 72, 'lambda_l2': 12, 'max_bin': 47, 'max_depth': 9, \n",
        "          'min_data_in_leaf': 193, 'min_gain_to_split': 10, 'min_sum_hessian_in_leaf': 7.437792888438823, 'num_leaves': 65}\n",
        "\n",
        "verbose_eval = 0\n",
        "\n",
        "start = time.time()\n",
        "OneMinMarketData.initialize_for_bot(num_term, from_ind, to_ind, kijun_ratio, kijun_period, production_data_len)\n",
        "df = OneMinMarketData.genrate_df_from_dict()\n",
        "df = OneMinMarketData.remove_cols_contains_nan2(df)\n",
        "#df = OneMinMarketData.remove_all_correlated_cols4(df, corr_kijun)\n",
        "df2 = OneMinMarketData.remove_price_dependent_cols2(df, corr_kijun)\n",
        "print('len df2=',len(df2), df2['dt'].iloc[0], ' - ', df2['dt'].iloc[-1])\n",
        "\n",
        "sim = Sim()\n",
        "ac = SimAccount()\n",
        "ac2 = SimAccount()\n",
        "start_ind_log = 0\n",
        "end_ind_log = 0\n",
        "\n",
        "opt_params = {}\n",
        "\n",
        "for i in range(num_loop):\n",
        "    best_opt_params = None\n",
        "    best_opt_ac = None\n",
        "    current_best_performance = 9999 #assumed min optimization\n",
        "    best_model = None\n",
        "    for j in range(num_opt_trial):\n",
        "        print('opt calc no.=',j)\n",
        "        lgbmodel = LgbModel()\n",
        "        #catmodel = CatboostModel()\n",
        "        train_df = df2.iloc[test_start_ind - train_len + (test_len * i):(test_len * i) + test_start_ind].copy()\n",
        "        test_df = df2.iloc[kijun_period + (test_len * i) + test_start_ind:kijun_period + test_start_ind + (test_len * i) + test_len].copy()\n",
        "        #train_xb, test_xb, train_yb, test_yb, valid_xb, valid_yb, opt_xb, opt_yb = lgbmodel.generate_bpsp_data(train_df, test_df, valid_size, opt_len, random_state)\n",
        "        train_xb, test_xb, train_yb, test_yb, valid_xb, valid_yb, opt_xb, opt_yb = lgbmodel.generate_bpsp_data2(train_df, test_df, opt_len, valid_size, random_state)\n",
        "\n",
        "        if list(train_xb.columns) == list(test_xb.columns) == list(valid_xb.columns):\n",
        "            pass\n",
        "        else:\n",
        "            print('train col, test col, valid col are not matched!')\n",
        "\n",
        "        model = lgbmodel.train_params_with_validations(train_xb, train_yb, valid_xb, valid_yb, params, verbose_eval)\n",
        "        print(model.best_score)\n",
        "        #model = catmodel.param_train(train_xb, train_yb, cat_params)\n",
        "        prediction = lgbmodel.bpsp_prediction(model, train_xb, upper_kijun)\n",
        "        #prediction = lgbmodel.bpsp_prediction2(model, train_xb)\n",
        "        #prediction = catmodel.predict(model, train_xb, train_yb)\n",
        "        print('train accuracy={}'.format(lgbmodel.calc_bpsp_accuracy(prediction, train_yb)))\n",
        "\n",
        "        prediction = lgbmodel.bpsp_prediction(model, valid_xb, upper_kijun)\n",
        "        #prediction = lgbmodel.bpsp_prediction2(model, test_xb)\n",
        "        #prediction = catmodel.predict(model, test_xb, test_yb)\n",
        "        print('valid accuracy={}'.format(lgbmodel.calc_bpsp_accuracy(prediction, valid_yb)))\n",
        "\n",
        "        optsim = OptunaSim()\n",
        "        opt_params, best_ac = optsim.start_opt_sim(model, opt_xb, opt_yb, df2, pt_ratio, lc_ratio)\n",
        "        print('opt trial no.', j)\n",
        "        print('current opt pl=', best_ac.total_pl, ', current opt stability=', best_ac.pl_stability)\n",
        "        if current_best_performance > -best_ac.total_pl * best_ac.pl_stability:\n",
        "            best_opt_params = copy.copy(opt_params)\n",
        "            best_opt_ac = copy.copy(best_ac)\n",
        "            best_model = copy.copy(model)\n",
        "            current_best_performance = copy.copy(-best_ac.total_pl * best_ac.pl_stability)\n",
        "\n",
        "    print('opt pl=', best_opt_ac.total_pl)\n",
        "    print('opt params:', opt_params)\n",
        "    plt.plot(best_opt_ac.total_pl_log, label=str((test_len * i) + test_start_ind) + ' - ' + str((test_len * i) + test_start_ind + opt_len))\n",
        "    plt.legend()\n",
        "\n",
        "    if best_opt_params['pred_method'] == 0:\n",
        "        prediction = lgbmodel.bpsp_prediction(best_model, test_xb, best_opt_params['upper_kijun'])\n",
        "    elif best_opt_params['pred_method'] == 1:\n",
        "        prediction = lgbmodel.bpsp_prediction2(best_model, test_xb)\n",
        "    elif best_opt_params['pred_method'] == 2:\n",
        "        prediction = lgbmodel.bpsp_prediction2_kai(best_model, test_xb)\n",
        "    elif best_opt_params['pred_method'] == 3:\n",
        "        prediction = lgbmodel.bpsp_prediction3(best_model, test_xb, best_opt_params['upper_kijun'])\n",
        "    elif best_opt_params['pred_method'] == 4:\n",
        "        prediction = lgbmodel.bpsp_prediction4(best_model, test_xb)\n",
        "    print('test accuracy={}'.format(lgbmodel.calc_bpsp_accuracy(prediction, test_yb)))\n",
        "\n",
        "    start_ind = OneMinMarketData.check_matched_dt(test_xb, df2)\n",
        "    last_day = True if i == num_loop -1 else False\n",
        "    if best_opt_params['avert_onemine'] == 0:\n",
        "        ac = sim.sim_model_pred_onemin(start_ind, prediction, pt_ratio, lc_ratio, ac, last_day)\n",
        "    else:\n",
        "        ac = sim.sim_model_pred_onemin_avert(start_ind, prediction, pt_ratio, lc_ratio, ac, ac2, int(best_opt_params['avert_period_kijun']), best_opt_params['avert_val_kijun']/10000, last_day)\n",
        "    print('i=',i)\n",
        "    print('total pl={},num trade={},win rate={}, pl_stability={}, num_buy={}, num_sell={}'.format(ac.total_pl,ac.num_trade,ac.win_rate, ac.pl_stability, ac.num_buy,ac.num_sell))\n",
        "    print('strategy performance={}'.format(ac.total_pl * ac.pl_stability))\n",
        "\n",
        "    if i == 0:\n",
        "        start_ind_log = start_ind\n",
        "    else:\n",
        "        end_ind_log = start_ind\n",
        "\n",
        "if end_ind_log == 0:\n",
        "    end_ind_log = start_ind_log\n",
        "\n",
        "with open('/content/drive/My Drive/Model/bpsp_cols.csv', 'w') as file:\n",
        "    writer = csv.writer(file, lineterminator='\\n')\n",
        "    writer.writerow(train_xb)\n",
        "\n",
        "with open('/content/drive/My Drive/Model/lgb_bpsp_model.dat', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "config = {'num_term':num_term, 'kijun_period':kijun_period, 'pt_ratio':pt_ratio, 'lc_ratio':lc_ratio, 'pred_method':opt_params['pred_method'], 'upper_kijun':opt_params['upper_kijun'], 'avert_onemine':opt_params['avert_onemine'], \n",
        "            'avert_period_kijun':opt_params['avert_period_kijun'], 'avert_val_kijun':opt_params['avert_val_kijun']/10000.0}\n",
        "pd.DataFrame(config,index=['0']).to_csv('/content/drive/My Drive/Model/bpsp_config.csv')\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "plt.figure(figsize=(30,30),dpi=200)\n",
        "ax1.plot(ac.performance_total_pl_log,color='red',linewidth = 3.0,label='pl')\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(OneMinMarketData.ohlc.close[start_ind_log:end_ind_log + test_len])\n",
        "plt.show()\n",
        "print('test period=', OneMinMarketData.ohlc.dt[start_ind_log], ' - ', OneMinMarketData.ohlc.dt[end_ind_log + test_len])\n",
        "print('total pl={},num trade={},win rate={}, pl_stability={}, num_buy={}, num_sell={}'.format(ac.total_pl,ac.num_trade,ac.win_rate, ac.pl_stability, ac.num_buy,ac.num_sell))\n",
        "print('strategy performance={}'.format(ac.total_pl * ac.pl_stability))\n",
        "\n",
        "lgbmodel.eval_multi_score(prediction, test_yb)\n",
        "\n",
        "ac.log_data_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4QWmIFnQ1Jk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "importance = pd.DataFrame(model.feature_importance(), index=list(train_xb.columns), columns=['importance'])\n",
        "print(importance.sort_values('importance', ascending=False)[:50])\n",
        "plt.plot(importance.sort_values('importance', ascending=True).values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_i7Vhwu-axQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(OneMinMarketData.ohlc.close)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udLpqucBoADF",
        "colab_type": "code",
        "outputId": "df549e3b-f228-474d-b53f-df726b0b08bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "'''\n",
        "Opt Sim Lgb non opt sim\n",
        "'''\n",
        "\n",
        "\n",
        "import time\n",
        "num_term = 1500\n",
        "upper_kijun = 0.6\n",
        "corr_kijun = 0.2\n",
        "from_ind = 0\n",
        "to_ind = 110000\n",
        "production_data_len = 0 #set 0 when testing\n",
        "\n",
        "train_len = 25000\n",
        "test_len = 10000\n",
        "opt_len = 1\n",
        "test_start_ind = 30000 #should be larger than train_len\n",
        "valid_size = 0.1\n",
        "num_loop = 7\n",
        "\n",
        "kijun_ratio =0.0075\n",
        "kijun_period = 300\n",
        "pt_ratio = kijun_ratio\n",
        "lc_ratio = 0.03\n",
        "random_state = 1\n",
        "lgb_random_state = 1\n",
        "\n",
        "avert_period_kijun = 908\n",
        "avert_val_kijun = -63/10000.0\n",
        "\n",
        "pred_method = 0\n",
        "avert_onemine = 0\n",
        "sim_action = 0\n",
        "flg_large_only = True\n",
        "flg_abs = True\n",
        "\n",
        "\n",
        "#params = {'objective': 'multiclass', 'num_class':4, 'learning_rate':0.1, 'boosting': 'gbdt', 'num_iterations':1000,'early_stopping_rounds':50, 'device_type':'gpu', 'metric':'multi_logloss', 'silent':True}\n",
        "\n",
        "params = {'objective': 'multiclass', 'num_class':4, 'learning_rate':0.1, 'boosting': 'gbdt', 'num_iterations':1000,'early_stopping_rounds':50, 'device_type':'gpu', 'metric':'multi_logloss', 'silent':True, \n",
        "           'lambda_l1': 15, 'lambda_l2': 15,  'max_depth': 5, 'num_leaves': 100}\n",
        "verbose_eval = 0\n",
        "\n",
        "start = time.time()\n",
        "OneMinMarketData.initialize_for_bot(num_term, from_ind, to_ind, kijun_ratio, kijun_period, production_data_len)\n",
        "df = OneMinMarketData.genrate_df_from_dict()\n",
        "df = OneMinMarketData.remove_cols_contains_nan2(df)\n",
        "#df2 = OneMinMarketData.remove_all_correlated_cols4(df, corr_kijun, flg_abs)\n",
        "df2 = OneMinMarketData.remove_price_dependent_cols2(df, corr_kijun, flg_abs)\n",
        "print('len df2=',len(df2), df2['dt'].iloc[0], ' - ', df2['dt'].iloc[-1])\n",
        "\n",
        "sim = None\n",
        "if sim_action == 0:\n",
        "    sim = Sim()\n",
        "else:\n",
        "    sim = SimAction()\n",
        "ac = None\n",
        "ac2 = None\n",
        "ac = SimAccount()\n",
        "ac2 = SimAccount()\n",
        "start_ind_log = 0\n",
        "end_ind_log = 0\n",
        "last_test_len = 0\n",
        "\n",
        "kyuhen_period = 10\n",
        "kyuhen_kijun = 0.01\n",
        "\n",
        "for i in range(num_loop):\n",
        "    lgbmodel = LgbModel()\n",
        "    #catmodel = CatboostModel()\n",
        "    train_df = df2.iloc[test_start_ind - train_len + (test_len * i):(test_len * i) + test_start_ind].copy()\n",
        "    test_df = df2.iloc[kijun_period + (test_len * i) + test_start_ind:kijun_period + test_start_ind + (test_len * i) + test_len].copy()\n",
        "    train_xb, test_xb, train_yb, test_yb, valid_xb, valid_yb, opt_xb, opt_yb = lgbmodel.generate_bpsp_data(train_df, test_df, opt_len, valid_size, random_state)\n",
        "    #train_xb, test_xb, train_yb, test_yb, valid_xb, valid_yb, opt_xb, opt_yb = lgbmodel.generate_bpsp_data2(train_df, test_df, opt_len, valid_size, random_state)\n",
        "\n",
        "    if list(train_xb.columns) == list(test_xb.columns) == list(valid_xb.columns):\n",
        "        pass\n",
        "    else:\n",
        "        print('train col, test col, valid col are not matched!')\n",
        "\n",
        "    model = lgbmodel.train_params_with_validations(train_xb, train_yb, valid_xb, valid_yb, params, verbose_eval)\n",
        "    print(model.best_score)\n",
        "\n",
        "    prediction = lgbmodel.bpsp_prediction(model, train_xb, upper_kijun)\n",
        "    #prediction = lgbmodel.bpsp_prediction4(model, test_xb)\n",
        "    print('train accuracy={}'.format(lgbmodel.calc_bpsp_accuracy(prediction, train_yb)))\n",
        "\n",
        "    prediction = lgbmodel.bpsp_prediction(model, valid_xb, upper_kijun)\n",
        "    #prediction = lgbmodel.bpsp_prediction4(model, test_xb)\n",
        "    print('valid accuracy={}'.format(lgbmodel.calc_bpsp_accuracy(prediction, valid_yb)))\n",
        "\n",
        "    if pred_method == 0:\n",
        "        prediction = lgbmodel.bpsp_prediction(model, test_xb, upper_kijun)\n",
        "    elif pred_method == 1:\n",
        "        prediction = lgbmodel.bpsp_prediction2(model, test_xb)\n",
        "    elif pred_method == 2:\n",
        "        prediction = lgbmodel.bpsp_prediction2_kai(model, test_xb)\n",
        "    elif pred_method == 3:\n",
        "        prediction = lgbmodel.bpsp_prediction3(model, test_xb, upper_kijun)\n",
        "    elif pred_method == 4:\n",
        "        prediction = lgbmodel.bpsp_prediction4(model, test_xb)\n",
        "    else:\n",
        "        print('invalid pred method!', params['pred_method'])\n",
        "    print('test accuracy={}'.format(lgbmodel.calc_bpsp_accuracy(prediction, test_yb)))\n",
        "\n",
        "    start_ind = OneMinMarketData.check_matched_dt(test_xb, df2)\n",
        "    last_day = True if i == num_loop -1 else False\n",
        "    #ac = sim.sim_model_pred_onemin_avert(start_ind, prediction, pt_ratio, lc_ratio, ac, ac2, avert_period_kijun, avert_val_kijun, last_day)\n",
        "    if avert_onemine == 0:\n",
        "        ac = sim.sim_model_pred_onemin(start_ind, prediction, pt_ratio, lc_ratio, ac, last_day, flg_large_only, kyuhen_period, kyuhen_kijun)\n",
        "    elif avert_onemine == 1:\n",
        "        ac = sim.sim_model_pred_onemin_avert(start_ind, prediction, pt_ratio, lc_ratio, ac, ac2, avert_period_kijun, avert_val_kijun, last_day, flg_large_only, kyuhen_period, kyuhen_kijun)\n",
        "    print('i=',i)\n",
        "    print('total pl={},num trade={},win rate={}, pl_stability={}, num_buy={}, num_sell={}'.format(ac.total_pl,ac.num_trade,ac.win_rate, ac.pl_stability, ac.num_buy,ac.num_sell))\n",
        "    print('strategy performance={}'.format(ac.total_pl * ac.pl_stability))\n",
        "\n",
        "    if i == 0:\n",
        "        start_ind_log = start_ind\n",
        "    else:\n",
        "        end_ind_log = start_ind\n",
        "    last_test_len = len(test_yb)\n",
        "    del train_df, test_df, train_xb, test_xb, train_yb, valid_xb, valid_yb, opt_xb, opt_yb, model\n",
        "\n",
        "if end_ind_log == 0:\n",
        "    end_ind_log = start_ind_log\n",
        "\n",
        "'''\n",
        "with open('/content/drive/My Drive/Model/bpsp_cols.csv', 'w') as file:\n",
        "    writer = csv.writer(file, lineterminator='\\n')\n",
        "    writer.writerow(train_xb)\n",
        "\n",
        "with open('/content/drive/My Drive/Model/lgb_bpsp_model.dat', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "'''\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "plt.figure(figsize=(30,30),dpi=200)\n",
        "ax1.plot(ac.performance_total_pl_log,color='red',linewidth = 3.0,label='pl')\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(OneMinMarketData.ohlc.close[start_ind_log:end_ind_log + test_len])\n",
        "plt.show()\n",
        "print('test period=', OneMinMarketData.ohlc.dt[start_ind_log], ' - ', OneMinMarketData.ohlc.dt[end_ind_log + last_test_len])\n",
        "print('total pl={},num trade={},win rate={}, pl_stability={}, num_buy={}, num_sell={}'.format(ac.total_pl,ac.num_trade,ac.win_rate, ac.pl_stability, ac.num_buy,ac.num_sell))\n",
        "print('strategy performance={}'.format(ac.total_pl * ac.pl_stability))\n",
        "\n",
        "lgbmodel.eval_multi_score(prediction, test_yb)\n",
        "\n",
        "ac.log_data_df\n",
        "\n",
        "del df, df2, test_yb, OneMinMarketData.ohlc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "normal cut data\n",
            "calculating all index dict\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-8342b447d25c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mOneMinMarketData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_for_bot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkijun_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkijun_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduction_data_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneMinMarketData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenrate_df_from_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneMinMarketData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_cols_contains_nan2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-0a652dd83238>\u001b[0m in \u001b[0;36minitialize_for_bot\u001b[0;34m(cls, num_term, from_ind, to_ind, kijun_ratio, kijun_period, production_data_len)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mohlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcut_data2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mproduction_data_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__generate_all_func_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__calc_all_index_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-0a652dd83238>\u001b[0m in \u001b[0;36m__calc_all_index_dict\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'makairi'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'diff'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ema_kairi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ema_gra'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dema_kairi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dema_gra'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                     \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mohlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_data_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mohlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mohlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mohlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_data_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mohlc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-0a652dd83238>\u001b[0m in \u001b[0;36mcalc_cci\u001b[0;34m(cls, term)\u001b[0m\n\u001b[1;32m    838\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalc_cci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         return list(\n\u001b[0;32m--> 840\u001b[0;31m             ta.CCI(np.array(cls.ohlc.high, dtype='f8'), np.array(cls.ohlc.low, dtype='f8'), np.array(cls.ohlc.close, dtype='f8'), timeperiod=term))\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbQNzOrot-qe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "for opt param\n",
        "'''\n",
        "\n",
        "\n",
        "import time\n",
        "num_term = 1000\n",
        "upper_kijun = 0.6\n",
        "corr_kijun = 0.5\n",
        "from_ind = 0\n",
        "to_ind = 124000\n",
        "production_data_len = 0 #set 0 when testing\n",
        "\n",
        "train_len = 25000\n",
        "test_len = 10000\n",
        "opt_len = 1\n",
        "test_start_ind = 25000 #should be larger than train_len\n",
        "valid_size = 0.1\n",
        "num_loop = 9\n",
        "\n",
        "kijun_ratio =0.0075\n",
        "kijun_period = 300\n",
        "pt_ratio = kijun_ratio\n",
        "lc_ratio = 0.03\n",
        "random_state = None\n",
        "lgb_random_state = None\n",
        "\n",
        "avert_period_kijun = 908\n",
        "avert_val_kijun = -63/10000.0\n",
        "\n",
        "pred_method = 0\n",
        "avert_onemine = 0\n",
        "sim_action = 0\n",
        "flg_large_only = True\n",
        "flg_abs = True\n",
        "\n",
        "\n",
        "\n",
        "pl = []\n",
        "performance = []\n",
        "num = []\n",
        "win_rate = []\n",
        "param = []\n",
        "\n",
        "test_len_list = [5000,10000,15000,30000,45000]\n",
        "num_loop_list = [18, 9, 6, 3, 2]\n",
        "\n",
        "num_test = 5\n",
        "for nt in range(num_test):\n",
        "    test_len = test_len_list[nt]\n",
        "    num_loop = num_loop_list[nt]\n",
        "    param.append('test='+str(test_len)+',  num_loop'+str(num_loop))\n",
        "\n",
        "    #params = {'objective': 'multiclass', 'num_class':4, 'learning_rate':0.1, 'boosting': 'gbdt', 'num_iterations':1000,'early_stopping_rounds':50, 'device_type':'gpu', 'metric':'multi_logloss', 'silent':True}\n",
        "\n",
        "    params = {'objective': 'multiclass', 'num_class':4, 'learning_rate':0.1, 'boosting': 'gbdt', 'num_iterations':1000,'early_stopping_rounds':50, 'device_type':'gpu', 'metric':'multi_logloss', 'silent':True, \n",
        "            'lambda_l1': 50, 'lambda_l2': 55,  'max_depth': 5, 'num_leaves': 50}\n",
        "    verbose_eval = 0\n",
        "\n",
        "    start = time.time()\n",
        "    OneMinMarketData.initialize_for_bot(num_term, from_ind, to_ind, kijun_ratio, kijun_period, production_data_len)\n",
        "    df = OneMinMarketData.genrate_df_from_dict()\n",
        "    df = OneMinMarketData.remove_cols_contains_nan2(df)\n",
        "    #df2 = OneMinMarketData.remove_all_correlated_cols4(df, corr_kijun, flg_abs)\n",
        "    df2 = OneMinMarketData.remove_price_dependent_cols2(df, corr_kijun, flg_abs)\n",
        "    print('len df2=',len(df2), df2['dt'].iloc[0], ' - ', df2['dt'].iloc[-1])\n",
        "\n",
        "    sim = None\n",
        "    if sim_action == 0:\n",
        "        sim = Sim()\n",
        "    else:\n",
        "        sim = SimAction()\n",
        "    ac = SimAccount()\n",
        "    ac2 = SimAccount()\n",
        "    start_ind_log = 0\n",
        "    end_ind_log = 0\n",
        "\n",
        "    for i in range(num_loop):\n",
        "        lgbmodel = LgbModel()\n",
        "        #catmodel = CatboostModel()\n",
        "        train_df = df2.iloc[test_start_ind - train_len + (test_len * i):(test_len * i) + test_start_ind].copy()\n",
        "        test_df = df2.iloc[kijun_period + (test_len * i) + test_start_ind:kijun_period + test_start_ind + (test_len * i) + test_len].copy()\n",
        "        #train_xb, test_xb, train_yb, test_yb, valid_xb, valid_yb, opt_xb, opt_yb = lgbmodel.generate_bpsp_data(train_df, test_df, opt_len, valid_size, random_state)\n",
        "        train_xb, test_xb, train_yb, test_yb, valid_xb, valid_yb, opt_xb, opt_yb = lgbmodel.generate_bpsp_data2(train_df, test_df, opt_len, valid_size, random_state)\n",
        "\n",
        "        if list(train_xb.columns) == list(test_xb.columns) == list(valid_xb.columns):\n",
        "            pass\n",
        "        else:\n",
        "            print('train col, test col, valid col are not matched!')\n",
        "\n",
        "        model = lgbmodel.train_params_with_validations(train_xb, train_yb, valid_xb, valid_yb, params, verbose_eval)\n",
        "        print(model.best_score)\n",
        "\n",
        "        prediction = lgbmodel.bpsp_prediction(model, train_xb, upper_kijun)\n",
        "        #prediction = lgbmodel.bpsp_prediction4(model, test_xb)\n",
        "        print('train accuracy={}'.format(lgbmodel.calc_bpsp_accuracy(prediction, train_yb)))\n",
        "\n",
        "        prediction = lgbmodel.bpsp_prediction(model, valid_xb, upper_kijun)\n",
        "        #prediction = lgbmodel.bpsp_prediction4(model, test_xb)\n",
        "        print('valid accuracy={}'.format(lgbmodel.calc_bpsp_accuracy(prediction, valid_yb)))\n",
        "\n",
        "        if pred_method == 0:\n",
        "            prediction = lgbmodel.bpsp_prediction(model, test_xb, upper_kijun)\n",
        "        elif pred_method == 1:\n",
        "            prediction = lgbmodel.bpsp_prediction2(model, test_xb)\n",
        "        elif pred_method == 2:\n",
        "            prediction = lgbmodel.bpsp_prediction2_kai(model, test_xb)\n",
        "        elif pred_method == 3:\n",
        "            prediction = lgbmodel.bpsp_prediction3(model, test_xb, upper_kijun)\n",
        "        elif pred_method == 4:\n",
        "            prediction = lgbmodel.bpsp_prediction4(model, test_xb)\n",
        "        else:\n",
        "            print('invalid pred method!', params['pred_method'])\n",
        "        print('test accuracy={}'.format(lgbmodel.calc_bpsp_accuracy(prediction, test_yb)))\n",
        "\n",
        "        start_ind = OneMinMarketData.check_matched_dt(test_xb, df2)\n",
        "        last_day = True if i == num_loop -1 else False\n",
        "        #ac = sim.sim_model_pred_onemin_avert(start_ind, prediction, pt_ratio, lc_ratio, ac, ac2, avert_period_kijun, avert_val_kijun, last_day)\n",
        "        if avert_onemine == 0:\n",
        "            ac = sim.sim_model_pred_onemin(start_ind, prediction, pt_ratio, lc_ratio, ac, last_day, flg_large_only)\n",
        "        elif avert_onemine == 1:\n",
        "            ac = sim.sim_model_pred_onemin_avert(start_ind, prediction, pt_ratio, lc_ratio, ac, ac2, avert_period_kijun, avert_val_kijun, last_day)\n",
        "        print('i=',i)\n",
        "        print('total pl={},num trade={},win rate={}, pl_stability={}, num_buy={}, num_sell={}'.format(ac.total_pl,ac.num_trade,ac.win_rate, ac.pl_stability, ac.num_buy,ac.num_sell))\n",
        "        print('strategy performance={}'.format(ac.total_pl * ac.pl_stability))\n",
        "\n",
        "        pl.append(ac.total_pl)\n",
        "        performance.append(ac.total_pl * ac.pl_stability)\n",
        "        num.append(ac.num_trade)\n",
        "        win_rate.append(ac.win_rate)\n",
        "\n",
        "        if i == 0:\n",
        "            start_ind_log = start_ind\n",
        "        else:\n",
        "            end_ind_log = start_ind\n",
        "\n",
        "    if end_ind_log == 0:\n",
        "        end_ind_log = start_ind_log\n",
        "\n",
        "    with open('/content/drive/My Drive/Model/bpsp_cols.csv', 'w') as file:\n",
        "        writer = csv.writer(file, lineterminator='\\n')\n",
        "        writer.writerow(train_xb)\n",
        "\n",
        "    with open('/content/drive/My Drive/Model/lgb_bpsp_model.dat', 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "    fig, ax1 = plt.subplots()\n",
        "    plt.figure(figsize=(30,30),dpi=200)\n",
        "    ax1.plot(ac.performance_total_pl_log,color='red',linewidth = 3.0,label='pl')\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(OneMinMarketData.ohlc.close[start_ind_log:end_ind_log + test_len])\n",
        "    plt.show()\n",
        "    print('test period=', OneMinMarketData.ohlc.dt[start_ind_log], ' - ', OneMinMarketData.ohlc.dt[end_ind_log + test_len])\n",
        "    print('total pl={},num trade={},win rate={}, pl_stability={}, num_buy={}, num_sell={}'.format(ac.total_pl,ac.num_trade,ac.win_rate, ac.pl_stability, ac.num_buy,ac.num_sell))\n",
        "    print('strategy performance={}'.format(ac.total_pl * ac.pl_stability))\n",
        "\n",
        "    del ac, ac2, df, df2, train_xb, test_xb, train_yb, test_yb, valid_xb, valid_yb, opt_xb, opt_yb\n",
        "\n",
        "df = pd.DataFrame({'param':param, 'pl':pl, 'performance':performance, 'num':num, 'win rate':win_rate})\n",
        "df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzfqGKLUZ7gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame({'param':param, 'pl':pl, 'performance':performance, 'num':num, 'win rate':win_rate})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiulH20DaUB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwAgvJerb9yW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    '''\n",
        "Opt Sim Lgb write param\n",
        "'''\n",
        "\n",
        "\n",
        "import time\n",
        "num_term = 1500\n",
        "upper_kijun = 0.7\n",
        "corr_kijun = 0.7\n",
        "from_ind = 100000\n",
        "to_ind = 244000\n",
        "production_data_len = 0 #set 0 when testing\n",
        "\n",
        "train_len = 25000\n",
        "test_len = 5000\n",
        "opt_len = 1\n",
        "test_start_ind = 25000 #should be larger than train_len\n",
        "valid_size = 0.1\n",
        "num_loop = \n",
        "\n",
        "kijun_ratio =0.0075\n",
        "kijun_period = 300\n",
        "pt_ratio = kijun_ratio\n",
        "lc_ratio = 0.03\n",
        "random_state = None\n",
        "lgb_random_state = None\n",
        "avert_period_kijun=10\n",
        "avert_val_kijun=0\n",
        "\n",
        "pred_method = 0\n",
        "avert_onemine = 0\n",
        "\n",
        "\n",
        "params = {'objective': 'multiclass', 'num_class':4, 'learning_rate':0.1, 'boosting': 'gbdt', 'num_iterations':1000,'early_stopping_rounds':50, 'device_type':'gpu', 'metric':'multi_logloss', 'silent':True, \n",
        "           'bagging_fraction': 0.44126029400204486, 'bagging_freq': 35, 'feature_fraction': 0.8596205555714488, 'lambda_l1': 31, 'lambda_l2': 78, 'max_bin': 21, 'max_depth': 7, \n",
        "          'min_data_in_leaf': 54, 'min_gain_to_split': 10, 'min_sum_hessian_in_leaf': 5.8059781895664555, 'num_leaves': 607}\n",
        "\n",
        "verbose_eval = 0\n",
        "\n",
        "start = time.time()\n",
        "OneMinMarketData.initialize_for_bot(num_term, from_ind, to_ind, kijun_ratio, kijun_period, production_data_len)\n",
        "df = OneMinMarketData.genrate_df_from_dict()\n",
        "df = OneMinMarketData.remove_cols_contains_nan2(df)\n",
        "#df = OneMinMarketData.remove_all_correlated_cols4(df, corr_kijun)\n",
        "df2 = OneMinMarketData.remove_price_dependent_cols2(df, corr_kijun)\n",
        "print('len df2=',len(df2), df2['dt'].iloc[0], ' - ', df2['dt'].iloc[-1])\n",
        "\n",
        "sim = SimAction()\n",
        "ac = SimAccount()\n",
        "ac2 = SimAccount()\n",
        "start_ind_log = 0\n",
        "end_ind_log = 0\n",
        "\n",
        "for i in range(num_loop):\n",
        "    lgbmodel = LgbModel()\n",
        "    #catmodel = CatboostModel()\n",
        "    train_df = df2.iloc[test_start_ind - train_len + (test_len * i):(test_len * i) + test_start_ind].copy()\n",
        "    test_df = df2.iloc[kijun_period + (test_len * i) + test_start_ind:kijun_period + test_start_ind + (test_len * i) + test_len].copy()\n",
        "    #train_xb, test_xb, train_yb, test_yb, valid_xb, valid_yb, opt_xb, opt_yb = lgbmodel.generate_bpsp_data(train_df, test_df, valid_size, opt_len, random_state)\n",
        "    train_xb, test_xb, train_yb, test_yb, valid_xb, valid_yb, opt_xb, opt_yb = lgbmodel.generate_bpsp_data2(train_df, test_df, opt_len, valid_size, random_state)\n",
        "\n",
        "    if list(train_xb.columns) == list(test_xb.columns) == list(valid_xb.columns):\n",
        "        pass\n",
        "    else:\n",
        "        print('train col, test col, valid col are not matched!')\n",
        "\n",
        "    model = lgbmodel.train_params_with_validations(train_xb, train_yb, valid_xb, valid_yb, params, verbose_eval)\n",
        "    print(model.best_score)\n",
        "\n",
        "    prediction = lgbmodel.bpsp_prediction(model, train_xb, upper_kijun)\n",
        "    #prediction = lgbmodel.bpsp_prediction4(model, test_xb)\n",
        "    print('train accuracy={}'.format(lgbmodel.calc_bpsp_accuracy(prediction, train_yb)))\n",
        "\n",
        "    prediction = lgbmodel.bpsp_prediction(model, valid_xb, upper_kijun)\n",
        "    #prediction = lgbmodel.bpsp_prediction4(model, test_xb)\n",
        "    print('valid accuracy={}'.format(lgbmodel.calc_bpsp_accuracy(prediction, valid_yb)))\n",
        "\n",
        "    if pred_method == 0:\n",
        "        prediction = lgbmodel.bpsp_prediction(model, test_xb, upper_kijun)\n",
        "    elif pred_method == 1:\n",
        "        prediction = lgbmodel.bpsp_prediction2(model, test_xb)\n",
        "    elif pred_method == 2:\n",
        "        prediction = lgbmodel.bpsp_prediction2_kai(model, test_xb)\n",
        "    elif pred_method == 3:\n",
        "        prediction = lgbmodel.bpsp_prediction3(model, test_xb, upper_kijun)\n",
        "    elif pred_method == 4:\n",
        "        prediction = lgbmodel.bpsp_prediction4(model, test_xb)\n",
        "    else:\n",
        "        print('invalid pred method!', params['pred_method'])\n",
        "    print('test accuracy={}'.format(lgbmodel.calc_bpsp_accuracy(prediction, test_yb)))\n",
        "\n",
        "    start_ind = OneMinMarketData.check_matched_dt(test_xb, df2)\n",
        "    last_day = True if i == num_loop -1 else False\n",
        "    #ac = sim.sim_model_pred_onemin_avert(start_ind, prediction, pt_ratio, lc_ratio, ac, ac2, avert_period_kijun, avert_val_kijun, last_day)\n",
        "    if avert_onemine == 0:\n",
        "        ac = sim.sim_model_pred_onemin(start_ind, prediction, pt_ratio, lc_ratio, ac, last_day)\n",
        "    elif avert_onemine == 1:\n",
        "        ac = sim.sim_model_pred_onemin_avert(start_ind, prediction, pt_ratio, lc_ratio, ac, ac2, avert_period_kijun, avert_val_kijun, last_day)\n",
        "    print('i=',i)\n",
        "    print('total pl={},num trade={},win rate={}, pl_stability={}, num_buy={}, num_sell={}'.format(ac.total_pl,ac.num_trade,ac.win_rate, ac.pl_stability, ac.num_buy,ac.num_sell))\n",
        "    print('strategy performance={}'.format(ac.total_pl * ac.pl_stability))\n",
        "\n",
        "    if i == 0:\n",
        "        start_ind_log = start_ind\n",
        "    else:\n",
        "        end_ind_log = start_ind\n",
        "\n",
        "if end_ind_log == 0:\n",
        "    end_ind_log = start_ind_log\n",
        "\n",
        "with open('/content/drive/My Drive/Model/bpsp_cols.csv', 'w') as file:\n",
        "    writer = csv.writer(file, lineterminator='\\n')\n",
        "    writer.writerow(train_xb)\n",
        "\n",
        "with open('/content/drive/My Drive/Model/lgb_bpsp_model.dat', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "config = {'num_term':num_term, 'kijun_period':kijun_period, 'pt_ratio':pt_ratio, 'lc_ratio':lc_ratio, 'pred_method':pred_method, 'upper_kijun':upper_kijun, 'avert_onemine':avert_onemine, \n",
        "            'avert_period_kijun':avert_period_kijun, 'avert_val_kijun':avert_val_kijun}\n",
        "pd.DataFrame(config,index=['0']).to_csv('/content/drive/My Drive/Model/bpsp_config.csv')\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "plt.figure(figsize=(30,30),dpi=200)\n",
        "ax1.plot(ac.performance_total_pl_log,color='red',linewidth = 3.0,label='pl')\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(OneMinMarketData.ohlc.close[start_ind_log:end_ind_log + test_len])\n",
        "plt.show()\n",
        "print('test period=', OneMinMarketData.ohlc.dt[start_ind_log], ' - ', OneMinMarketData.ohlc.dt[end_ind_log + test_len])\n",
        "print('total pl={},num trade={},win rate={}, pl_stability={}, num_buy={}, num_sell={}'.format(ac.total_pl,ac.num_trade,ac.win_rate, ac.pl_stability, ac.num_buy,ac.num_sell))\n",
        "print('strategy performance={}'.format(ac.total_pl * ac.pl_stability))\n",
        "\n",
        "lgbmodel.eval_multi_score(prediction, test_yb)\n",
        "\n",
        "ac.log_data_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S76X91aQ9deD",
        "colab_type": "code",
        "outputId": "91595274-d682-4443-8dc3-dda8ec413e6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot(OneMinMarketData.ohlc.close)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe917fea048>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG4rsxGiCBUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnj5fBRntf2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(test_xb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8wcmM4quP4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for op in opt_ac_list:\n",
        "    print(op.total_pl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY8M_ng8bOlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = lgbmodel.bpsp_prediction(model, opt_xb,0.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkLEExu5LaoA",
        "colab_type": "code",
        "outputId": "8acf7949-9a04-415a-8cb2-9dca09a9d4b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "df.iloc[3:6]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0\n",
              "3  4\n",
              "4  5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaDPSIEEh1Cc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "li = [1,2,3, 4, 5]\n",
        "df = pd.DataFrame(li)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZQ80iz5skmX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aaDstwqPEqjg",
        "colab": {}
      },
      "source": [
        "'''\n",
        "train data長いほうがいい\n",
        "corr removeしないほうがいい\n",
        "num_termは適切なものがある。（少なすぎても多すぎてもだめ）\n",
        "train / valid split (?)に大きく影響される。lgb seedはnoneでも結果は変わらない。\n",
        "valid sizeを極端に小さくしたら（１）結果の変動は小さくなる。\n",
        "train dataのindex orderにも影響され、index orderがdecending / ascendingの場合は学習が失敗して取引がなされない。\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}